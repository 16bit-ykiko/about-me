


[{"content":"","date":"18 December 2024","externalUrl":null,"permalink":"/en/articles/","section":"Articles","summary":"","title":"Articles","type":"articles"},{"content":"","date":"18 December 2024","externalUrl":null,"permalink":"/en/series/clice-dev-diary/","section":"Series","summary":"","title":"Clice Dev Diary","type":"series"},{"content":"It has been several months since the last blog post. The reason for the long hiatus is that I have been busy working on clice — a brand-new C++ language server.\nSome readers might be unfamiliar with the concept of a language server. However, you have likely used IDEs like Visual Studio or CLion and experienced features such as code completion, navigation, and refactoring. In traditional IDEs, these features are implemented through plugins or built-in functionalities, which require separate development for each editor, leading to high maintenance costs. When Microsoft released Visual Studio Code, they aimed to solve this problem by introducing the Language Server Protocol (LSP). LSP proposes a standard client-server model where language features are provided by an independent language server, and VSCode only needs to implement a generic client to communicate with the language server. This approach decouples the editor from language support, allowing VSCode to easily support multiple languages. For example, if you want to view the implementation of a method, your editor sends a go to implementation request to the language server, which might include the file path and the cursor\u0026rsquo;s position in the source file. The language server processes this request and returns a file location and coordinates, enabling the editor to open the corresponding file and navigate to the specified location.\nclice is such a language server, designed to handle requests related to C/C++ code. The name \u0026ldquo;clice\u0026rdquo; is derived from my avatar \u0026ldquo;alice,\u0026rdquo; with the first letter replaced by \u0026ldquo;c\u0026rdquo; to represent C/C++.\nAfter several months of design and development, the project has taken shape, but it will likely take a few more months to refine before it can be put into use. This article primarily introduces the design and implementation of clice, serving as a personal summary of the current development stage. While the content is related to language servers, it also involves a lot of C/C++ compilation knowledge, so interested readers are encouraged to continue reading.\nAdditionally, if you have any feature requests or suggestions, feel free to leave a comment. I will do my best to consider them in the next phase of development.\nWhy a New Language Server? # The first question is, why develop a new language server? Is it necessary to reinvent the wheel?\nThis question deserves a serious answer. Before this project, I had written many small or large projects. However, most of them were toy projects, created merely to validate an idea or for personal learning, without solving any real-world problems. clice is different; it aims to address existing issues (specific problems will be discussed later), not just to rewrite something for the sake of it.\nAt the beginning of this year, I wanted to contribute to the LLVM project. I thought I would start with something familiar, like C++ and Clang. However, without a specific need, I couldn\u0026rsquo;t just stare at the source code. Normally, the process would involve starting with some \u0026ldquo;first issues\u0026rdquo; to gradually familiarize myself with the project. But I found that boring; I wanted to tackle something significant right away, like implementing a new C++ standard feature. However, I discovered that there was almost no room for me to contribute here, as new features were almost always implemented by a few core Clang developers. So, I shifted my focus to clangd, since I primarily use VSCode for development, and clangd is the best C++ language server for VSCode.\nAt the time, I knew nothing about clangd, except that it seemed to render keyword highlighting incorrectly. So, I started reading clangd\u0026rsquo;s source code and browsing through its numerous issues to see if there was anything I could fix. After going through hundreds of issues, I found that there were indeed many problems. One issue that particularly caught my interest was related to code completion within templates (issue). Why was I interested in this? Regular readers might know that I am a seasoned metaprogramming enthusiast and have written many articles on the topic. Naturally, I was curious not only about how template metaprogramming works but also about how Clang, as a compiler, implements related features. This issue seemed like a great entry point. After spending a few weeks prototyping a solution, I managed to address the issue, but then I realized there was no one to review the code!\nUpon further investigation, I found that clangd\u0026rsquo;s current state is quite dire. Let\u0026rsquo;s go through the timeline: clangd started as a small project within LLVM, with limited functionality and usability. As MaskRay mentioned in his ccls blog post, clangd at the time could only handle single compilation units, making it unable to process cross-compilation unit requests. This blog post was published in 2017, which is why MaskRay chose to develop ccls, another C/C++ language server that was superior to clangd at the time. However, later on, Google began assigning people to improve clangd to meet the needs of their large internal codebases. At the same time, the LSP standard was continuously expanding, and clangd kept up with the new standards, while ccls\u0026rsquo;s author seemed to become increasingly busy with other matters and had less time to maintain ccls. Eventually, clangd surpassed ccls in overall capability. The turning point came around 2023 when clangd reached a highly usable state for Google\u0026rsquo;s internal use, and the employees originally responsible for clangd were reassigned to other projects. Currently, clangd\u0026rsquo;s issues are primarily handled by HighCommander4, who works on it out of passion and is not employed by anyone to do so. Since he is not officially hired to maintain clangd, he can only address issues in his limited free time, mostly answering questions and conducting occasional code reviews. As he mentioned in this comment:\nThe other part of the reason is lack of resources to pursue the ideas we do have, such as the idea mentioned above of trying to shift more of the burden to disk usage through more aggressive preamble caching. I\u0026rsquo;m a casual contributor, and the limited time I have to spend on clangd is mostly taken up by answering questions, some code reviews, and the occasional small fix / improvement; I haven\u0026rsquo;t had the bandwidth to drive this type of performance-related experimentation.\nGiven this situation, it\u0026rsquo;s no surprise that large PRs like preliminary support for C++20 modules in clangd have been delayed for nearly a year. Realizing this, I began to consider developing my own language server. I estimated the project size to be around 20,000 lines of code (excluding tests), which is manageable for one person over a period of time, and there are precedents like ccls and rust-analyzer. Another point is that clangd\u0026rsquo;s codebase is quite dated. Despite having extensive comments, the logic is still convoluted, and making large-scale modifications might take longer than rewriting from scratch.\nSo, I decided to proceed. I categorized clangd\u0026rsquo;s hundreds of issues to see if some problems were due to clangd\u0026rsquo;s initial architectural design flaws, making them difficult to resolve and thus left unresolved. If so, could these issues be addressed by redesigning from the start? I found that indeed, some issues fit this description! Over the next few months, I spent time studying Clang\u0026rsquo;s related mechanisms, exploring solutions to these problems, and prototyping implementations. After confirming that these issues could be resolved, I officially began developing clice.\nImportant Improvements # After all that, let\u0026rsquo;s take a look at the major issues in clangd that clice aims to solve. This section focuses on feature introductions, while the implementation details will be covered in the Design section. In addition to these significant improvements, there are also many smaller feature enhancements, which won\u0026rsquo;t be listed here.\nBetter Template Support # First and foremost, better template support, which was my initial motivation for wanting clangd to support this feature. What exactly are the current issues with template handling?\nTake code completion as an example. Consider the following code, where ^ represents the cursor position:\ntemplate \u0026lt;typename T\u0026gt; void foo(std::vector\u0026lt;T\u0026gt; vec) { vec.^ } In C++, if a type depends on a template parameter, we cannot make any accurate assumptions about it before the template is instantiated. For example, here vector could be either the primary template or a partial specialization like vector\u0026lt;bool\u0026gt;. Which one should we choose? For code compilation, accuracy is always paramount; we cannot use any results that might lead to errors. However, for a language server, providing more possible results is often better than providing none. We can assume that users are more likely to use the primary template rather than a partial specialization, and thus provide code completion based on the primary template. Currently, clangd does this; in the above case, it provides code completion based on the primary template of vector.\nNow consider a more complex example:\ntemplate \u0026lt;typename T\u0026gt; void foo(std::vector\u0026lt;std::vector\u0026lt;T\u0026gt;\u0026gt; vec2) { vec2[0].^ } From the user\u0026rsquo;s perspective, code completion should also be provided here, since the type of vec2[0] is also vector\u0026lt;T\u0026gt;, similar to the previous example. However, clangd does not provide any completion here. What\u0026rsquo;s the issue? According to the C++ standard, the return type of std::vector\u0026lt;T\u0026gt;::operator[] is std::vector\u0026lt;T\u0026gt;::reference, which is a dependent name. Its result seems straightforward: T\u0026amp;. However, in libstdc++, its definition is nested within dozens of template layers, possibly for compatibility with older standards? So why can\u0026rsquo;t clangd handle this situation?\nIt assumes the primary template and does not consider partial specializations, which might prevent the lookup from proceeding. It only performs name lookup without template instantiation, so even if it finds the result, it cannot map it back to the original template parameters. It does not consider default template parameters, making it unable to handle dependent names caused by default template parameters. Although we could hack support for standard library types, I wanted user code to have the same status as standard library code, so we needed a generic algorithm to handle dependent types. To solve this, I developed a pseudo-instantiation mechanism. It can instantiate dependent types without specific types, thereby simplifying them. For example, in the above case, std::vector\u0026lt;std::vector\u0026lt;T\u0026gt;\u0026gt;::reference can be simplified to std::vector\u0026lt;T\u0026gt;\u0026amp;, allowing us to provide code completion options to the user.\nHeader Context # For clangd to function properly, users often need to provide a compile_commands.json file (referred to as CDB file). The traditional C++ compilation model treats a source file (e.g., .c or .cpp) as the basic compilation unit, where #include simply pastes the contents of the header file into the source file at the corresponding location. The CDB file stores the compilation commands for each source file. When you open a source file, clangd uses the corresponding compilation command from the CDB to compile the file.\nThis naturally raises a question: if the CDB file only contains compilation commands for source files and not header files, how does clangd handle header files? clangd treats header files as source files and, based on certain rules, uses the compilation command of a corresponding source file in the same directory as the header file\u0026rsquo;s compilation command. This model is simple and effective but overlooks some scenarios.\nSince a header file is part of a source file, its content can vary depending on the preceding content in the source file. For example:\n// a.h #ifdef TEST struct X { ... }; #else struct Y { ... }; #endif // b.cpp #define TEST #include \u0026#34;a.h\u0026#34; // c.cpp #include \u0026#34;a.h\u0026#34; Clearly, a.h has different states in b.cpp and c.cpp—one defines X, and the other defines Y. If a.h is simply treated as a source file, only Y will be visible.\nA more extreme case is non-self-contained header files, such as:\n// a.h struct Y { X x; }; // b.cpp struct X {}; #include \u0026#34;a.h\u0026#34; a.h cannot be compiled on its own, but when embedded in b.cpp, it compiles correctly. In this case, clangd will report an error in a.h, stating that X is undefined. This is because it treats a.h as an independent source file. There are many such header files in libstdc++, and some popular C++ header-only libraries also contain such code, which clangd currently cannot handle.\nclice will support header context, allowing automatic and user-initiated switching of header file states, and will also support non-self-contained header files. We aim to achieve the following effect, using the initial code as an example. When you navigate from b.cpp to a.h, b.cpp will be used as the context for a.h. Similarly, when navigating from c.cpp to a.h, c.cpp will be used as the context for a.h.\nFull C++20 Module Support # C++20 introduced modules to speed up compilation. Unlike the traditional compilation model, module units may have dependencies, requiring additional handling. Although a PR for preliminary support of modules in clangd has been merged, it is in a very early stage.\nPrecompiled modules are not shared between different files, leading to redundant module compilation. Other LSP facilities have not kept up, such as highlighting and navigation for module names, and providing completions similar to header files. Only Clang is supported, not other compilers. clice will provide compiler and build-system-agnostic C++20 module support, and the project itself will eventually fully migrate to modules.\nBetter Index Format # Some ccls users might complain that, despite pre-indexing the entire project, ccls can jump instantly upon opening a file, while clangd still needs to wait for file parsing to complete. Why is this the case? This is due to a design flaw in clangd\u0026rsquo;s index format. What is an index? Since C/C++ supports forward declarations, declarations and definitions may reside in different source files, requiring handling of cross-compilation unit symbol relationships.\nHowever, parsing files is a time-consuming operation. If we wait until a query is needed to parse the file, the query time would be astronomical. To support fast symbol relationship lookup, language servers generally pre-index the entire project. But what format should be used to store this data? There is no standard.\nclice has thoroughly studied existing index designs and developed a more efficient index format. It can achieve the same effect as ccls: if the project is pre-indexed, responses can be obtained immediately without waiting.\nDesign # This section will delve deeper into the design and implementation of clice.\nServer # First, a language server is still a server, not much different from a traditional server in this regard. It uses an event-driven programming model, accepting server requests and processing them. Since C++20 is available, it\u0026rsquo;s natural to experience asynchronous programming using stackless coroutines. clangd\u0026rsquo;s code contains numerous callback functions, making this part of the code quite unreadable. Using stackless coroutines can avoid such callback hell.\nNotably, in terms of library selection, I did not choose an existing coroutine library but instead wrapped libuv using C++20\u0026rsquo;s coroutine facilities to create a simple coroutine library. The reasons are as follows:\nThe LLVM project does not use exceptions, and we aim to stay consistent with it. Directly wrapping a C library allows better control over this. The event model of a language server is quite simple, with one-to-one connections. Handling IO-related requests in the main thread and delegating time-consuming tasks to a thread pool is entirely sufficient. In this model, no synchronization primitives like locks are needed for inter-thread communication. Thus, the model of general network libraries is overly complex for clice. Finally, I successfully replicated the asynchronous programming experience similar to Python and JS in C++, which was very pleasant and straightforward.\nHow It Works # Next, let\u0026rsquo;s discuss in detail how clice handles certain specific requests.\nWhen a user opens or updates a file in the editor, the editor sends a notification to clice. Upon receiving the request, clice parses the file. More specifically, it parses the file into an AST (Abstract Syntax Tree). Given the complexity of C++ syntax, writing a parser from scratch is impractical. Like clangd, we chose to use Clang\u0026rsquo;s provided interfaces to parse source files.\nAfter obtaining the AST, we traverse it to collect information of interest. Take SemanticTokens as an example: we need to traverse the AST to add semantic information to each token in the source code—whether it\u0026rsquo;s a variable, function, const, static, etc. All this information can be extracted from the AST. For a deeper understanding, you can read an introductory article I wrote about Clang\u0026rsquo;s AST.\nMost requests can be implemented similarly. Code completion (CodeCompletion) and signature help (SignatureHelper) are more special. Since the syntax at the completion point may be incomplete, in the regular compilation process, if a syntax node is incomplete, Clang might treat it as an error node, discard it entirely, or even terminate compilation with a fatal error. None of these outcomes are acceptable for us. Generally, to implement code completion, the parser needs special handling. Clang is no exception; it provides a special code completion mode, where you inherit CodeCompleteConsumer and override relevant methods to obtain the necessary information.\nYou can experience this functionality with a special compilation option:\n-std=c++20 -fsyntax-only -Xclang -code-completion-at=\u0026#34;example.cpp:1:3\u0026#34; Assuming the source file is:\ncon The expected output is:\nCOMPLETION: const COMPLETION: consteval COMPLETION: constexpr COMPLETION: constinit As you can see, the result is the completion of four C++ keywords, with no errors or warnings.\nYes, that\u0026rsquo;s the entire process. It sounds quite simple, doesn\u0026rsquo;t it? Indeed, the logic for traversing the AST is quite clear. However, there are many corner cases to consider, and it will take time to implement features\n","date":"18 December 2024","externalUrl":null,"permalink":"/en/articles/13394352064/","section":"Articles","summary":"\u003cp\u003eIt has been several months since the last blog post. The reason for the long hiatus is that I have been busy working on \u003ca href=\"https://github.com/clice-project/clice\" target=\"_blank\"\u003eclice\u003c/a\u003e — a brand-new C++ language server.\u003c/p\u003e","title":"Design and Implementation of a New C++ Language Server","type":"articles"},{"content":"","date":"18 December 2024","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"18 December 2024","externalUrl":null,"permalink":"/en/","section":"ykiko's blog","summary":"","title":"ykiko's blog","type":"page"},{"content":"Due to a series of coincidences, I had the opportunity to attend last week\u0026rsquo;s WG21 meeting (the C++ Standards Committee meeting). Although I frequently browse new proposals for the C++ standard, I never imagined that one day I would actually participate in a WG21 meeting and get real-time updates on the latest developments in the C++ standard. Of course, this was my first time attending, and I was very excited. Here, I’ll document my impressions and the progress of the meeting.\nThe Backstory # The story began in January of this year when I was pondering how to write an efficient small_vector. I referred to the LLVM source code and found that it specialized implementations for types that are trivially destructible, using bitwise copy for operations like expansion. At the time, I didn’t understand why this was possible. Later, I learned about the concept of trivially copyable and further delved into the concept of relocatable. After reading several related proposals, I wrote this article discussing trivially relocatable.\nA few days later, a friend of mine, blueloveTH, asked if I could help write a lightweight small_vector for his project. This project is pocketpy, a lightweight Python interpreter. I thought, what a coincidence! I had just researched this topic a few days prior, so I spent a few hours writing a very lightweight small_vector that supports trivially relocatable optimizations. Coincidentally, this project is also the one I applied to participate in for this year’s GSoC.\nOn May 1st, I received two emails: one from the GSoC committee informing me that my application had been accepted, and the other from Arthur O\u0026rsquo;Dwyer, the author of P1144 (trivially relocatable). I was puzzled at first—why would he suddenly email me? We didn’t know each other. It turned out that he periodically searches for C++ projects related to trivially relocatable on GitHub and exchanges ideas with the authors. He found the code in pocketpy and thus sent us an email. He also seemed to have found my personal blog post discussing trivially relocatable here. We initially exchanged a few emails and later discussed some content of the proposal on Slack.\nAt the end of our discussion, he invited me to attend this WG21 meeting. The reason was that the current state of trivially relocatable in C++ is such that the committee is considering adopting an unreliable proposal, P2786, instead of the more comprehensive P1144. Arthur O\u0026rsquo;Dwyer hoped that supporters of P1144 could express their approval. Later, I sent an email to ISO applying to participate as a guest (guest) online. After three weeks without a reply, I almost thought I wouldn’t be able to attend. However, three days before the meeting, Herb Sutter finally replied, saying that he thought all emails had been replied to, but somehow mine was missed. He then informed me that my application had been approved and welcomed me to the meeting.\nThere was a small hiccup here. During the opening event, Herb Sutter was counting the number of participating countries. The method was to call out each country one by one, and if someone was participating, they would raise their hand. When he called out China, I was a bit excited and couldn’t find the hand-raising button. Finally, when he noticed no one raised their hand, he mentioned that he remembered there was a Chinese participant in this meeting.\nHow the C++ Standard Evolves # To make it easier to introduce the meeting progress later, let me briefly explain how the C++ committee operates.\nC++ has 23 study groups, SG1 to SG23, each responsible for discussing different topics. For example, compile-time metaprogramming is discussed by SG7.\nAfter a proposal is discussed and passed by a study group, depending on whether it pertains to language features or standard library features, it is reviewed by EWG (Evolution Working Group) or LEWG (Library Evolution Working Group). If approved, it is then submitted to CWG (Core Working Group) or LWG (Library Working Group) to refine the wording of the proposal so that it can be incorporated into the C++ standard.\nFinally, proposals that pass CWG or LWG are voted on in a plenary session. If the vote passes, they are officially added to the C++ standard.\nThe process of this St. Louis meeting was as follows: the opening event was on Monday morning. In the afternoon, each study group began discussing their respective agendas simultaneously. I mainly stayed in the EWG meeting room. Guests could participate in group voting but not in the final plenary session voting.\nMeeting Progress # First, let’s briefly discuss the proposals that were confirmed to pass, and then talk about the current progress of some important proposals.\nPassed Proposals # In terms of core language, the following proposals were passed:\nconstexpr placement new supports directly using placement new to call object constructors during constant evaluation. Previously, only std::construct_at could be used, which is a specialized version of placement new with parentheses. For a detailed discussion on this, you can read my blog on the history of constexpr development. deleting a pointer to an incomplete type should be ill-formed Now, deleting a pointer to an incomplete type will result in a compilation error instead of undefined behavior. ordering of constraints involving fold expressions clarifies the partial ordering rules for constraints involving fold expressions. structured binding declaration as a condition Structured bindings can now be used in the condition of an if statement. In terms of the standard library, the following proposals were passed:\ninplace_vector Note that inplace_vector is different from small_vector; the latter performs dynamic memory allocation when the SBO capacity is insufficient, while the former does not. It is equivalent to a dynamic array and can be conveniently used as a buffer. std::is_virtual_base_of Used to determine if a class is a virtual base class of another class. std::optional range support Supports range operations for optional. std::execution The long-debated std::execution has finally been included in the standard. Proposals with Significant Progress # I spent most of my time in the EWG meeting room, so I’ll mainly discuss some progress in core language aspects.\nOn Monday afternoon and all day Tuesday, EWG discussed Contracts. Compared to the last Tokyo meeting, some consensus was reached on certain disputes regarding Contracts, but there are still unresolved issues. Personally, I think the hope of including it in C++26 is still slim.\nOn Wednesday morning, EWG discussed Reflection for C++26. It was passed with 0 votes against (including my super favor vote) and handed over to CWG for wording revisions to be included in the C++ standard. On Thursday and Friday, CWG reviewed part of the content, but the proposal is too extensive and wasn’t fully reviewed. If everything goes smoothly, it is expected to be officially added to C++26 in two to three more meetings. The voting results show that everyone believes C++ needs reflection, and reflection is very likely to be included in C++26.\nOn Friday morning, EWG mainly discussed trivially relocatable. In previous meetings, P2786 had already passed EWG voting and was handed over to CWG. However, it is not perfect and has many issues. Including such a proposal in the standard would undoubtedly be detrimental to the development of C++. Since the last Tokyo meeting, several new proposals discussing trivially relocatable have emerged:\nIssues with P2786 Please reject P2786 and adopt P1144 Analysis of interaction between relocation, assignment, and swap Clearly, they all pointed fingers at P2786. After the authors of these proposals presented, a vote was needed to decide whether to return P2786 from CWG back to EWG, essentially reconsidering the trivially relocatable model that C++26 would adopt. In the end, P2786 was returned to EWG with an overwhelming majority. Of course, I voted super favor, as this was the main reason I attended this meeting. As for P1144, it might have to wait until the next meeting, as it wasn’t discussed this time.\nThe rest are some minor proposal progresses. Notably, many proposals related to constexpr passed EWG, including:\nLess transient constexpr allocation Allowing exception throwing in constant-evaluation Emitting messages at compile time However, it’s still uncertain how likely they are to pass CWG. If you’re interested in the latest progress of a specific proposal, you can search for the proposal number in the ISO C++ GitHub issues, where the latest progress of each proposal is recorded in detail.\nSome Personal Reflections # Now that the meeting progress is covered, let me share some personal reflections.\nFirst, regarding the trivially relocatable vote, after voting, I suddenly felt a sense of guilt. The reason was that before the final vote, the author of P2786 said:\nIf other people want to make modifications and bring forward their own paper, you know, as an author, I am not going to say, \u0026lsquo;No, don\u0026rsquo;t; it\u0026rsquo;s my paper.\u0026rsquo; If it\u0026rsquo;s a good change, you know, that\u0026rsquo;s good.\nI could clearly hear the emotion in his voice when he said this. Putting myself in his shoes, I can understand his feelings. He must have poured a lot of effort into this proposal, and having it withdrawn in such an unceremonious manner is hard to accept. But in reality, the author of P1144 has invested even more effort, with the proposal already at version R11, and the content itself is more comprehensive, yet it has been consistently overlooked. I find it hard to understand why this situation has arisen.\nAnother point is about the plenary session voting. The proposal Structured Bindings can introduce a Pack, which supports introducing parameter packs in structured bindings:\nauto [x, ...pack] = std::tuple{1, 2, 3, 4}; It had already passed CWG, but during the plenary session, a compiler vendor pointed out that some examples in the wording of the proposal’s reference implementation could cause the compiler to crash. As a result, the plenary session vote did not pass.\nA similar situation occurred with std::execution. Before the plenary session vote, someone pointed out that std::execution should not be included in C++26, as it is overly complex and not mature enough. The authors were merely theorizing without considering practical application scenarios. Additionally, heavy use of templates leads to very slow compilation speeds and frequent internal compiler errors. Although the final vote result was more in favor than against, the C++ committee emphasizes consensus rather than majority rule. A certain proportion must be reached for a proposal to pass, so theoretically, this proposal should not have passed this meeting. However, due to certain reasons, it was ultimately passed. I didn’t pay close attention to the specifics, so I can’t say for sure.\nHonestly, attending this meeting didn’t yield much in terms of knowledge, but it did broaden my horizons. Some debates felt no different from online arguments. From each side’s perspective, both viewpoints are correct, which is reasonable. Not everything has a clear right or wrong, and many problems don’t have perfect solutions, especially in software engineering. To be included in the standard, compromises must be made. Where to compromise and who compromises to whom often involves intense debates and sometimes even factors outside the issue itself.\nIf I have the opportunity in the future, I might attend again, preferably in person. However, I definitely won’t attend every single meeting punctually like I did this time (it was my first time, so I was excited). I might mainly focus on the parts I’m interested in. I’m really looking forward to seeing reflection included in C++26.\nThat’s it for this article. Thank you for reading.\n","date":"2 July 2024","externalUrl":null,"permalink":"/en/articles/706509748/","section":"Articles","summary":"\u003cp\u003eDue to a series of coincidences, I had the opportunity to attend last week\u0026rsquo;s WG21 meeting (the C++ Standards Committee meeting). Although I frequently browse new proposals for the C++ standard, I never imagined that one day I would actually participate in a WG21 meeting and get real-time updates on the latest developments in the C++ standard. Of course, this was my first time attending, and I was very excited. Here, I’ll document my impressions and the progress of the meeting.\u003c/p\u003e","title":"Recap of the St. Louis WG21 Meeting","type":"articles"},{"content":"I participated in Google Summer of Code 2024, where my main task was to implement a pybind11 compatibility interface for a Python interpreter. While it\u0026rsquo;s called implementing a compatibility interface, it essentially amounts to rewriting pybind11, so I\u0026rsquo;ve been diving deep into its source code recently.\nFor readers who might not be familiar with pybind11, it is essentially a middleware that facilitates seamless interaction between Python and C++ code. For instance, embedding a Python interpreter within C++ or compiling C++ code into a dynamic library for Python to call. For more details, please refer to the official documentation.\nI\u0026rsquo;ve recently managed to grasp the overall operational logic of the framework. Looking back, pybind11 truly lives up to its reputation as the de facto standard for binding C++ and Python, with many ingenious designs. Its interaction logic can also be applied to interactions between C++ and other GC languages, such as JS and C# (though there are no equivalents like jsbind11 or csharpbind11 yet). I might write a series of articles on this topic, stripping away some of the intricate details to introduce some of the shared concepts.\nThis article mainly discusses some interesting points about object design in pybind11.\nPyObject # We all know that in Python, everything is an object, all instances of object. However, pybind11 actually needs to interact with specific implementations of Python like CPython. So, how is \u0026ldquo;everything is an object\u0026rdquo; reflected in CPython? The answer is PyObject*. Let\u0026rsquo;s \u0026ldquo;see\u0026rdquo; Python and understand how actual Python code operates within CPython.\nCreating an object essentially means creating a PyObject*.\nx = [1, 2, 3] CPython has specific APIs to create objects of built-in types. The above statement would roughly translate to:\nPyObject* x = PyList_New(3); PyList_SetItem(x, 0, PyLong_FromLong(1)); PyList_SetItem(x, 1, PyLong_FromLong(2)); PyList_SetItem(x, 2, PyLong_FromLong(3)); Thus, the role of is becomes clear—it checks whether the values of two pointers are the same. The reason for the default shallow copy is that the default assignment is merely a pointer assignment, not involving the elements it points to.\nCPython also provides a series of APIs to manipulate the objects pointed to by PyObject*, such as:\nPyObject* PyObject_CallObject(PyObject *callable_object, PyObject *args); PyObject* PyObject_CallFunction(PyObject *callable_object, const char *format, ...); PyObject* PyObject_CallMethod(PyObject *o, const char *method, const char *format, ...); PyObject* PyObject_CallFunctionObjArgs(PyObject *callable, ...); PyObject* PyObject_CallMethodObjArgs(PyObject *o, PyObject *name, ...); PyObject* PyObject_GetAttrString(PyObject *o, const char *attr_name); PyObject* PyObject_SetAttrString(PyObject *o, const char *attr_name, PyObject *v); int PyObject_HasAttrString(PyObject *o, const char *attr_name); PyObject* PyObject_GetAttr(PyObject *o, PyObject *attr_name); int PyObject_SetAttr(PyObject *o, PyObject *attr_name, PyObject *v); int PyObject_HasAttr(PyObject *o, PyObject *attr_name); PyObject* PyObject_GetItem(PyObject *o, PyObject *key); int PyObject_SetItem(PyObject *o, PyObject *key, PyObject *v); int PyObject_DelItem(PyObject *o, PyObject *key); These functions generally have direct counterparts in Python, and their purposes are evident from their names.\nhandle # Since pybind11 needs to support manipulating Python objects in C++, its primary task is to encapsulate these C-style APIs. This is specifically achieved by the handle type. handle is a simple wrapper around PyObject* and encapsulates some member functions, such as:\nRoughly like this:\nclass handle { protected: PyObject* m_ptr; public: handle(PyObject* ptr) : m_ptr(ptr) {} friend bool operator==(const handle\u0026amp; lhs, const handle\u0026amp; rhs) { return PyObject_RichCompareBool(lhs.m_ptr, rhs.m_ptr, Py_EQ); } friend bool operator!=(const handle\u0026amp; lhs, const handle\u0026amp; rhs) { return PyObject_RichCompareBool(lhs.m_ptr, rhs.m_ptr, Py_NE); } // ... }; Most functions are simply wrapped like above, but some functions are special.\nget/set # According to Bjarne Stroustrup, the father of C++, in \u0026ldquo;The Design and Evolution of C++\u0026rdquo;, part of the reason for introducing reference (lvalue) types was to allow users to assign to return values, making the overloading of operators like [] more natural. For example:\nstd::vector\u0026lt;int\u0026gt; v = {1, 2, 3}; int x = v[0]; // get v[0] = 4; // set Without references, one would have to return pointers, and the above code would have to be written as:\nstd::vector\u0026lt;int\u0026gt; v = {1, 2, 3}; int x = *v[0]; // get *v[0] = 4; // set In comparison, using references is much more aesthetically pleasing, isn\u0026rsquo;t it? This issue exists in other programming languages as well, but not all languages adopt this solution. For example, Rust chooses automatic dereferencing, where the compiler automatically adds * to dereference at appropriate times, thus eliminating the need to write the extra *. However, neither of these methods works for Python because Python doesn\u0026rsquo;t have the concept of dereferencing, nor does it distinguish between lvalues and rvalues. So, what\u0026rsquo;s the solution? The answer is to distinguish between getter and setter.\nFor example, to overload []:\nclass List: def __getitem__(self, key): print(\u0026#34;__getitem__\u0026#34;) return 1 def __setitem__(self, key, value): print(\u0026#34;__setitem__\u0026#34;) a = List() x = a[0] # __getitem__ a[0] = 1 # __setitem__ Python checks the syntactic structure; if [] appears on the left side of =, it calls __setitem__; otherwise, it calls __getitem__. Actually, many languages adopt similar designs, such as C#\u0026rsquo;s this[] operator overloading.\nEven the . operator can be overloaded by overriding __getattr__ and __setattr__:\nclass Point: def __getattr__(self, key): print(f\u0026#34;__getattr__\u0026#34;) return 1 def __setattr__(self, key, value): print(f\u0026#34;__setattr__\u0026#34;) p = Point() x = p.x # __getattr__ p.x = 1 # __setattr__ pybind11 aims for the handle to achieve similar effects, calling __getitem__ and __setitem__ at appropriate times. For example:\npy::handle obj = py::list(1, 2, 3); obj[0] = 4; // __setitem__ auto x = obj[0]; // __getitem__ x = py::int_(1); The corresponding Python code is:\nobj = [1, 2, 3] obj[0] = 4 x = obj[0] x = 1 accessor # Next, let\u0026rsquo;s focus on how to achieve this effect. First, consider the return value of operator[]. Since it might need to call __setitem__, we return a proxy object here. It stores the key for subsequent calls.\nclass accessor { handle m_obj; ssize_t m_key; handle m_value; public: accessor(handle obj, ssize_t key) : m_obj(obj), m_key(key) { m_value = PyObject_GetItem(obj.ptr(), key); } }; The next question is how to distinguish between obj[0] = 4 and x = int_(1), so that the former calls __setitem__ and the latter is a simple assignment to x. Notice the key difference between the two scenarios: lvalue and rvalue.\nobj[0] = 4; // assign to rvalue auto x = obj[0]; x = 1; // assign to lvalue How can operator= call different functions based on the value category of the operand? This requires a relatively rare trick. We all know that we can add a const qualifier to a member function to allow it to be called on const objects.\nstruct A { void foo() {} void bar() const {} }; int main() { const A a; a.foo(); // error a.bar(); // ok } In addition, we can also add reference qualifiers \u0026amp; and \u0026amp;\u0026amp;, which require expr.f() to be an lvalue or rvalue, respectively. This allows us to call different functions based on whether the expression is an lvalue or rvalue.\nstruct A { void foo() \u0026amp; {} void bar() \u0026amp;\u0026amp; {} }; int main() { A a; a.foo(); // ok a.bar(); // error A().bar(); // ok A().foo(); // error } Using this feature, we can achieve the desired effect.\nclass accessor { handle m_obj; ssize_t m_key; handle m_value; public: accessor(handle obj, ssize_t key) : m_obj(obj), m_key(key) { m_value = PyObject_GetItem(obj.ptr(), key); } // assign to rvalue void operator=(handle value) \u0026amp;\u0026amp; { PyObject_SetItem(m_obj.ptr(), m_key, value.ptr()); } // assign to lvalue void operator=(handle value) \u0026amp; { m_value = value; } }; lazy evaluation # Going further, we want this proxy object to behave just like a handle, able to use all methods of handle. This is simple; just inherit from handle.\nclass accessor : public handle { handle m_obj; ssize_t m_key; public: accessor(handle obj, ssize_t key) : m_obj(obj), m_key(key) { m_ptr = PyObject_GetItem(obj.ptr(), key); } // assign to rvalue void operator=(handle value) \u0026amp;\u0026amp; { PyObject_SetItem(m_ptr, m_key, value.ptr()); } // assign to lvalue void operator=(handle value) \u0026amp; { m_ptr = value; } }; At this point, it seems we\u0026rsquo;re done. However, note that our __getitem__ is called in the constructor, meaning that even if the fetched value isn\u0026rsquo;t used later, it will still be called. There seems to be room for further optimization. Can we somehow lazy-evaluate this, only calling __getitem__ when we need to call these functions within handle?\nCurrently, directly inheriting from handle certainly won\u0026rsquo;t work. It\u0026rsquo;s impossible to insert a check before every member function call to decide whether to call __getitem__. We can have both handle and accessor inherit from a base class, which has an interface to actually get the pointer to operate on.\nclass object_api{ public: virtual PyObject* get() = 0; bool operator==(const handle\u0026amp; rhs) { return PyObject_RichCompareBool(get(), rhs.ptr(), Py_EQ); } // ... }; Then, both handle and accessor inherit from this base class. Now, accessor can perform lazy evaluation of __getitem__ here.\nclass handle : public object_api { PyObject* get() override { return m_ptr; } }; class accessor : public handle { PyObject* get() override { if (!m_ptr) { m_ptr = PyObject_GetItem(m_obj.ptr(), m_key); } return m_ptr; } }; This doesn\u0026rsquo;t involve type erasure; it just requires subclasses to expose an interface. Naturally, we can use CRTP to devirtualize.\ntemplate \u0026lt;typename Derived\u0026gt; class object_api { public: PyObject* get() { return static_cast\u0026lt;Derived*\u0026gt;(this)-\u0026gt;get(); } bool operator==(const handle\u0026amp; rhs) { return PyObject_RichCompareBool(get(), rhs.ptr(), Py_EQ); } // ... }; class handle : public object_api\u0026lt;handle\u0026gt; { PyObject* get() { return m_ptr; } }; class accessor : public object_api\u0026lt;accessor\u0026gt; { PyObject* get() { if (!m_ptr) { m_ptr = PyObject_GetItem(m_obj.ptr(), m_key); } return m_ptr; } }; Thus, we\u0026rsquo;ve lazy-evaluated the call to __getitem__ without introducing additional runtime overhead.\nConclusion # We often say that C++ is too complex, with a dazzling array of features that often conflict with each other. But from another perspective, having many features means users have more choices, more design space, and can assemble brilliant designs like the one above. It\u0026rsquo;s hard to imagine another language achieving such effects. Perhaps this is the charm of C++.\nThis concludes the article. Thank you for reading, and feel free to discuss in the comments.\n","date":"7 June 2024","externalUrl":null,"permalink":"/en/articles/702197261/","section":"Articles","summary":"\u003cp\u003eI participated in \u003ca href=\"https://summerofcode.withgoogle.com/programs/2024/projects/Ji2Mi97o\" target=\"_blank\"\u003eGoogle Summer of Code 2024\u003c/a\u003e, where my main task was to implement a \u003ca href=\"https://github.com/pybind/pybind11\" target=\"_blank\"\u003epybind11\u003c/a\u003e compatibility interface for a \u003ca href=\"https://pocketpy.dev/\" target=\"_blank\"\u003ePython interpreter\u003c/a\u003e. While it\u0026rsquo;s called implementing a compatibility interface, it essentially amounts to rewriting pybind11, so I\u0026rsquo;ve been diving deep into its source code recently.\u003c/p\u003e","title":"The Perfect Integration of Python and C++: Object Design in pybind11","type":"articles"},{"content":"Singleton Pattern is a common design pattern often used in scenarios requiring object uniqueness, such as configuration systems, logging systems, and database connection pools. But does the Singleton Pattern truly guarantee a singleton? What consequences might arise if uniqueness is not ensured?\nSince this article is written, the answer is clearly no. There have been many discussions on Zhihu, such as Does the C++ Singleton Pattern across DLLs cause issues? and Singleton Pattern BUG in Mixed Use of Dynamic and Static Libraries. However, most of these discussions only provide solutions after encountering problems, which are scattered and lack systematic analysis of the root causes. Therefore, I wrote this article to delve into this issue in detail.\nClarifying the Problem # First, we need to clarify the problem under discussion. Taking a common C++11 Singleton Pattern implementation as an example:\nclass Singleton { public: Singleton(const Singleton\u0026amp;) = delete; Singleton\u0026amp; operator=(const Singleton\u0026amp;) = delete; static Singleton\u0026amp; instance() { static Singleton instance; return instance; } private: Singleton() = default; }; We set the default constructor to private and explicitly delete the copy constructor and assignment operator, ensuring users can only obtain the pre-created object through the instance function and cannot create an object themselves via the constructor. Using a static local variable ensures thread safety during initialization.\nHowever, a singleton object is essentially no different from a regular global variable. In C++, both have static storage duration, and the compiler treats them similarly (with some differences in initialization). The Singleton Pattern merely uses language-level techniques to prevent users from accidentally creating multiple objects.\nThus, the problem we are discussing can be equated to: Are global variables in C++ unique?\nA Definition # First, we need to distinguish between variable declaration and definition. We know that variable definitions generally cannot be written in header files. Otherwise, if the header file is included by multiple source files, multiple definitions will result, causing a multiple definition of variable error during linking. Therefore, we usually declare variables in header files using extern and define them in the corresponding source files.\nHow does the compiler handle global variable definitions?\nSuppose we define a global variable:\nint x = 1; This does not generate any instructions. The compiler adds a symbol x to the symbol table of the compilation unit (each source file). It reserves 4 bytes of space in static storage (possibly in the bss segment or rdata segment, etc.) for the symbol x. Depending on the initialization method (static initialization or dynamic initialization), the data in this memory is filled accordingly.\nSince there is only one definition, this case is certainly globally unique.\nMultiple Definitions # We know that C++ does not have an official build system. Different libraries use different build systems, making them inconvenient to use together (currently, cmake is the de facto standard). This situation has led to the increasing popularity of header-only libraries, which are easy to use by simply including them. But header-only means all code is written in header files. How can variables be defined in header files and directly included by multiple source files without causing linking errors?\nBefore C++17, there was no direct way. However, there were indirect methods. Considering that inline functions or template function definitions can appear in multiple source files, and the C++ standard guarantees they have the same address (related discussions can be found in Where Does C++ Code Bloat Occur?). Thus, defining static local variables within these functions effectively allows variable definitions in header files:\ninline int\u0026amp; x() { static int x = 1; return x; } template\u0026lt;typename T = void\u0026gt; int\u0026amp; y() { static int y = 1; return y; } After C++17, we can directly use inline to mark variables, allowing their definitions to appear in multiple source files. Using this, we can directly define variables in header files:\ninline int x = 1; We know that marking a variable as static also allows its definition to appear in multiple source files. What is the difference between inline and static? The key difference is that static marked variables have internal linkage, with each compilation unit having its own instance, and addresses taken in different compilation units are different. In contrast, inline marked variables have external linkage, and the C++ standard guarantees that the address of the same inline variable taken in different compilation units is the same.\nTruly Singleton? # Practice is the sole criterion for testing truth. Let\u0026rsquo;s experiment to see if the C++ standard is truthful.\nSample code:\n// src.cpp #include \u0026lt;cstdio\u0026gt; inline int x = 1; void foo() { printf(\u0026#34;addreress of x in src: %p\\n\u0026#34;, \u0026amp;x); } // main.cpp #include \u0026lt;cstdio\u0026gt; inline int x = 1; extern void foo(); int main() { printf(\u0026#34;addreress of x in main: %p\\n\u0026#34;, \u0026amp;x); foo(); } First, compile these two source files into an executable and test on Windows (MSVC) and Linux (GCC):\n# Windows: addreress of x in main: 00007FF7CF84C000 addreress of x in src: 00007FF7CF84C000 # Linux: addreress of x in main: 0x404018 addreress of x in src: 0x404018 The addresses are indeed the same. Next, compile src.cpp into a dynamic library and link main.cpp to this library, then compile and run. Let\u0026rsquo;s see if, as many say, it fails when encountering dynamic libraries. Note that on Windows, foo must be explicitly marked with __declspec(dllexport), otherwise the dynamic library will not export this symbol.\n# Windows: addreress of x in main: 00007FF72F3FC000 addreress of x in src: 00007FFC4D91C000 # Linux: addreress of x in main: 0x404020 addreress of x in src: 0x404020 Oh no, why are the results different on Windows and Linux?\nSymbol Export # Initially, I thought it was simply due to the default symbol export rules of dynamic libraries. GCC exports all symbols by default when compiling dynamic libraries, while MSVC does the opposite, exporting no symbols by default, requiring manual export. Clearly, only when a symbol is exported can the linker \u0026ldquo;see\u0026rdquo; it and then merge symbols from different dynamic libraries.\nWith this in mind, I tried to find ways to customize symbol export on GCC and eventually found Visibility - GCC Wiki. Using -fvisibility=hidden during compilation makes symbols default to hidden (not exported). Then, use __attribute__((visibility(\u0026quot;default\u0026quot;))) or its C++ equivalent [[gnu::visibility(\u0026quot;default\u0026quot;)]] to explicitly mark symbols for export. Thus, I modified the code:\n// src.cpp #include \u0026lt;cstdio\u0026gt; inline int x = 1; [[gnu::visibility(\u0026#34;default\u0026#34;)]] void foo () { printf(\u0026#34;addreress of x in src: %p\\n\u0026#34;, \u0026amp;x); } // main.cpp #include \u0026lt;cstdio\u0026gt; inline int x = 1; extern void foo(); int main() { printf(\u0026#34;addreress of x in main: %p\\n\u0026#34;, \u0026amp;x); foo(); } Note, I only exported foo for function calls; neither inline variable was exported. Compile and run:\naddreress of x in main: 0x404020 addreress of x in src: 0x7f5a45513010 As expected, the addresses are different. This verifies that symbol export is a necessary condition for the linker to merge symbols, but not sufficient. If changing the default symbol export rules on Windows could make inline variables have the same address, sufficiency would be verified. Excitedly, I began to try, only to find things were not so simple.\nNoting that GCC on Windows (MinGW64 toolchain) still exports all symbols by default, the variable addresses should be the same. The result:\naddreress of x in main: 00007ff664a68130 addreress of x in src: 00007ffef4348110 The results are different. I didn\u0026rsquo;t understand and thought it was a compiler bug. Switching to MSVC, I found that CMake provides a CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS option, which automatically exports all symbols (via dumpbin). Trying this, compiling and running, the result:\naddreress of x in main: 00007FF60B11C000 addreress of x in src: 00007FFEF434C000 Oh, the results are still different. I realized my guess was wrong. After much research, I couldn\u0026rsquo;t find why. Later, I got the answer by asking in the C++ group on TG.\nSimply put, ELF does not distinguish which .so a symbol comes from; it uses the first loaded one, so multiple inline variables use the first loaded one. However, the PE file\u0026rsquo;s symbol table specifies which dll a symbol is imported from, meaning if a variable is dllexported, the dll will always use its own variable. Even if multiple dlls dllexport the same variable, they cannot be merged; the format of dlls on Windows inherently prevents this.\nThe issue of symbol resolution during dynamic library linking is actually much more complex, with many other scenarios, such as actively loading dynamic libraries via dlopen and other functions. If time permits, I may write a dedicated article to analyze this issue; for now, I won\u0026rsquo;t elaborate further.\nWhat If Not Unique? # Why ensure the uniqueness of \u0026ldquo;singleton\u0026rdquo; variables? Here, I use the C++ standard library as an example.\nWe know that type_info can distinguish different types at runtime, and the standard library\u0026rsquo;s std::function and std::any rely on it for type erasure. Its constructor and operator= are deleted, and we can only obtain the corresponding type_info object reference via typeid(T), with object creation handled by the compiler.\nDoesn\u0026rsquo;t this fully conform to the Singleton Pattern? The next question is, how does the compiler determine if two type_info objects are the same? A typical implementation is as follows:\n#if _PLATFORM_SUPPORTS_UNIQUE_TYPEINFO bool operator==(const type_info\u0026amp; __rhs) const { return __mangled_name == __rhs.__mangled_name; } #else bool operator==(const type_info\u0026amp; __rhs) const { return __mangled_name == __rhs.__mangled_name || strcmp(__mangled_name, __rhs.__mangled_name) == 0; } #endif The above code is straightforward. If type_info addresses are guaranteed unique, directly compare __mangled_name (it\u0026rsquo;s const char*, so pointer comparison). Otherwise, compare addresses first, then type names. Specific to the three major standard library implementations:\nlibstdc++ uses __GXX_MERGED_TYPEINFO_NAMES to control enabling. libc++ uses _LIBCPP_TYPEINFO_COMPARATION_IMPLEMENTATION to decide the approach (actually, there\u0026rsquo;s a special BIT_FLAG mode). msvc stl (crt/src/vcruntime/std_type_info.cpp) always uses the second method due to the aforementioned Windows dll limitations. The purpose of this example is to illustrate that the uniqueness of singleton variable addresses affects how we write code. If not unique, we might be forced to write defensive code, potentially impacting performance, and if not written, it could directly cause logical errors.\nSolutions # Merely raising problems is not enough; solutions are needed. How to ensure singleton uniqueness?\nOn Linux, it\u0026rsquo;s simple. If the same variable appears in multiple dynamic libraries, ensure all these dynamic libraries set this symbol to be externally visible. The compiler\u0026rsquo;s default behavior is external visibility, so this issue is generally not a concern.\nOn Windows, it\u0026rsquo;s more complicated. Ensure only one dll uses dllexport to export this symbol, and all other dlls must use dllimport. This is often tricky; you might forget which dll is responsible for exporting the symbol. What to do? Use a dedicated dll to manage all singleton variables, meaning this dll is responsible for dllexporting all singleton variables, while other dlls only dllimport. Adding and modifying variables are done in this dll, making management easier.\nThis concludes the article. Honestly, I\u0026rsquo;m not sure if the above discussion covers all scenarios. If there are errors, please leave a comment for discussion.\n","date":"10 May 2024","externalUrl":null,"permalink":"/en/articles/696878184/","section":"Articles","summary":"\u003cp\u003e\u003cstrong\u003eSingleton Pattern\u003c/strong\u003e is a common design pattern often used in scenarios requiring object uniqueness, such as configuration systems, logging systems, and database connection pools. But does the Singleton Pattern truly guarantee a singleton? What consequences might arise if uniqueness is not ensured?\u003c/p\u003e","title":"Is the Singleton Pattern in C++ Truly \"Singleton\"?","type":"articles"},{"content":"Compiler Explorer is a highly popular online C++ compiler that can be used to test different compilation and execution environments or to share code. As a C++ enthusiast, I interact with it almost daily, far more frequently than I initially imagined. Additionally, I am a heavy VSCode user, handling almost all tasks within VSCode. Considering the frequent need to write code locally and then copy it to Compiler Explorer, it often feels cumbersome. Sometimes, I directly modify the code in its web editor, but without code completion, it\u0026rsquo;s equally uncomfortable. Therefore, in collaboration with @iiirhe, we developed this plugin Compiler Explorer for VSCode, which integrates Compiler Explorer into VSCode using the API provided by Compiler Explorer, allowing users to directly utilize Compiler Explorer\u0026rsquo;s functionalities within VSCode.\nNow you can search for this plugin in the VSCode marketplace.\nDemonstration # Single File Support # Let\u0026rsquo;s introduce from top to bottom.\nThe functions of these three buttons are as follows:\nCompile All: Compile all compiler instances. Add New: Add a new compiler instance. Share Link: Generate a link based on the current compiler instance and copy it to the clipboard. The functions of these four buttons are as follows:\nAdd CMake: Add a CMake compiler instance (details will be discussed later). Clear All: Close all displayed webview panels. Load Link: Load compiler instance information based on the input link. Remove All: Delete all compiler instances. The functions of these three buttons are as follows:\nRun: Compile this compiler instance. Clone: Clone this compiler instance. Remove: Delete this compiler instance. Below are the parameters for setting up the compiler instance:\nCompiler: Click the button on the right to select the compiler version. Input: Select the source code file, default is active, i.e., the currently active editor. Output: The file to output the compilation results, default uses webview. Options: Compilation options, click the button on the right to open the input box. Execute Arguments: Arguments passed to the executable. Stdin: Buffer for standard input. Filters: Some options. Multi-File Support # Using the Add CMake button, you can add a CMake compiler instance, which can be used to compile multiple files.\nMost options are the same as the single-file compiler instance, with two additional ones:\nCMake Arguments: Arguments passed to CMake. Source: The path to the folder containing CMakelists.txt. Note, since multi-file compilation requires uploading all used files to the server, we default to reading all files in the specified directory (regardless of the file extension), so please do not specify folders with too many files at this time. We may add options to allow users to filter out some files in the future, but not currently.\nSome User Settings # compiler-explorer.default.options: Default parameters when creating a compiler with the + sign.\n\u0026#34;compiler-explorer.default.options\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The default compiler configuration\u0026#34;, \u0026#34;default\u0026#34;: { \u0026#34;compiler\u0026#34;: \u0026#34;x86-64 gcc 13.2\u0026#34;, \u0026#34;language\u0026#34;: \u0026#34;c++\u0026#34;, \u0026#34;options\u0026#34;: \u0026#34;-std=c++17\u0026#34;, \u0026#34;exec\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stdin\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cmakeArgs\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;src\u0026#34;: \u0026#34;workspace\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;binaryObject\u0026#34;: false, \u0026#34;binary\u0026#34;: false, \u0026#34;execute\u0026#34;: false, \u0026#34;intel\u0026#34;: true, \u0026#34;demangle\u0026#34;: true, \u0026#34;labels\u0026#34;: true, \u0026#34;libraryCode\u0026#34;: true, \u0026#34;directives\u0026#34;: true, \u0026#34;commentOnly\u0026#34;: true, \u0026#34;trim\u0026#34;: false, \u0026#34;debugCalls\u0026#34;: false } } } compiler-explorer.default.color: Used to specify the color for highlighting assembly code.\n\u0026#34;compiler-explorer.default.color\u0026#34;:{ \u0026#34;symbol\u0026#34;: \u0026#34;#61AFEF\u0026#34;, \u0026#34;string\u0026#34;: \u0026#34;#98C379\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;#D19A66\u0026#34;, \u0026#34;register\u0026#34;: \u0026#34;#E5C07B\u0026#34;, \u0026#34;instruction\u0026#34;: \u0026#34;#C678DD\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;#7F848E\u0026#34;, \u0026#34;operator\u0026#34;: \u0026#34;#ABB2BF\u0026#34; } compiler-explorer.default.url: The default link loaded when opening the plugin, default is empty.\n\u0026#34;compiler-explorer.default.url\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;\u0026#34; } Feedback # This plugin is still in its early stages. If you encounter any issues during use or have any suggestions, please feel free to leave a message on GitHub for discussion. Or join the QQ group: 662499937.\nhttps://qm.qq.com/q/DiO6rvnbHi (QR code automatically recognized)\nAdditionally, the Output window may provide some useful information, so please pay attention to it.\n","date":"24 April 2024","externalUrl":null,"permalink":"/en/articles/694365783/","section":"Articles","summary":"\u003cp\u003e\u003ca href=\"https://godbolt.org/\" target=\"_blank\"\u003eCompiler Explorer\u003c/a\u003e is a highly popular online C++ compiler that can be used to test different compilation and execution environments or to share code. As a C++ enthusiast, I interact with it almost daily, far more frequently than I initially imagined. Additionally, I am a heavy VSCode user, handling almost all tasks within VSCode. Considering the frequent need to write code locally and then copy it to Compiler Explorer, it often feels cumbersome. Sometimes, I directly modify the code in its web editor, but without code completion, it\u0026rsquo;s equally uncomfortable. Therefore, in collaboration with \u003ca href=\"https://www.zhihu.com/people/32ffceca937677f7950b64e5186bb998\" target=\"_blank\"\u003e@iiirhe\u003c/a\u003e, we developed this plugin \u003ca href=\"https://marketplace.visualstudio.com/items?itemName=ykiko.vscode-compiler-explorer\" target=\"_blank\"\u003eCompiler Explorer for VSCode\u003c/a\u003e, which integrates Compiler Explorer into VSCode using the \u003ca href=\"https://github.com/compiler-explorer/compiler-explorer/blob/main/docs/API.md\" target=\"_blank\"\u003eAPI\u003c/a\u003e provided by Compiler Explorer, allowing users to directly utilize Compiler Explorer\u0026rsquo;s functionalities within VSCode.\u003c/p\u003e","title":"Super Useful C++ Online Compiler (VSCode Edition)","type":"articles"},{"content":"The Application Binary Interface, commonly referred to as ABI, is a concept that feels both familiar and alien. Familiar because it often comes up in discussions and articles, and sometimes we have to deal with compatibility issues it causes. Alien because if someone asks you what ABI is, you might find it hard to describe it in precise terms. Eventually, you might resort to quoting WIKI: ABI is the interface between two binary program modules. Is there a problem with this definition? Not really, as a general description, it suffices. But it feels somewhat hollow.\nThis situation is not uncommon in the field of Computer Science. The author previously wrote an article discussing reflection and encountered the same issue. At its core, CS is not a discipline that strives for rigor; many concepts lack strict definitions and are more about conventional wisdom. Therefore, instead of obsessing over definitions, let\u0026rsquo;s focus on practical aspects and explore what these so-called binary interfaces are and what factors affect their stability.\nCPU \u0026amp; OS # Ultimately, executable files run on specific CPUs and operating systems. If the CPU instruction sets differ, binary incompatibility is inevitable. For example, programs compiled for ARM cannot directly run on x64 processors (unless virtualization techniques are used). What if the instruction sets are compatible? For instance, x64 processors are compatible with x86 instruction sets. Can x86 programs run on x64 operating systems? This depends on the operating system, specifically factors like Object File Format, Data Representation, Function Calling Convention, and Runtime Library. These can be considered as ABI specifications at the operating system level. We\u0026rsquo;ll discuss the fourth point in a later section. Below, we\u0026rsquo;ll focus on the first three points using the x64 platform as an example.\nx64, x86-64, x86_64, AMD64, and Intel 64 all refer to the 64-bit version of the x86 instruction set.\nThere are mainly two sets of ABIs on the x64 platform:\nWindows x64 ABI for 64-bit Windows operating systems x86-64 System V ABI for 64-bit Linux and other UNIX-like operating systems Calling a function from a dynamic library can be simplified into three steps:\nParse the dynamic library in a specific format Look up the function address from the parsed result based on the symbol name Pass function parameters and call the function Object File Format # How to parse the dynamic library? This is where the ABI\u0026rsquo;s specification of the Object File Format comes into play. If you want to write a linker, the generated executable must comply with the format requirements of the target platform. Windows x64 uses the PE32+ format, a 64-bit version of the PE32 (Portable Executable 32-bit) format. System V ABI uses the ELF (Executable Linkable Format) format. By using parsing libraries like pe-parse and elfio, you can parse actual executable files to obtain the symbol table, which maps function names to their addresses.\nData Representation # After obtaining the function address, the next step is to call the function. Before calling, parameters need to be passed. Here, consistency in Data Representation is crucial. What does this mean?\nSuppose I compile the following file into a dynamic library:\nstruct X{ int a; int b; }; int foo(X x){ return x.a + x.b; } Later, the structure changes due to version upgrades, and the user code sees the structure definition as:\nstruct X{ int a; int b; int c; }; Then, the user tries to link the old version of the dynamic library and call the function:\nint main(){ int n = foo({1, 2, 3}); printf(\u0026#34;%d\\n\u0026#34;, n); } Will this succeed? Of course not. This error can be seen as a violation of the One Definition Rule (ODR), more examples of which will be discussed in later sections.\nThe above scenario involves user-initiated code changes leading to ODR violations. What if I don\u0026rsquo;t change the code? Can I ensure the stability of the structure layout? This is where the ABI\u0026rsquo;s Data Representation comes into play. For example, it specifies the size and alignment of basic types: Windows x64 specifies long as 32-bit, while System V specifies long as 64-bit. It also specifies the size and alignment of struct and union.\nNote that the C language standard does not specify ABI. For System V ABI, it primarily uses C language terminology and concepts, so it can be considered as providing an ABI for C. The Windows x64 ABI does not make a clear distinction between C and C++.\nFunction Calling Convention # Next, we come to function parameter passing. We know that a function is just a block of binary data. Executing a function means jumping to its entry address, executing the code, and then jumping back. Passing parameters simply means finding a place to store data so that it can be accessed before and after the call. Where can this data be stored? There are four main options:\nGlobal variables Heap Registers Stack Using global variables to pass parameters sounds magical, but in practice, we often turn frequently passed parameters into global variables, like config. However, not all parameters are suitable for global variables, especially when considering thread safety.\nUsing the heap to pass parameters also seems unconventional, but C++20\u0026rsquo;s stackless coroutines store coroutine states (function parameters, local variables) on the heap. However, for ordinary function calls, dynamic memory allocation for each parameter is a bit extravagant.\nTherefore, we mainly consider using registers and the stack for parameter passing. Having more options is usually good, but not here. If the caller decides to use registers to pass parameters, it stores the parameters in registers. But if the callee expects parameters to be passed via the stack, it retrieves data from the stack. This inconsistency can lead to reading garbage values, causing logical errors and program crashes.\nHow to ensure that the caller and callee agree on where to pass parameters? You might have guessed it: this is where the Function Calling Convention comes into play.\nSpecifically, the calling convention specifies:\nThe order of function parameter passing: left to right or right to left? How function parameters and return values are passed: via stack or registers? Which registers remain unchanged before and after the call? Who is responsible for cleaning up the stack frame: caller or callee? How to handle C\u0026rsquo;s variadic functions? ... In 32-bit programs, there are many calling conventions like __cdecl, __stdcall, __fastcall, __thiscall, etc., leading to significant compatibility issues. In 64-bit programs, this has largely been unified. There are mainly two calling conventions: those specified by Windows x64 ABI and x86-64 System V ABI (though they don\u0026rsquo;t have formal names). It\u0026rsquo;s important to note that function parameter passing is only related to the calling convention, not the code optimization level. You wouldn\u0026rsquo;t want code compiled with different optimization levels to fail to link and run together.\nDiscussing specific rules is somewhat boring, so interested readers can refer to the relevant sections of the documentation. Below, we\u0026rsquo;ll discuss some interesting topics.\nNote: The following discussions only apply when function calls actually occur. If a function is fully inlined, the parameter passing behavior does not occur. Currently, C++ code inlining mainly happens within the same compilation unit (single file). For cross-compilation unit code, LTO (Link Time Optimization) must be enabled. Cross-dynamic library code cannot currently be inlined.\nPassing structures smaller than 16 bytes by value is more efficient than by reference This has been a long-standing claim, but I never found evidence for it. Recently, while studying calling conventions, I found the reason. First, if the structure size is less than or equal to 8 bytes, it can be directly passed in a 64-bit register. Passing parameters via registers involves fewer memory accesses than passing by reference, making it more efficient. What about 16 bytes? System V ABI allows splitting a 16-byte structure into two 8-byte parts and passing them via registers. In this case, passing by value is indeed more efficient than passing by reference. Observe the following code:\n#include \u0026lt;cstdio\u0026gt; struct X { size_t x; size_t y; }; extern void f(X); extern void g(const X\u0026amp;); int main() { f({1, 2}); // pass by value g({1, 2}); // pass by reference } The generated assembly code is as follows:\nmain: sub rsp, 24 mov edi, 1 mov esi, 2 call f(X) movdqa xmm0, XMMWORD PTR .LC0[rip] mov rdi, rsp movaps XMMWORD PTR [rsp], xmm0 call g(X const\u0026amp;) xor eax, eax add rsp, 24 ret .LC0: .quad 1 .quad 2 System V ABI specifies that the first six integer parameters can be passed using rdi, rsi, rdx, rcx, r8, and r9 registers. Windows x64 ABI specifies that the first four integer parameters can be passed using rcx, rdx, r8, and r9 registers. If registers are exhausted, parameters are passed via the stack. Integer parameters include basic integer types like char, short, int, long, long long, and pointer types. Floating-point and SIMD parameters have dedicated registers, which we won\u0026rsquo;t delve into here.\nYou can see that 1 and 2 are passed to the f function via registers edi and esi, while g passes the address of a temporary variable to the g function. However, this is System V ABI. For Windows x64 ABI, if the structure size is greater than 8 bytes, it must be passed by reference. The same code compiled on Windows produces the following assembly:\nmain: sub rsp, 56 lea rcx, QWORD PTR [rsp+32] mov QWORD PTR [rsp+32], 1 mov QWORD PTR [rsp+40], 2 call void f(X) lea rcx, QWORD PTR [rsp+32] mov QWORD PTR [rsp+32], 1 mov QWORD PTR [rsp+40], 2 call void g(X const \u0026amp;) xor eax, eax add rsp, 56 ret 0 You can see that the code generated for both function calls is identical. This means that for Windows x64 ABI, structures larger than 8 bytes generate the same code whether passed by value or by reference.\nunique_ptr and raw_ptr are equally efficient I used to believe this firmly, thinking that unique_ptr is just a simple wrapper around raw pointers. However, after watching the thought-provoking talk There are no zero-cost abstractions at CPPCON, I realized I was mistaken. Here, we won\u0026rsquo;t discuss the additional overhead caused by exceptions (destructors requiring the compiler to generate additional stack frame cleanup code). Instead, we\u0026rsquo;ll focus on whether a C++ object (less than 8 bytes) can be passed via registers. For a completely trivial type, this is possible; it behaves almost exactly like a C structure. But what if it\u0026rsquo;s not trivial?\nFor example, if a custom copy constructor is defined, can it still be passed via registers? Logically, it cannot. Why? We know that C++ allows taking the address of function parameters. If the parameter is an integer passed via a register, where does the address come from? Let\u0026rsquo;s experiment:\n#include \u0026lt;cstdio\u0026gt; extern void f(int\u0026amp;); int g(int x) { f(x); return x; } The generated assembly is as follows:\ng(int): sub rsp, 24 mov DWORD PTR [rsp+12], edi lea rdi, [rsp+12] call f(int\u0026amp;) mov eax, DWORD PTR [rsp+12] add rsp, 24 ret You can see that the value in edi (used to pass the first integer parameter) is copied to the address rsp+12, which is on the stack. This address is then passed to f. This means that if a function parameter is passed via a register and its address is needed, the compiler copies the parameter to the stack. However, users cannot observe these copy operations because their copy constructors are trivial. Any optimization that does not affect the final execution result complies with the as-if rule.\nIf the object has a user-defined copy constructor, passing parameters via registers could lead to additional copy constructor calls, which users can observe. This is clearly unreasonable, so objects with custom copy constructors cannot be passed via registers. What about passing via the stack? Similar copy issues arise. Therefore, such objects must be passed by reference. Note that explicitly marking the copy constructor as delete also counts as a custom copy constructor.\nTherefore, for unique_ptr, it must be passed by reference, whether you write the function signature as void f(unique_ptr\u0026lt;int\u0026gt;) or void f(unique_ptr\u0026lt;int\u0026gt;\u0026amp;). The generated binary code for parameter passing is the same. However, raw pointers can be safely passed via registers. In conclusion, unique_ptr and raw pointers are not equally efficient.\nIn reality, the situation is more complex for non-trivial C++ objects. Interested readers can refer to the relevant sections of the ABI documentation. Additionally, whether the rules for passing C++ objects belong to the operating system\u0026rsquo;s ABI or the C++ compiler\u0026rsquo;s ABI is not entirely clear.\nC++ Standard # Finally, we\u0026rsquo;ve covered the operating system-level guarantees. Since this is low-level and involves a lot of assembly, readers unfamiliar with assembly might find it challenging. However, the following content is mostly assembly-free and can be read with ease.\nWe all know that the C++ standard does not explicitly specify ABI, but it does have some requirements for compiler implementations, such as:\nStructure member addresses increase in declaration order incrementally, ensuring that the compiler does not reorder structure members. Structures satisfying the Standard Layout constraints must be compatible with corresponding C structures. Structures satisfying the Trivially Copyable constraints can be copied using memmove or memcpy to create an identical new object. ... Additionally, as C++ continues to release new versions, will the same code compiled with new and old standards produce the same result (ignoring the impact of macros controlling C++ version conditional compilation)? This depends on the C++ standard\u0026rsquo;s guarantees for ABI compatibility. In fact, the C++ standard strives to ensure backward compatibility. This means that two pieces of code compiled with old and new standards should be identical.\nHowever, there are a few exceptions, such as (I could only find these; feel free to comment with more):\nC++17 made noexcept part of the function type, affecting the function\u0026rsquo;s mangling name. C++20 introduced no_unique_address, which MSVC still does not fully support due to ABI breakage. More often, new C++ versions introduce new language features with new ABIs without affecting old code. For example, C++23 introduced two new features:\nExplicit Object Parameter # Before C++23, there was no legal way to obtain the address of a member function. The only option was to obtain a member pointer (for more on member pointers, refer to this article):\nstruct X { void f(int); }; auto p = \u0026amp;X::f; // p is a pointer to member function of X // type of p is void (X::*)(int) To use a member function as a callback, you had to wrap it in a lambda expression:\nstruct X { void f(int); }; using Fn = void(*)(X*, int); Fn p = [](A* self, int x) { self-\u0026gt;f(x); }; This is cumbersome and unnecessary, and the wrapper could introduce additional function call overhead. This is somewhat a historical legacy issue. On 32-bit systems, member function calling conventions were special (the well-known thiscall), and C++ did not include calling convention details, leading to the creation of member function pointers. Old code cannot change for ABI compatibility, but new code can. C++23 introduced the explicit object parameter, allowing us to specify how this is passed, even by value:\nstruct X { // Here, `this` is just a marker to distinguish from old syntax void f(this X self, int x); // pass by value void g(this X\u0026amp; self, int x); // pass by reference }; Functions marked with explicit this can now have their addresses taken directly, just like ordinary functions:\nauto f = \u0026amp;X::f; // type of f is ","date":"17 April 2024","externalUrl":null,"permalink":"/en/articles/692886292/","section":"Articles","summary":"\u003cp\u003eThe Application Binary Interface, commonly referred to as ABI, is a concept that feels both familiar and alien. Familiar because it often comes up in discussions and articles, and sometimes we have to deal with compatibility issues it causes. Alien because if someone asks you what ABI is, you might find it hard to describe it in precise terms. Eventually, you might resort to quoting \u003ca href=\"https://en.wikipedia.org/wiki/Application_binary_interface\" target=\"_blank\"\u003eWIKI\u003c/a\u003e: ABI is the interface between two binary program modules. Is there a problem with this definition? Not really, as a general description, it suffices. But it feels somewhat hollow.\u003c/p\u003e","title":"Understanding C++ ABI in Depth","type":"articles"},{"content":"Readers often hear that C++ code suffers from severe binary bloat, but few can pinpoint the exact reasons. After some online research, it becomes clear that there are not many in-depth discussions on this topic. The statement seems more like a cliché, passed down through word of mouth, with few able to explain it thoroughly. Today, ykiko will take you on a journey to uncover the mysteries of C++ code bloat (^ω^)\nFirst, let\u0026rsquo;s discuss what code bloat actually means. If a function is heavily inlined, the resulting executable file will be larger compared to when it is not inlined. Does this count as bloat? I argue that it does not, as this is within our expectations and is considered normal behavior. Conversely, code bloat that is not within our expectations, theoretically avoidable but not eliminated due to current implementations, is what I call \u0026ldquo;true code bloat.\u0026rdquo; The bloat discussed later in this article refers to this type.\nDoes Marking Functions with inline Cause Bloat? # First, it\u0026rsquo;s important to clarify that the inline keyword in C++ has a specific semantic meaning: it allows a function to be defined in multiple source files. Functions marked with inline can be defined directly in header files, and even if they are included by multiple source files, it won\u0026rsquo;t cause linking errors. This facilitates the creation of header-only libraries.\nMultiple Instances # Since the function can be defined in multiple source files, does this mean each source file will have its own instance of the code, potentially leading to code bloat?\nConsider the following example, where the comments indicate the file names:\n// src1.cpp inline int add(int a, int b) { return a + b; } int g1(int a, int b) { return add(a, b); } // src2.cpp inline int add(int a, int b) { return a + b; } int g2(int a, int b){ return add(a, b); } // main.cpp #include \u0026lt;cstdio\u0026gt; extern int g1(int, int); extern int g2(int, int); int main() { return g1(1, 2) + g2(3, 4); } First, let\u0026rsquo;s compile the first two files without optimization to see if they each retain a copy of the add function.\n$ g++ -c src1.cpp -o src1.o $ g++ -c src2.cpp -o src2.o Now, let\u0026rsquo;s examine the symbol tables of these two files:\n$ objdump -d src1.o | c++filt $ objdump -d src2.o | c++filt For convenience, I\u0026rsquo;ll provide the corresponding links and screenshots from Godbolt, which omits many non-essential symbols for clarity.\nAs you can see, both source files retain their own instances of the add function. Now, let\u0026rsquo;s link them into an executable:\n$ g++ main.o src1.o src2.o -o main.exe $ objdump -d main.exe | c++filt The result is shown below:\nThe linker retains only one instance of the add function, so there is no additional code bloat. The C++ standard requires that inline functions have identical definitions across different translation units, so it doesn\u0026rsquo;t matter which instance is retained. But what if the definitions differ? This would violate the One Definition Rule (ODR), leading to undefined behavior. The specific instance retained may depend on the implementation or even the linking order. I might write a separate article on ODR violations in the future, so I won\u0026rsquo;t delve too deep here. Just know that the C++ standard guarantees that inline functions have identical definitions across translation units.\nFull Inlining # Earlier, I specifically emphasized compiling without optimization. What happens if we enable optimization? Using the same code, let\u0026rsquo;s try compiling with -O2 optimization. The result is shown below:\nSurprisingly, with -O2 optimization, the add function is completely inlined. The compiler doesn\u0026rsquo;t even generate a symbol for add, so there\u0026rsquo;s nothing to link. According to our earlier definition, this type of function inlining doesn\u0026rsquo;t count as code bloat, so there\u0026rsquo;s no additional binary bloat.\nAs a side note, if neither file generates the add symbol, what happens if another file references add? Wouldn\u0026rsquo;t that cause a linking error?\nConsider the following code:\n// src1.cpp inline int add(int a, int b) { return a + b; } int g1(int a, int b) { return add(a, b); } // main.cpp inline int add(int a, int b); int main() { return g1(1, 2) + add(3, 4); } Compiling and linking this code without optimization works fine. However, with optimization enabled, the linker fails with undefined reference to add(int, int). All three major compilers behave this way, and the reason is as explained earlier: with optimization, the compiler doesn\u0026rsquo;t generate the add symbol, so it can\u0026rsquo;t be found during linking.\nBut is this behavior compliant with the C++ standard?\nSince all three major compilers behave this way, it seems compliant. However, the standard doesn\u0026rsquo;t explicitly state this in the inline section. In the One Definition Rule, there are two relevant points:\nFor an inline function or inline variable (since C++17), a definition is required in every translation unit where it is odr-used. A function is odr-used if a function call to it is made or its address is taken. What does this mean? It means that if an inline function is odr-used in a translation unit, that unit must have a definition of the function. What counts as odr-used? The second point explains that if a function is called or its address is taken, it is odr-used.\nIn our earlier code, main.cpp calls an inline function but doesn\u0026rsquo;t define it, which violates the C++ standard. This is a bit counterintuitive, but it\u0026rsquo;s the reality, and all three major compilers are correct!\nOther Cases # This section mainly discusses two scenarios:\nThe first is when an inline function has instances (generates symbols) in multiple translation units. In this case, mainstream linkers will retain only one instance, avoiding additional code bloat. The second scenario is when an inline function is fully inlined and no symbol is generated. This is similar to regular function inlining and doesn\u0026rsquo;t count as \u0026ldquo;additional overhead.\u0026rdquo; Some might think that C++ optimization rules are too complex. However, the core rule is the as-if principle: the compiler can perform any optimization as long as the resulting code behaves the same as the unoptimized version. Most compiler optimizations follow this principle, with only a few exceptions. The optimization of inline functions also adheres to this principle. If the address of an inline function isn\u0026rsquo;t explicitly taken, there\u0026rsquo;s no need to retain its symbol.\nAdditionally, while the inline keyword no longer enforces inlining at the standard level, it does provide a hint to the compiler that makes the function more likely to be inlined. How does this hint work? As mentioned earlier, the standard\u0026rsquo;s wording allows inline functions to avoid generating symbols. In contrast, functions without any specifier are marked as extern by default and must generate symbols. The compiler is more willing to inline functions that don\u0026rsquo;t need to generate symbols. From this perspective, you might guess that static has a similar hinting effect, and indeed it does. Of course, this is just one aspect; in reality, the decision to inline a function is much more complex.\nNote: This section only discusses functions marked with inline. There are also combinations like inline static and inline extern, which interested readers can explore in the official documentation or by experimenting.\nWhat Really Causes Template Code Bloat? # If someone gives a reason for C++ binary bloat, it\u0026rsquo;s almost always templates. Is this really the case? How exactly do templates cause binary bloat? Under what circumstances? Does using templates always cause bloat?\nImplicit Instantiation is Like inline # We know that template instantiation occurs in the current translation unit, and each instantiation generates a copy of the code. Consider the following example:\n// src1.cpp template \u0026lt;typename T\u0026gt; int add(T a, T b) { return a + b; } float g1() { return add(1, 2) + add(3.0, 4.0); } // src2.cpp template \u0026lt;typename T\u0026gt; int add(T a, T b) { return a + b; } float g2() { return add(1, 2) + add(3.0, 4.0); } // main.cpp extern float g1(); extern float g2(); int main() { return g1() + g2(); } Compile without optimization and check the compilation result:\nAs with inline functions, both translation units instantiate add\u0026lt;int, int\u0026gt; and add\u0026lt;double, double\u0026gt;, each with its own copy. During linking, the linker retains only one instance of each template instantiation. Now, let\u0026rsquo;s try compiling with -O2 and see what happens. The result is as follows:\nSimilar to inline functions, the compiler inlines the function and discards the symbols of the instantiated functions. In this case, either the function is inlined and no symbol is generated, or a symbol is generated and the function is merged during linking. Like inline functions, this doesn\u0026rsquo;t seem to cause additional bloat. So, where does the often-mentioned template bloat come from?\nExplicit Instantiation and extern Templates # Before discussing the real cause of bloat, let\u0026rsquo;s talk about explicit instantiation.\nAlthough the linker can merge multiple identical template instantiations, parsing the template definition, instantiating the template, generating the final binary code, and removing duplicate code during linking all take time. Sometimes, we know that only a few fixed template parameter instantiations are needed, such as with the standard library\u0026rsquo;s basic_string, which is almost always instantiated with a few fixed types. If every file that uses these types has to instantiate the template, it could significantly increase compilation time.\nCan we place the implementation in a single source file and have other files reference it, like with non-template functions? From the previous discussion, since symbols are generated, there should be a way to link to them. But how can we ensure that symbols are generated?\nThe answer is — explicit instantiation!\nWhat is explicit instantiation? Simply put, if you directly use a template without declaring specific types, and the compiler generates the declaration for you, it\u0026rsquo;s called implicit instantiation. Conversely, if you declare specific types beforehand, it\u0026rsquo;s called explicit instantiation. For function templates:\ntemplate \u0026lt;typename T\u0026gt; void f(T a, T b) { return a + b; } template void f\u0026lt;int\u0026gt;(int, int); // Explicit instantiation of f\u0026lt;int\u0026gt; definition void g() { f(1, 2); // Calls the explicitly instantiated f\u0026lt;int\u0026gt; f(1.0, 2.0); // Implicitly instantiates f\u0026lt;double\u0026gt; } This is quite straightforward, and explicit instantiation definitions will always generate symbols. Now, how do other files link to this explicitly instantiated function? There are two ways:\nOne is to explicitly instantiate a function declaration:\ntemplate \u0026lt;typename T\u0026gt; void f(T a, T b); template void f\u0026lt;int\u0026gt;(int, int); // Explicit instantiation of f\u0026lt;int\u0026gt; declaration The other is to use the extern keyword to instantiate a definition:\ntemplate \u0026lt;typename T\u0026gt; void f(T a, T b){ return a + b; } extern template void f\u0026lt;int\u0026gt;(int, int); // Explicit instantiation of f\u0026lt;int\u0026gt; declaration // Note: Without extern, this would explicitly instantiate a definition Both methods correctly reference the f function defined earlier, allowing calls to template instantiations in other files!\nThe Real Cause of Template Bloat # Now, let\u0026rsquo;s discuss the real cause of template bloat. Due to some historical reasons, in C++, char, unsigned char, and signed char are always distinct types:\nstatic_assert(!std::is_same_v\u0026lt;char, unsigned char\u0026gt;); static_assert(!std::is_same_v\u0026lt;char, signed char\u0026gt;); static_assert(!std::is_same_v\u0026lt;unsigned char, signed char\u0026gt;); However, in the compiler\u0026rsquo;s final implementation, char is either signed or unsigned. Suppose we write a template function:\ntemplate \u0026lt;typename T\u0026gt; void f(T a, T b){ return a + b; } void g() { f\u0026lt;char\u0026gt;(\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;); f\u0026lt;unsigned char\u0026gt;(\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;); f\u0026lt;signed char\u0026gt;(\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;); } Instantiating the template for these three types means that two of the instantiations will generate identical code. Will the compiler merge functions that have different types but generate identical binary code? Let\u0026rsquo;s try it out. The result is as follows:\nAs you can see, two identical functions are generated but not merged. Of course, if we enable -O2 optimization, such short functions will be inlined, and no symbols will be generated. As mentioned earlier, this means there\u0026rsquo;s no \u0026ldquo;additional template bloat.\u0026rdquo; In practice, many small template functions, like vector\u0026rsquo;s end, begin, and operator[], are likely to be fully inlined, avoiding \u0026ldquo;additional bloat.\u0026rdquo;\nNow, the question is: what if the function isn\u0026rsquo;t inlined? Suppose the template function is complex and has a large body. For demonstration purposes, we\u0026rsquo;ll use GCC\u0026rsquo;s [[gnu::noinline]] attribute to simulate this effect, then compile the code with -O2:\nEven though the function is optimized down to a single instruction, the compiler still generates three copies. In reality, functions that aren\u0026rsquo;t inlined by the compiler might be much larger, making the situation worse than this \u0026ldquo;pseudo-large function.\u0026rdquo; This is where the so-called \u0026ldquo;template bloat\u0026rdquo; comes from. Code that could be merged isn\u0026rsquo;t merged, and this is the real cause of template bloat.\nIf you really want the compiler/linker to merge identical binary code, what can you do? Unfortunately, mainstream toolchains like ld, lld, and MS linker don\u0026rsquo;t perform this merging. The only linker that supports this feature is gold, but it only works with ELF format executables, so it can\u0026rsquo;t be used on Windows. Here\u0026rsquo;s how to use gold to merge identical binary code:\n// main.cpp #include \u0026lt;cstdio\u0026gt; #include \u0026lt;utility\u0026gt; template \u0026lt;std::size_t I\u0026gt; struct X { std::size_t x; [[gnu::noinline]] void f() { printf(\u0026#34;X\u0026lt;%zu\u0026gt;::f() called\\n\u0026#34;, x); } }; template \u0026lt;std::size_t... Is\u0026gt; void call_f(std::index_sequence\u0026lt;Is...\u0026gt;) { ((X\u0026lt;Is\u0026gt;{Is}).f(), ...); } int main(int argc, char *argv[]) { call_f(std::make_index_sequence\u0026lt;100\u0026gt;{}); return 0; } Here, I generate 100 different types using templates, but in reality, they are all based on size_t, so the final compiled binary code is identical. Compile it with the following command:\n$ g++ -O2 -ffunction-sections -fuse-ld=gold -Wl,--icf=all main.cpp -o main.o $ objdump -d main.o | c++filt Using -fuse-ld=gold specifies the linker, and -Wl,--icf=all specifies the linker option. icf stands for \u0026ldquo;identical code folding,\u0026rdquo; which merges identical code. Since the linker works at the section level, GCC needs to enable -ffunction-sections. You can also replace GCC with Clang:\n0000000000000740 \u0026lt;X\u0026lt;99ul\u0026gt;::f() [clone .isra.0]\u0026gt;: 740: 48 89 fa mov %rdi,%rdx 743: 48 8d 35 1a 04 00 00 lea 0x41a(%rip),%rsi 74a: bf 01 00 00 00 mov $0x1,%edi 74f: 31 c0 xor %eax,%eax 751: e9 ca fe ff ff jmp 620 \u0026lt;_init+0x68\u0026gt; 756: 66 2e 0f 1f 84 00 00 cs nopw 0x0(%rax,%rax,1) 75d: 00 00 00 0000000000000760 \u0026lt;void call_f\u0026lt;0..99\u0026gt;(std::integer_sequence\u0026lt;unsigned long, 0..99\u0026gt;) ","date":"11 March 2024","externalUrl":null,"permalink":"/en/articles/686296374/","section":"Articles","summary":"\u003cp\u003eReaders often hear that C++ code suffers from severe binary bloat, but few can pinpoint the exact reasons. After some online research, it becomes clear that there are not many in-depth discussions on this topic. The statement seems more like a cliché, passed down through word of mouth, with few able to explain it thoroughly. Today, ykiko will take you on a journey to uncover the mysteries of C++ code bloat (^ω^)\u003c/p\u003e","title":"Where Exactly Does C++ Code Bloat Occur?","type":"articles"},{"content":"前情提要：C++中constexpr的历史！（第一部分）\n2015-2016：模板的语法糖 # 在C++中，支持全特化（full specialization）的模板很多，但支持偏特化（partial specialization）的模板并不多。事实上，只有类模板（class template）和变量模板（variable template）支持偏特化，而变量模板可以看作是类模板的语法糖，因此实际上只有类模板支持偏特化。不支持偏特化会导致某些代码难以编写。\n假设我们想实现一个destroy_at函数，其作用是调用对象的析构函数。特别地，如果析构函数是trivial的，我们就省去这次无意义的析构函数调用。\n直觉上，我们可以写出如下代码：\ntemplate\u0026lt;typename T, bool value = std::is_trivially_destructible_v\u0026lt;T\u0026gt;\u0026gt; void destroy_at(T* p) { p-\u0026gt;~T(); } template\u0026lt;typename T\u0026gt; void destroy_at\u0026lt;T, true\u0026gt;(T* p) {} 遗憾的是，clangd已经可以智能地提醒你：Function template partial specialization is not allowed。函数模板不能偏特化，那怎么办呢？当然，可以通过包装一层类模板来解决，但每次遇到这种情况都额外包装一层实在是让人难以接受。\n旧时代的做法是利用SFINAE来解决这个问题：\ntemplate\u0026lt;typename T, std::enable_if_t\u0026lt;(!std::is_trivially_destructible_v\u0026lt;T\u0026gt;)\u0026gt;* = nullptr\u0026gt; void destroy_at(T* p) { p-\u0026gt;~T(); } template\u0026lt;typename T, std::enable_if_t\u0026lt;std::is_trivially_destructible_v\u0026lt;T\u0026gt;\u0026gt;* = nullptr\u0026gt; void destroy_at(T* p) {} 具体的原理这里就不赘述了，虽然少了一层包装，但仍然有很多与代码逻辑无关的东西出现。这里的std::enable_if_t就是典型例子，严重影响了代码的可读性。\n提案N4461希望引入static_if（借鉴自D语言），用于在编译期控制代码生成，只会把实际用到的分支编译进最终的二进制代码。这样就可以写出如下代码，其中static_if的条件必须是常量表达式：\ntemplate\u0026lt;typename T\u0026gt; void destroy_at(T* p){ static_if(!std::is_trivially_destructible_v\u0026lt;T\u0026gt;){ p-\u0026gt;~T(); } } 可以发现逻辑非常清晰，但委员会一般对新增关键字比较谨慎。后来static_if被重命名为constexpr_if，再后来变成了我们今天熟悉的这种形式，并进入了C++17：\nif constexpr (...){...} else if constexpr (...){...} else {...} 巧妙地避免了新增关键字，C++委员会还真是喜欢关键字复用呢。\n2015：constexpr lambda # 提案N4487讨论了支持constexpr lambda的可能性，尤其希望在constexpr计算中能够使用lambda表达式，并附带了一个实验性实现。\n其实支持constexpr的lambda表达式并不困难，我们都知道lambda在C++中是很透明的，基本上完全就是一个匿名的函数对象。函数对象都能是constexpr的，那么支持constexpr的lambda也就是理所当然的事情了。\n唯一需要注意的是，lambda是可以进行捕获的，捕获constexpr的变量会怎么样呢？\nvoid foo() { constexpr int x = 3; constexpr auto foo = [=]() { return x + 1; }; static_assert(sizeof(foo) == 1); } 从直觉上来说，由于x是常量表达式，没有必要给它分配空间来储存。那么f其实里面没有任何成员，在C++中空类的size至少是1。上面的代码挺合理的，但在文章的上篇也说到了，constexpr变量其实也是可以占用内存的，我们可以显式取它的地址：\nvoid foo() { constexpr int x = 3; constexpr auto foo = [=]() { return \u0026amp;x + 1; }; static_assert(sizeof(foo) == 4); } 可以发现这种情况下，编译器不得不给x分配内存。实际上的判断规则更复杂一些，感兴趣的可以自行参考lambda capture。最终这个提案被接受，进入了C++17。\n2017-2019：编译期和运行期\u0026hellip;不同？ # 通过不断放宽constexpr的限制，越来越多的函数可以在编译期执行。但具有外部链接（也就是被extern的函数）无论如何是无法在编译期执行的。绝大部分从C继承过来的函数都是这样的，例如memcpy, memmove等等。\n假设我写了一个constexpr的memcpy：\ntemplate \u0026lt;typename T\u0026gt; constexpr T* memcpy(T* dest, const T* src, std::size_t count) { for(std::size_t i = 0; i \u0026lt; count; ++i) { dest[i] = src[i]; } return dest; } 虽然能在编译期用了，编译期执行效率倒是无所谓，但运行期效率肯定不如标准库的实现。如果能在编译期使用我的实现，运行期使用外部链接的标准库函数就好了。\n提案P0595希望加入一个新的magic function，也就是constexpr()，用于判断当前函数是否在编译期执行，后来被更名为is_constant_evaluated并进入C++20。使用起来就像下面这样：\nconstexpr int foo(int x) { if(std::is_constant_evaluated()) { return x; } else { return x + 1; } } 这样的话编译期和运行期就可以采用不同的逻辑实现了，我们可以对外部链接的函数进行一层封装，使得它们在内部暴露为constexpr的函数接口，既可以代码复用又可以保证运行期效率，两全其美。\n唯一的问题是，假设上面的foo在运行期运行，你会发现第一个分支仍然被编译了，虽然可能编译器最终应该会把if(false)这个分支优化掉。但这个分支里面仍然会进行语法检查之类的工作，如果里面用到了模板，那么模板实例化仍然会被触发（甚至产生预料外的实例化导致编译错误），显然这不是我们想要的结果。尝试使用if constexpr改写上面的代码呢？\nconstexpr int foo(int x) { if constexpr(std::is_constant_evaluated()) { // ... } } 这种写法被认为是obviously incorrect，因为if constexpr的条件只能在编译期执行，所以这里is_constant_evaluated永远会返回true，这与我们最开始的目的相悖了。所以提案P1938R3提议加入新的语法来解决这个问题：\nif consteval /* !consteval */ { // ... } else { // ... } 代码看上去是一目了然的，两个分支一个编译期一个运行期。这个升级过后的版本最终被接受并加入C++23。\n2017-2019：高效的调试 # C++模板一个最被人诟病的问题就是报错信息非常糟糕，而且难以调试。内层模板实例化失败之后，会把整个实例化栈打印出来，能轻松产生成百上千行报错。但事情在constexpr函数这里其实也并没有变好，如果constexpr函数常量求值失败，也会把整个函数调用堆栈打印出来：\nconstexpr int foo(){ return 13 + 2147483647; } constexpr int bar() { return oo(); } constexpr auto x = bar(); 报错：\nin \u0026#39;constexpr\u0026#39; expansion of \u0026#39;bar()\u0026#39; in \u0026#39;constexpr\u0026#39; expansion of \u0026#39;foo()\u0026#39; error: overflow in constant expression [-fpermissive] 233 | constexpr auto x = bar(); 如果函数嵌套多了，报错信息也非常糟糕。不同于模板的地方在于，constexpr函数也可以在运行期运行。所以我们可以在运行期调试代码，最后在编译期执行就好了。但如果考虑到上一小节加的is_constant_evaluated，就会发现这种做法并不完全可行，因为编译期和运行期的代码逻辑可能不同。提案P0596希望引入constexpr_trace和constexpr_assert来方便编译期调试代码，虽然投票一致赞成，但暂时未进入C++标准。\n2017：编译期可变容器 # 尽管在先前的提案中，允许了constexpr函数使用和修改变量，但动态内存分配还是不允许的。如果有未知长度的数据需要处理，一般就是在栈上开一个大数组，这没什么问题。但从实践上来说，有特别多的函数依赖于动态内存分配，支持constexpr函数中使用vector势在必得。\n在当时，直接允许在constexpr函数中使用new/delete似乎过于让人惊讶了，所以提案P0597想了一个折中的办法，先提供一个magic container叫做std::constexpr_vector，它由编译器实现，并且支持在constexpr函数中使用和修改。\nconstexpr constexpr_vector\u0026lt;int\u0026gt; x; // ok constexpr constexpr_vector\u0026lt;int\u0026gt; y{ 1, 2, 3 }; // ok constexpr auto series(int n) { std::constexpr_vector\u0026lt;int\u0026gt; r{}; for(int k; k \u0026lt; n; ++k) { r.push_back(k); } return r; } 这并不彻底解决问题，用户仍然需要重写它的代码以支持常量求值。从在constexpr函数支持循环的那一节来看，这种加重语言不一致性的东西，很难被加入标准。最终有更好的提案取代了它，后面会提到。\n2018：真正的编译期多态？ # 提案P1064R0希望在常量求值中支持虚函数调用。哎，还不支持动态内存分配呢，咋就要支持虚函数调用了？其实不依赖动态内存分配也可以弄出来多态指针嘛，指向栈上的对象或者静态储存就可以了。\nstruct Base { virtual int foo() const { return 1; } }; struct Derived : Base { int foo() const override { return 2; } }; constexpr auto foo() { Base* p; Derived d; p = \u0026amp;d; return p-\u0026gt;foo(); } 似乎没有任何理由拒绝上面这段代码编译通过。由于是在编译期执行，编译器当然能知道p指向的是Derived，然后调用Derived::f，实践上没有任何难度。的确如此，之后又有一个新的提案P1327R1进一步希望dynamic_cast和typeid也能在常量求值中使用，最终它们都被接受并且加入了C++20，现在可以自由的在编译期使用这些特性了。\n2017-2019：真正的动态内存分配！ # 在constexpr everything的这个演示视频中，展示了一个能在编译期处理JSON对象的例子：\nconstexpr auto jsv= R\u0026#34;({ \u0026#34;feature-x-enabled\u0026#34;: true, \u0026#34;value-of-y\u0026#34;: 1729, \u0026#34;z-options\u0026#34;: {\u0026#34;a\u0026#34;: null, \u0026#34;b\u0026#34;: \u0026#34;220 and 284\u0026#34;, \u0026#34;c\u0026#34;: [6, 28, 496]} })\u0026#34;_json; if constexpr (jsv[\u0026#34;feature-x-enabled\u0026#34;]) { // feature x } else { // feature y } 希望能直接通过解析常量字符串起到配置文件的作用（字符串文本可以由#include引入）。作者们因为不能使用STL的容器受到了严重影响，并且自己编写了替代品。通过std::array来实现std::vector和std::map这样的容器，由于没有动态内存分配，只能预先计算出需要的大小（可能导致多次遍历）或者在栈上开块大内存。\n提案P0784R7重新讨论了在常量求值中支持标准库容器的可能性。\n主要有以下三个难点：\n析构函数不能被声明为constexpr（对于constexpr对象，它们必须是trivial的） 无法进行动态内存分配/释放 无法在常量求值中使用placement new来调用对象的构造函数 针对第一个问题，作者们与MSVC，GCC，Clang，EDG等前端开发人员快速讨论并解决了这个问题。C++20起，可以符合literal type要求的类型具有constexpr修饰的析构函数，而不是严格要求平凡的析构函数。\n针对第二个问题，处理起来并不简单。C++有很多未定义行为都是由于错误的内存处理导致的，相比之下，不能直接操作内存的脚本语言则安全的多。但是为了复用代码，C++编译器中的常量求值器不得不直接操作内存，不过由于所有信息都是编译期已知的，理论上可以保证常量求值中不会出现内存错误（out of range, double free, memory leak, \u0026hellip;），如果出现应该中止编译并报告错误。\n常量求值器需要跟踪许多对象的元信息，并找出这些错误：\n记录union哪个field是active的，访问unactive的成员导致未定义行为，这由P1330阐明 正确记录对象的lifetime，访问未初始化的内存和已经析构的对象都是不允许的 当时还不允许在常量求值中把void*转换成T*，所以理所当然的：\nvoid* operator new(std::size_t); 不支持在常量求值中使用，取而代之的是：\n// new =\u0026gt; initialize when allocate auto pa = new int(42); delete pa; // std::allocator =\u0026gt; initialize after allocate std::allocator\u0026lt;int\u0026gt; alloc; auto pb = alloc.allocate(1); alloc.deallocate(pb, 1); 它们返回的都是T*，并且由编译器实现，这对于支持标准库容器来说已经足够了。\n对于第三个问题，则是添加了一个magic function即std::construct_at，它的作用是在指定的内存位置上调用对象的构造函数，用来在常量求值中取代placement new。这样的话我们就可以先通过std::allocator分配内存，再通过std::construct_at来构造对象了。该提案最终被接受，进入了C++20，同时使得std::vector，std::string在常量求值中可用（其它的容器理论上也行，但目前的实现还没支持，如果非常想要只能自己搓一个了）。\n虽然支持了动态内存分配，但并不是毫无限制。在一次常量求值中分配的内存必须要在这次常量求值结束之前释放完全，不能有内存泄漏，否则会导致编译错误。这种类型的内存分配被叫做transient constexpr allocations（瞬态内存分配）。该提案也讨论了non-transient allocation（非瞬态内存分配），在编译期未被释放的内存，将被转为静态储存（其实就是存在数据区，就像全局变量那样）。但是，委员会认为这种可能性\u0026quot;too brittle\u0026quot;，出于多种原因，目前尚未采纳。\n2018：更多的constexpr # 提案P1002希望在constexpr函数中支持try-catch块。但不能throw，这样是为了能把更多的标准库容器的成员函数标记为constexpr。\nconstexpr int foo(){ throw 1; return 1; } constexpr auto x = foo(); // error // expression \u0026#39;\u0026lt;throw-expression\u0026gt;\u0026#39; is not a constant expression // 233 | throw 1; 如果在编译期throw会直接导致编译错误，由于throw不会发生，那自然也不会有异常被捕获。\n2018：保证编译期执行！ # 有些时候我们想保证一个函数在编译期执行：\nextern int foo(int x); constexpr int bar(int x){ return x; } foo(bar(1)); // evaluate at compile time ? 事实上g无论是在编译期还是运行期执行，理论上都可以。为了保证它在编译期执行，我们需要多写一些代码：\nconstexpr auto x = bar(1); foo(x); 这样就保证了g在编译期执行，同样，这种没意义的局部变量实在是多余。提案P1073希望增加一个标记constexpr!来确保一个函数在编译期执行，如果不满足则导致编译错误。最终该标记被更名为[consteval](https://en.cppreference.com/w\n","date":"22 February 2024","externalUrl":null,"permalink":"/en/articles/683463723/","section":"Articles","summary":"\u003cp\u003e前情提要：\u003ca href=\"https://www.ykiko.me/zh-cn/articles/682031684\" target=\"_blank\"\u003eC++中constexpr的历史！（第一部分）\u003c/a\u003e\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003e2015-2016：模板的语法糖 \n    \u003cdiv id=\"2015-2016%E6%A8%A1%E6%9D%BF%E7%9A%84%E8%AF%AD%E6%B3%95%E7%B3%96\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#2015-2016%E6%A8%A1%E6%9D%BF%E7%9A%84%E8%AF%AD%E6%B3%95%E7%B3%96\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在C++中，支持\u003ca href=\"https://en.cppreference.com/w/cpp/language/template_specialization\" target=\"_blank\"\u003e全特化（full specialization）\u003c/a\u003e的模板很多，但支持\u003ca href=\"https://en.cppreference.com/w/cpp/language/partial_specialization\" target=\"_blank\"\u003e偏特化（partial specialization）\u003c/a\u003e的模板并不多。事实上，只有类模板（class template）和变量模板（variable template）支持偏特化，而变量模板可以看作是类模板的语法糖，因此实际上只有类模板支持偏特化。不支持偏特化会导致某些代码难以编写。\u003c/p\u003e","title":"C++中constexpr的历史！（第二部分）","type":"articles"},{"content":"","date":"22 February 2024","externalUrl":null,"permalink":"/en/series/constexpr/","section":"Series","summary":"","title":"Constexpr","type":"series"},{"content":"几个月前，我写了一篇介绍 C++ 模板的文章：雾里看花：真正意义上的理解 C++ 模板。\n文章梳理了现代 C++ 中模板的地位。其中，使用 constexpr 函数替代模板进行编译期计算可以说是现代 C++ 最重要的改进之一。constexpr 本身其实并不难理解，非常直观。但由于几乎每个 C++ 版本都在改进它，不同 C++ 版本中可用的内容差异很大，有时可能会给人一种“不一致”的感觉。\n最近我偶然读到了这篇文章：Design and evolution of constexpr in C++，它全面介绍了 C++ 中 constexpr 的发展史，写得非常好。于是便想将其翻译到中文社区。\n有趣的是，这篇文章其实也是翻译的。文章的原作者是一位俄罗斯人，最初发表在俄罗斯的论坛上。这是作者的邮箱：izaronplatz@gmail.com，我已经和他联系过了，他回复说：\nIt\u0026rsquo;s always good to spread knowledge in more languages.\n也就是允许翻译了。不过我不懂俄文，所以主要参考了原文的结构，而主体部分基本都是我重新叙述的。\n原文内容较长，故分为上下两篇，这是上篇。\n很神奇吗？ # constexpr 是当代 C++ 中最神奇的关键字之一。它使得某些代码可以在编译期执行。\n随着时间的推移，constexpr 的功能越来越强大。现在几乎可以在编译时计算中使用标准库的所有功能。\nconstexpr 的发展历史可以追溯到早期版本的 C++。通过研究标准提案和编译器源代码，我们可以了解这一语言特性是如何一步步地构建起来的，为什么会以这样的形式存在，实际上 constexpr 表达式是如何计算的，未来有哪些可能的功能，以及哪些功能可能会存在但没有被纳入标准。\n本文适合任何人，无论你是否了解 constexpr！\nC++98/03：我比你更 const # 在 C++ 中，有些地方需要整数常量（比如内建数组类型的长度），这些值必须在编译期就确定。C++ 标准允许通过简单的表达式来构造常量，例如：\nenum EPlants{ APRICOT = 1 \u0026lt;\u0026lt; 0, LIME = 1 \u0026lt;\u0026lt; 1, PAPAYA = 1 \u0026lt;\u0026lt; 2, TOMATO = 1 \u0026lt;\u0026lt; 3, PEPPER = 1 \u0026lt;\u0026lt; 4, FRUIT = APRICOT | LIME | PAPAYA, VEGETABLE = TOMATO | PEPPER, }; template \u0026lt;int V\u0026gt; int foo(int v = 0){ switch(v){ case 1 + 4 + 7: case 1 \u0026lt;\u0026lt; (5 | sizeof(int)): case (12 \u0026amp; 15) + PEPPER: return v; } } int f1 = foo\u0026lt;1 + 2 + 3\u0026gt;(); int f2 = foo\u0026lt;((1 \u0026lt; 2) ? 10 * 11 : VEGETABLE)\u0026gt;(); 这些表达式在[expr.const]小节中被定义，并且被叫做常量表达式（constant expression）。它们只能包含：\n字面量：1,'A',true,... 枚举值 整数或枚举类型的模板参数（例如template\u0026lt;int v\u0026gt;中的v） sizeof表达式 由常量表达式初始化的const变量 前几项都很好理解，最后一项稍微有点复杂。如果一个变量具有静态储存期，那么在常规情况下，它的内存会被填充为0，之后在程序开始执行的时候改变。但对于上述的变量来说，这太晚了，需要在编译结束之前就计算出它们的值。\n在 C++98/03 当中有两种类型的静态初始化：\n零初始化：内存被填充为0，然后在程序执行期间改变 常量初始化：使用常量表达式进行初始化，内存（如果需要的话）立即填充为计算出来的值 所有其它的初始化都被叫做动态初始化，这里我们不考虑它们。\n让我们看一个包含两种静态初始化的例子：\nint foo() { return 13; } const int v1 = 1 + 2 + 3 + 4; // 常量初始化 const int v2 = 15 * v1 + 8; // 常量初始化 const int v3 = foo() + 5; // 零初始化 const int v4 = (1 \u0026lt; 2) ? 10 * v3 : 12345; // 零初始化 const int v5 = (1 \u0026gt; 2) ? 10 * v3 : 12345; // 常量初始化 变量v1, v2和v5都可以作为常量表达式，可以用作模板参数，switch的case，enum的值，等等。而v3和v4则不行。即使我们能明显看出foo() + 5的值是18，但在那时还没有合适的语义来表达这一点。\n由于常量表达式是递归定义的，如果一个表达式的某一部分不是常量表达式，那么整个表达式就不是常量表达式。在这个判断过程中，只考虑实际计算的表达式，所以v5是常量表达式，但v4不是。\n如果没有获取常量初始化的变量的地址，编译器就可以不为它分配内存。所以我们可以通过取地址的方式，来强制编译器给常量初始化的变量预留内存（其实如果没有显式取地址的话，普通的局部变量也可能被优化掉，任何不违背as-if原则的优化都是允许的。可以考虑使用[[gnu::used]]这个 attribute 标记避免变量被优化掉）。\nint main() { std::cout \u0026lt;\u0026lt; v1 \u0026lt;\u0026lt; \u0026amp;v1 \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; v2 \u0026lt;\u0026lt; \u0026amp;v2 \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; v3 \u0026lt;\u0026lt; \u0026amp;v3 \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; v4 \u0026lt;\u0026lt; \u0026amp;v4 \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; v5 \u0026lt;\u0026lt; \u0026amp;v5 \u0026lt;\u0026lt; std::endl; } 编译上述代码并查看符号表（环境是 windows x86-64）：\n$ g++ --std=c++98 -c main.cpp $ objdump -t -C main.o (sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x0000000000000000 v1 (sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x0000000000000004 v2 (sec 3)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x0000000000000000 v3 (sec 3)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x0000000000000004 v4 (sec 6)(fl 0x00)(ty 0)(scl 3) (nx 0) 0x0000000000000008 v5 ---------------------------------------------------------------- (sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x0000000000000000 .bss (sec 4)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x0000000000000000 .xdata (sec 5)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x0000000000000000 .pdata (sec 6)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x0000000000000000 .rdata 可以发现在我的 GCC 14 上，零初始化的变量v3和v4被放在.bss段，而常量初始化的变量v1, v2,v5被放在.rdata段。操作系统会对.rdata段进行保护，使其处于只读模式，尝试写入会导致段错误。\n从上述的差异可以看出，一些const变量比其它的更加const。但是在当时我们并没有办法检测出这种差异（后来的 C++20 引入了constinit来确保一个变量进行常量初始化）。\n0-∞：编译器中的常量求值器 # 为了理解常量表达式是如何求值的，我们需要简单了解编译器的构造。不同编译器的处理方法大致相同，接下来将以 Clang/LLVM 为例。\n总的来说，编译器可以看做由以下三个部分组成：\n前端（Front-end）：将 C/C++/Rust 等源代码转换为 LLVM IR（一种特殊的中间表示）。Clang 是 C 语言家族的编译器前端。 中端（Middle-end）：根据相关的设置对 LLVM IR 进行优化。 后端（Back-end）：将 LLVM IR 转换为特定平台的机器码：x86/Arm/PowerPC 等等。 对于一个简单的编程语言，通过调用 LLVM，1000行就能实现一个编译器。你只需要负责实现语言前端就行了，后端交给 LLVM 即可。甚至前端也可以考虑使用 lex/yacc 这样的现成的语法解析器。\n具体到编译器前端的工作，例如这里提到的 Clang，可以分为以下三个阶段：\n词法分析：将源文件转换为 Token Stream，例如 []() { return 13 + 37; } 被转换为 [, ], (, ), {, return, 13, +, 37, ;, } 语法分析：产生 Abstract Syntax Tree（抽象语法树），就是将上一步中的 Token Stream 转换为类似于下面这样的递归的树状结构： lambda-expr └── body └── return-expr └── plus-expr ├── number 13 └── number 37 代码生成：根据给定的 AST 生成 LLVM IR 因此，常量表达式的计算（以及相关的事情，如模板实例化）严格发生在 C++ 编译器的前端，而 LLVM 不涉及此类工作。这种处理常量表达式（从 C++98 的简单表达式到 C++23 的复杂表达式）的工具被称为常量求值器 (constant evaluator)。\n多年来，对常量表达式的限制一直在不断放宽，而 Clang 的常量求值器相应地变得越来越复杂，直到管理 memory model（内存模型）。有一份旧的文档，描述 C++98/03 的常量求值。由于当时的常量表达式非常简单，它们是通过分析语法树进行 constant folding （常量折叠）来进行的。由于在语法树中，所有的算术表达式都已经被解析为子树的形式，因此计算常量就是简单地遍历子树。\n常量计算器的源代码位于lib/AST/ExprConstant.cpp，在撰写本文时已经扩展到将近 17000 行。随着时间的推移，它学会了解释许多内容，例如循环（EvaluateLoopBody），所有这些都是在语法树上进行的。\n常量表达式与运行时代码有一个重要的区别：它们必须不引发 undefined behavior（未定义行为）。如果常量计算器遇到未定义行为，编译将失败。\nerror: constexpr variable \u0026#39;foo\u0026#39; must be initialized by a constant expression 2 | constexpr int foo = 13 + 2147483647; | ^ ~~~~~~~~~~~~~~~ note: value 2147483660 is outside the range of representable values of type \u0026#39;int\u0026#39; 2 | constexpr int foo = 13 + 2147483647; 因此在有些时候可以用它们来检测程序中的潜在错误。\n2003：真的能 macro free 吗？ # 标准的改变是通过 proposals（提案）进行的\n在哪里可以找到提案？它们是由什么组成的？\n所有的有关 C++ 标准的提案都可以在open-std.org上找到。它们中的大多数都有详细的描述并且易于阅读。通常由如下部分组成：\n- 当前遇到的问题\n- 标准中相关措辞的的链接\n- 上述问题的解决方案\n- 建议对标准措辞进行的修改\n- 相关提案的链接（提案可能有多个版本或者需要和其它提案进行对比）\n- 在高级提案中，往往还会附带上实验性实现的链接\n可以通过这些提案来了解 C++ 的每个部分是如何演变的。并非存档中的所有提案最终都被接受，但是它们都对 C++ 的发展有着重要的影响。\n通过提交新提案，任何人都可以参与到 C++ 的演变过程中来。\n2003年的提案N1521 Generalized Constant Expressions指出一个问题。如果一个表达式中的某个部分含有函数调用，那么整个表达式就不能是常量表达式，即使这个函数最终能够被常量折叠。这迫使人们在处理复杂常量表达式的时候使用宏，甚至一定程度上导致了宏的滥用：\ninline int square(int x) { return x * x; } #define SQUARE(x) ((x) * (x)) square(9) std::numeric_limits\u0026lt;int\u0026gt;::max() // 理论上可用于常量表达式, 但是实际上不能 SQUARE(9) INT_MAX // 被迫使用宏代替 因此，建议引入**常值 (constant-valued)**函数的概念，允许在常量表达式中使用这些函数。如果希望一个函数是常值函数，那么它必须满足：\ninline ，non-recursive，并且返回类型不是 void 仅由单一的 return expr 语句组成，并且在把 expr 里面的函数参数替换为常量表达式之后，得到的仍然是一个常量表达式 如果这样的函数被调用，并且参数是常量表达式，那么函数调用表达式也是常量表达式：\nint square(int x) { return x * x; } // 常值函数 long long_max(int x) { return 2147483647; } // 常值函数 int abs(int x) { return x \u0026lt; 0 ? -x : x; } // 常值函数 int next(int x) { return ++x; } // 非常值函数 这样的话，不需要修改任何代码，最开始的例子中的v3和v4也可以被用作常量表达式了，因为foo被认为是常值函数。\n该提案认为，可以考虑进一步支持下面这种情况：\nstruct cayley{ const int value; cayley(int a, int b) : value(square(a) + square(b)) {} operator int() const { return value; } }; std::bitset\u0026lt;cayley(98, -23)\u0026gt; s; // same as bitset\u0026lt;10133\u0026gt; 因为成员value是totally constant的，在构造函数中通过两次调用常值函数进行初始化。换句话说，根据该提案的一般逻辑，此代码可以大致转换为以下形式（将变量和函数移到结构体之外）：\n// 模拟 cayley::cayley(98, -23)的构造函数调用和 operator int() const int cayley_98_m23_value = square(98) + square(-23); int cayley_98_m23_operator_int() { return cayley_98_m23_value; } // 创建 bitset std::bitset\u0026lt;cayley_98_m23_operator_int()\u0026gt; s; // same as bitset\u0026lt;10133\u0026gt; 但是和变量一样，程序员无法确定一个函数是否为常值函数，只有编译器知道。\n提案通常不会深入到编译器实现它们的细节。上述提案表示，实现它不应该有任何困难，只需要稍微改变大多数编译器中存在的常量折叠即可。然而，提案与编译器实现密切相关。如果提案无法在合理时间内实现，很可能不会被采纳。从后来的视角来看，许多大的提案最后被分成了多个小的提案逐步实现。\n2006-2007：当一切浮出水面 # 幸运的是，三年后，这个提案的后续修订版N2235认识到了过多的隐式特性是不好的，程序员应该有办法确保一个变量可以被用作常量，如果不满足相应的条件应该导致编译错误。\nstruct S{ static const int size; }; const int limit = 2 * S::size; // 动态初始化 const int S::size = 256; // 常量初始化 const int z = std::numeric_limits\u0026lt;int\u0026gt;::max(); // 动态初始化 根据程序员的设想，limit应该被常量初始化，但事实并非如此，因为S::size被定义在limit之后，定义的太晚了。可以通过 C++20 加入的constinit来验证这一点，constinit保证一个变量进行常量初始化，如果不能进行常量初始化，则会编译错误。\n在新的提案中，常值函数被重命名为 constexpr function，对它们的要求保持不变。但现在，为了能够在常量表达式中使用它们，必须使用 constexpr 关键字进行声明。此外，如果函数体不符合相关的要求，将会编译失败。同时建议将一些标准库的函数（如std::numeric_limits中的函数）标记为 constexpr，因为它们符合相关的要求。变量或类成员也可以声明为 constexpr，这样的话，如果变量不是通过常量表达式进行初始化，将会编译失败。\n用户自定义class的 constexpr 构造函数也合法化了。该构造函数必须具有空函数体，并用常量表达式初始化成员。隐式生成的构造函数将尽可能的被标记为 constexpr。对于 constexpr 的对象，析构函数必须是平凡的，因为非平凡的析构函数通常会在正在执行的程序上下文中做一些改变，而在 constexpr 计算中不存在这样的上下文。\n以下是包含 constexpr 的示例类：\n","date":"10 February 2024","externalUrl":null,"permalink":"/en/articles/682031684/","section":"Articles","summary":"\u003cp\u003e几个月前，我写了一篇介绍 C++ 模板的文章：\u003ca href=\"https://www.ykiko.me/zh-cn/articles/655902377\" target=\"_blank\"\u003e雾里看花：真正意义上的理解 C++ 模板\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e文章梳理了现代 C++ 中模板的地位。其中，使用 constexpr 函数替代模板进行编译期计算可以说是现代 C++ 最重要的改进之一。constexpr 本身其实并不难理解，非常直观。但由于几乎每个 C++ 版本都在改进它，不同 C++ 版本中可用的内容差异很大，有时可能会给人一种“不一致”的感觉。\u003c/p\u003e","title":"C++ 中 constexpr 的发展史！（上篇）","type":"articles"},{"content":" Avoid Hardcoding # Define an enum\nenum Color { RED, GREEN, BLUE }; Attempt to print\nColor color = RED; std::cout \u0026lt;\u0026lt; color \u0026lt;\u0026lt; std::endl; // output =\u0026gt; 0 If we need to output enums as logs, we don\u0026rsquo;t want to manually look up the corresponding strings based on the enum values when reviewing the logs, as it is cumbersome and unintuitive. We hope to directly output the strings corresponding to the enum values, such as RED, GREEN, BLUE.\nConsider using an array as a map, where the enum values are the keys and the strings are the values. This way, we can directly find the corresponding string through the enum value.\nstd::string_view color_map[] = { \u0026#34;RED\u0026#34;, \u0026#34;GREEN\u0026#34;, \u0026#34;BLUE\u0026#34; }; However, when there are many enums, writing them manually is inconvenient and very tedious. Specifically, if we want to add several enum definitions, the corresponding content in the string mapping table also needs to be modified. When the number reaches hundreds, there may be omissions. Or, when taking over someone else\u0026rsquo;s project, you might find a large number of enums, making manual writing very time-consuming.\nWe need to find a solution that can automatically make the relevant modifications. In other languages like Java, C#, and Python, this functionality can be easily achieved through reflection. However, C++ currently does not have reflection, so this approach is not feasible. Currently, there are three main solutions to this problem.\nTemplate Table Generation # The content introduced in this section has already been encapsulated by someone else and can be directly used via the magic enum library. Below is mainly an analysis of the principles of this library. For convenience, it will be implemented in C++20, although C++17 is actually sufficient.\nIn the three major compilers, there are some special macro variables. __PRETTY_FUNCTION__ in GCC and Clang, and __FUNCSIG__ in MSVC. These macro variables are replaced with the function signature during compilation. If the function is a template function, the template instantiation information will also be output (you can also use source_location added in C++20, which has a similar effect to these macros).\ntemplate \u0026lt;typename T\u0026gt; void print_fn(){ #if __GNUC__ || __clang__ std::cout \u0026lt;\u0026lt; __PRETTY_FUNCTION__ \u0026lt;\u0026lt; std::endl; #elif _MSC_VER std::cout \u0026lt;\u0026lt; __FUNCSIG__ \u0026lt;\u0026lt; std::endl; #endif } print_fn\u0026lt;int\u0026gt;(); // gcc and clang =\u0026gt; void print_fn() [with T = int] // msvc =\u0026gt; void __cdecl print_fn\u0026lt;int\u0026gt;(void) Specifically, when the template parameter is an enum constant, the name of the enum constant will be output.\ntemplate \u0026lt;auto T\u0026gt; void print_fn(){ #if __GNUC__ || __clang__ std::cout \u0026lt;\u0026lt; __PRETTY_FUNCTION__ \u0026lt;\u0026lt; std::endl; #elif _MSC_VER std::cout \u0026lt;\u0026lt; __FUNCSIG__ \u0026lt;\u0026lt; std::endl; #endif } enum Color { RED, GREEN, BLUE }; print_fn\u0026lt;RED\u0026gt;(); // gcc and clang =\u0026gt; void print_fn() [with auto T = RED] // msvc =\u0026gt; void __cdecl print_fn\u0026lt;RED\u0026gt;(void) It can be observed that the enum name appears at a specific position. Through simple string trimming, we can obtain the desired content.\ntemplate\u0026lt;auto value\u0026gt; constexpr auto enum_name(){ std::string_view name; #if __GNUC__ || __clang__ name = __PRETTY_FUNCTION__; std::size_t start = name.find(\u0026#39;=\u0026#39;) + 2; std::size_t end = name.size() - 1; name = std::string_view{ name.data() + start, end - start }; start = name.rfind(\u0026#34;::\u0026#34;); #elif _MSC_VER name = __FUNCSIG__; std::size_t start = name.find(\u0026#39;\u0026lt;\u0026#39;) + 1; std::size_t end = name.rfind(\u0026#34;\u0026gt;(\u0026#34;); name = std::string_view{ name.data() + start, end - start }; start = name.rfind(\u0026#34;::\u0026#34;); #endif return start == std::string_view::npos ? name : std::string_view{ name.data() + start + 2, name.size() - start - 2 }; } Test it\nenum Color { RED, GREEN, BLUE }; int main(){ std::cout \u0026lt;\u0026lt; enum_name\u0026lt;RED\u0026gt;() \u0026lt;\u0026lt; std::endl; // output =\u0026gt; RED } Successfully meets our requirements. However, this is not the end. This form requires the enum to be a template parameter, meaning it only supports compile-time constants. But in most cases, we use enums as runtime variables. What to do? Convert static to dynamic by generating a table. Consider generating an array through template metaprogramming, where each element is the string representation of the enum corresponding to the index. One issue is determining the size of this array, which requires us to obtain the number of enum items. A straightforward method is to define a pair of start and end markers in the enum, so that the maximum number of enums can be obtained by subtraction. However, often we cannot modify the enum definition. Fortunately, there is a small trick to solve this problem.\nconstexpr Color color = static_cast\u0026lt;Color\u0026gt;(-1); std::cout \u0026lt;\u0026lt; enum_name\u0026lt;color\u0026gt;() \u0026lt;\u0026lt; std::endl; // output =\u0026gt; (Color)2 It can be seen that if the integer does not have a corresponding enum item, the output will not be the corresponding enum name but a cast expression with parentheses. Therefore, by checking if the obtained string contains ), we can determine if the corresponding enum item exists. Recursive judgment can find the maximum enum value (this method has limited applicability, such as for scattered enum values, it may be more difficult).\ntemplate\u0026lt;typename T, std::size_t N = 0\u0026gt; constexpr auto enum_max(){ constexpr auto value = static_cast\u0026lt;T\u0026gt;(N); if constexpr (enum_name\u0026lt;value\u0026gt;().find(\u0026#34;)\u0026#34;) == std::string_view::npos) return enum_max\u0026lt;T, N + 1\u0026gt;(); else return N; } Then generate a corresponding length array through make_index_sequence.\ntemplate\u0026lt;typename T\u0026gt; requires std::is_enum_v\u0026lt;T\u0026gt; constexpr auto enum_name(T value){ constexpr auto num = enum_max\u0026lt;T\u0026gt;(); constexpr auto names = []\u0026lt;std::size_t... Is\u0026gt;(std::index_sequence\u0026lt;Is...\u0026gt;){ return std::array\u0026lt;std::string_view, num\u0026gt;{ enum_name\u0026lt;static_cast\u0026lt;T\u0026gt;(Is)\u0026gt;()... }; }(std::make_index_sequence\u0026lt;num\u0026gt;{}); return names[static_cast\u0026lt;std::size_t\u0026gt;(value)]; } Test it\nenum Color { RED, GREEN, BLUE }; int main(){ Color color = RED; std::cout \u0026lt;\u0026lt; enum_name(color) \u0026lt;\u0026lt; std::endl; // output =\u0026gt; RED } Further, consider supporting bitwidth enums, such as RED | BLUE, which will not be expanded here.\nThe disadvantage of this method is obvious. Generating tables through template instantiation can significantly slow down compilation speed. If there are many enums, on compilers with low constant evaluation efficiency, such as MSVC, it may increase compilation time by tens of seconds or even longer. Therefore, it is generally only suitable for small enums. The advantage is that it is lightweight and ready to use without any additional work.\nExternal Code Generation # Since manually writing string-to-enum conversions is troublesome, why not write a script to generate the code? Indeed, we can easily accomplish this using the python bindings of libclang. For specific usage of this tool, refer to Use Clang Tools to Freely Manipulate C++ Code. Below is only the code to demonstrate the effect.\nimport clang.cindex as CX def generate_enum_to_string(enum: CX.Cursor): branchs = \u0026#34;\u0026#34; for child in enum.get_children(): branchs += f\u0026#39;case {child.enum_value}: return \u0026#34;{child.spelling}\u0026#34;;\\n\u0026#39; code = f\u0026#34;\u0026#34;\u0026#34; std::string_view {enum.spelling}_to_string({enum.spelling} value) {{ switch(value) {{ {branchs}}}}}\u0026#34;\u0026#34;\u0026#34; return code def traverse(node: CX.Cursor): if node.kind == CX.CursorKind.ENUM_DECL: print(generate_enum_to_string(node)) return for child in node.get_children(): traverse(child) index = CX.Index.create() tu = index.parse(\u0026#39;main.cpp\u0026#39;) traverse(tu.cursor) Test code\n// main.cpp enum Color { RED, GREEN, BLUE }; This is the final generated code, which can be directly generated into a .cpp file, placed in a fixed directory, and then run this script before building.\nstd::string_view enum_to_string(Color value) { switch(value) { case 0: return \u0026#34;RED\u0026#34;; case 1: return \u0026#34;BLUE\u0026#34;; case 2: return \u0026#34;GREEN\u0026#34;; }} Advantages: Non-intrusive, suitable for large numbers of enums. Disadvantages: External dependencies, need to add code generation to the build process, which may complicate the build process.\nMacros # The above two methods are non-intrusive. That is, you might get someone else\u0026rsquo;s library and cannot modify its code, so you have to do it this way. What if the enums are entirely defined by yourself? You can handle them specially during the definition phase to facilitate subsequent use. For example (the comment at the beginning of the code indicates the current file name):\n// Color.def #ifndef COLOR_ENUM #define COLOR_ENUM(...) #endif COLOR_ENUM(RED) COLOR_ENUM(GREEN) COLOR_ENUM(BLUE) #undef COLOR_ENUM Then, where you need to use it, modify the macro definition to generate the code.\n// Color.h enum Color { #define COLOR_ENUM(x) x, #include \u0026#34;Color.def\u0026#34; }; std::string_view color_to_string(Color value){ switch(value){ #define COLOR_ENUM(x) case x: return #x; #include \u0026#34;Color.def\u0026#34; } } In this way, you only need to add and modify the relevant content in the def file. Later, if you need to traverse the enum, you can directly define a macro to generate the code, which is very convenient. In fact, for large numbers of enums, many open-source projects adopt this approach. For example, when defining TokenKind, clang does this. The relevant code can be found in Token.def. Since clang needs to adapt to multiple language front-ends, the total number of TokenKind is in the hundreds. Without this approach, adding and modifying Token would be very difficult.\nSummary # Non-intrusive and the number of enums is small, compilation speed is not very important: use template table generation (requires at least C++17). Non-intrusive and the number of enums is large, compilation speed is important: use external code generation. Intrusive: directly use macros. Year after year, we look forward to reflection, but it\u0026rsquo;s still unclear when it will enter the standard. For those who want to learn about C++ static reflection in advance, you can read C++26 Static Reflection Proposal Analysis. Or for those who don\u0026rsquo;t know what reflection is, you can refer to this article: A Reflection Tutorial for C++ Programmers.\n","date":"29 January 2024","externalUrl":null,"permalink":"/en/articles/680412313/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003eAvoid Hardcoding \n    \u003cdiv id=\"avoid-hardcoding\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#avoid-hardcoding\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eDefine an \u003ccode\u003eenum\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eenum\u003c/span\u003e \u003cspan class=\"nc\"\u003eColor\u003c/span\u003e \u003cspan class=\"p\"\u003e{\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eRED\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eGREEN\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    \u003cspan class=\"n\"\u003eBLUE\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e};\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAttempt to print\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-cpp\" data-lang=\"cpp\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eColor\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eRED\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003ecout\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003ecolor\u003c/span\u003e \u003cspan class=\"o\"\u003e\u0026lt;\u0026lt;\u003c/span\u003e \u003cspan class=\"n\"\u003estd\u003c/span\u003e\u003cspan class=\"o\"\u003e::\u003c/span\u003e\u003cspan class=\"n\"\u003eendl\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e// output =\u0026gt; 0\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIf we need to output enums as logs, we don\u0026rsquo;t want to manually look up the corresponding strings based on the enum values when reviewing the logs, as it is cumbersome and unintuitive. We hope to directly output the strings corresponding to the enum values, such as \u003ccode\u003eRED\u003c/code\u003e, \u003ccode\u003eGREEN\u003c/code\u003e, \u003ccode\u003eBLUE\u003c/code\u003e.\u003c/p\u003e","title":"How to Elegantly Convert Enum to String in C++?","type":"articles"},{"content":"As is well known, there are two special constructors in C++: the copy constructor and the move constructor.\nThe copy constructor was introduced as early as C++98 to copy an object. For types like vector that own resources, copying will also duplicate the resources it owns.\nstd::vector\u0026lt;int\u0026gt; v1 = {1, 2, 3}; std::vector\u0026lt;int\u0026gt; v2 = v1; // copy Of course, the overhead of copying can sometimes be very large and completely unnecessary. Therefore, the move constructor was introduced in C++11 to transfer the resources of one object to another. This significantly reduces overhead compared to direct copying.\nstd::vector\u0026lt;int\u0026gt; v1 = {1, 2, 3}; std::vector\u0026lt;int\u0026gt; v2 = std::move(v1); // move Note that in C++, move is referred to as non-destructive move. The C++ standard specifies that the state of an object after being moved is a valid state, and the implementation must ensure that its destructor can be called normally. The moved object may still be used again (whether it can be used depends on the implementation).\nIs That All? # Are these two constructors sufficient? Of course not. In fact, there is another widely used operation that can be called the relocate operation. Consider the following scenario:\nSuppose you are implementing a vector, and capacity expansion is necessary. So you write a private member function grow to handle the expansion (the following code example temporarily ignores exception safety).\nvoid grow(std::size_t new_capacity) { auto new_data = malloc(new_capacity * sizeof(T)); for (std::size_t i = 0; i \u0026lt; m_Size; ++i) { new (new_data + i) T(std::move(m_Data[i])); m_Data[i].~T(); } free(m_Data); m_Data = new_data; m_Capacity = new_capacity; } The above code is simple: first, allocate new memory via malloc, then initialize it by calling the move constructor on the newly allocated memory using placement new. Note, as mentioned earlier: move in C++ is non-destructive, so after calling the move constructor, the original object still needs to call the destructor to correctly end its lifetime. Finally, release the original memory and update the member variables.\nNote: The construction and destruction steps can also use std::construct_at and std::destroy_at added in C++20, which are essentially encapsulations of placement new and destroy.\nHowever, this implementation is not efficient. In C++, there is a concept called trivially copyable, which can be checked using the is_trivially_copyable trait. Types that satisfy this constraint can directly use memcpy or memmove to copy to create a new object. Consider the following example:\nstruct Point { int x; int y; }; static_assert(std::is_trivially_copyable_v\u0026lt;Point\u0026gt;); Point points[3] = {{1, 2}, {3, 4}, {5, 6}}; Point new_points[3]; std::memcpy(new_points, points, sizeof(points)); Not only does this save multiple function calls, but memcpy and memmove are highly optimized built-in functions (which can be vectorized via SIMD). Therefore, the efficiency is much higher compared to directly calling the copy constructor for duplication.\nTo make our vector faster, we can also apply this optimization. Using if constexpr added in C++17 for compile-time judgment, we can easily write the following code:\nvoid grow(std::size_t new_capacity) { auto new_data = malloc(new_capacity * sizeof(T)); if constexpr (std::is_trivially_copyable_v\u0026lt;T\u0026gt;) { std::memcpy(new_data, m_Data, m_Size * sizeof(T)); } else if constexpr (std::is_move_constructible_v\u0026lt;T\u0026gt;) { for (std::size_t i = 0; i \u0026lt; m_Size; ++i) { std::construct_at(new_data + i, std::move(m_Data[i])); std::destroy_at(m_Data + i); } } else if constexpr (std::is_copy_constructible_v\u0026lt;T\u0026gt;) { for (std::size_t i = 0; i \u0026lt; m_Size; ++i) { std::construct_at(new_data + i, m_Data[i]); std::destroy_at(m_Data + i); } } free(m_Data); m_Data = new_data; m_Capacity = new_capacity; } Note: You can also consider directly using uninitialized_move_n and destroy_n added in C++17 to avoid reinventing the wheel. These functions have already undergone similar optimizations. However, due to pointer alias issues, they may at most optimize to memmove, whereas in this vector expansion scenario, it can be further optimized to memcpy, so self-optimization yields better results.\nOverkill # This still feels a bit odd. Our main goal is to move all objects from the old memory to the new memory, but we are using the trivially copyable trait, which seems too restrictive. There seems to be a significant difference between creating a new object entirely and placing the original object in a new location. Consider the following example. It seems that directly using memcpy for types like std::string is also feasible. Since the memory is manually managed and the destructor is manually called, there will be no multiple calls to the destructor.\nstd::byte buffer[sizeof(std::string)]; auto\u0026amp; str1 = *std::construct_at((std::string*) buffer, \u0026#34;hello world\u0026#34;); std::byte new_buffer[sizeof(std::string)]; std::memcpy(new_buffer, buffer, sizeof(std::string)); auto\u0026amp; str2 = *(std::string*) new_buffer; str2.~basic_string(); After carefully considering the data flow and destructor calls, there seems to be no issue. It seems we should look for a concept called trivially movable to relax the conditions, allowing more types to benefit from optimization. Unfortunately, there is currently no such concept in the C++ standard. To distinguish this from the existing move operation in C++, we call this operation relocate, which places the original object in a completely new location.\nIn fact, many well-known open-source components have implemented similar functionality through template specialization, such as:\nBSL\u0026rsquo;s bslmf::IsBitwiseMoveable\u0026lt;T\u0026gt; Folly\u0026rsquo;s folly::IsRelocatable\u0026lt;T\u0026gt; QT\u0026rsquo;s QTypeInfo\u0026lt;T\u0026gt;::isRelocatable By marking specific types, they can benefit from this optimization. However, the above optimization is only logically equivalent; strictly speaking, writing it this way in C++ is considered undefined behavior. So what can we do? We can only try to propose new proposals to modify the standard wording to support the above optimization.\nCurrent Status # This issue was discovered long ago, as evidenced by discussions on Zhihu:\nCompared to malloc new / free old, how much performance advantage does realloc have? Why doesn\u0026rsquo;t C++ vector\u0026rsquo;s push_back expansion mechanism consider applying for memory in the space after the tail element? There are quite a few similar questions. realloc will attempt to expand in place, and if it fails, it will try to allocate a new block of memory and then use memcpy to copy the original data to the new memory. Therefore, in the current C++ standard, if you want to directly use realloc for expansion, you must ensure that the object is trivially copyable. Of course, as mentioned earlier, this condition is quite strict, and a new concept needs to be introduced to relax the conditions.\nThe relevant proposal was first proposed in 2015, and the main active proposals in 2023 are the following four (targeting C++26):\nstd::is_trivially_relocatable Trivial Relocatability For C++26 Relocating prvalues Nontrivial Relocation via a New owning reference Type They can be roughly divided into two factions: the conservative faction and the radical faction.\nConservative Faction # The conservative faction\u0026rsquo;s solution is to add the concepts of relocatable and trivially-relocatable, along with related traits for judgment.\nIf a type is move-constructible and destructible, then it is relocatable.\nIf a type satisfies one of the following conditions, then it is trivially-relocatable:\nIt is a trivially-copyable type. It is an array of trivially-relocatable types. It is a class type declared with the trivially_relocatable attribute set to true. It is a class type that satisfies the following conditions: No user-provided move constructor or move assignment operator. No user-provided copy constructor or copy assignment operator. No user-provided destructor. No virtual member functions. No virtual base classes. Each member is either a reference or a trivially-relocatable type, and all base classes are trivially-relocatable types. A new attribute, trivially_relocatable, can be used to explicitly mark a type as trivially-relocatable. It can take a constant expression as a parameter to support generic types.\ntemplate\u0026lt;typename T\u0026gt; struct [[trivially_relocatable(std::std::is_trivially_relocatable_v\u0026lt;T\u0026gt;)]] X { T t; }; Some new operations are also added:\ntemplate\u0026lt;class T\u0026gt; T *relocate_at(T* source, T* dest); template\u0026lt;class T\u0026gt; [[nodiscard]] remove_cv_t\u0026lt;T\u0026gt; relocate(T* source); // ... template\u0026lt;class InputIterator, class Size, class NoThrowForwardIterator\u0026gt; auto uninitialized_relocate_n(InputIterator first, Size n, NoThrowForwardIterator result); These functions are implemented by the compiler, and their effect is equivalent to move + destroy the original object. The compiler is allowed to optimize operations on trivially_relocatable types into memcpy or memmove under the as-if rule. For structures that cannot be optimized, such as those containing self-references, the move constructor + destructor will be called normally. This way, when implementing vector, you can directly use these standard library functions to enjoy the optimization.\nThe reason this proposal is called conservative is that it neither affects the original API nor the original ABI, making it highly compatible and easy to introduce.\nRadical Faction # The more radical approach is the main topic today, which advocates introducing the relocate constructor and a new keyword, reloc.\nreloc is a unary operator that can be used for non-static local variables of functions. reloc performs the following operations:\nIf the variable is a reference type, perfect forwarding is performed. If not, the source object is turned into a pure rvalue and returned. Using reloc on an object and then using it again is considered a compilation error (the actual judgment rules are more detailed, see the relevant sections in the proposal).\nA new constructor, the relocate constructor (relocation constructor), is introduced with the form T(T), where the function parameter is a pure rvalue of type T. This function signature is chosen to complete the C++ value category system. Currently (C++17 and later), C++\u0026rsquo;s copy constructor creates objects from lvalues, the move constructor creates objects from xvalues, and the relocation constructor creates objects from prvalues. This fully covers all value categories, making it very friendly to overload resolution and semantically harmonious.\nstruct X { std::string s; X(X x): s(std::move(x.s)) {} } Another benefit is that currently, constructors declared as T(T) are not allowed, so there will be no conflict with existing code. One thing to note is that you may have heard people explain why the copy constructor\u0026rsquo;s parameter must be a reference: if it is not a reference, function parameter passing also requires copying, leading to infinite recursion.\nIn fact, this explanation is outdated. Due to the mandatory copy elision introduced in C++17, even if a type does not have a copy constructor or move constructor, it can still be directly constructed from a pure rvalue without any copy/move constructor calls.\nstruct X { X() = default; X(const X\u0026amp;) = delete; X(X\u0026amp;\u0026amp;) = delete; }; X f(){ return X{}; }; X x = f(); The above code can be compiled by major compilers after enabling C++17. Therefore, the T(T) form of the constructor will not cause infinite recursion. This proposal also introduces the relocation assignment function with the form T\u0026amp; operator=(T), where the function parameter is a pure rvalue of type T. Of course, there is also the concept of trivially-relocatable, allowing the relocation constructor that satisfies this condition to be optimized into memcpy. However, this is determined by the rules of the relocation constructor, and users cannot explicitly mark a type as trivially-relocatable via an attribute. I think this is not good; users should be allowed to manually mark a type as trivially-relocatable. Due to current implementation limitations, tuple must write a constructor, making it never trivially-copyable, and pair is also not trivially-copyable, which is clearly unreasonable. Therefore, I hope this proposal will support marking a type as trivially-relocatable via an attribute in the future.\nPersonally, I quite like this proposal. With it, I even feel that C++\u0026rsquo;s value category system can be associated with elegance. Before this, I always thought the value category system was chaotic and evil, a patch made to be compatible with old code. But if this proposal is accepted:\nLvalue — copy construction Xvalue — move construction Prvalue — relocation construction There is a sense of logical self-consistency and beauty. Other details in the proposal are more trivial and are omitted here. Interested readers can read it themselves.\nWhy Hasn\u0026rsquo;t It Entered the Standard After So Long? # Regarding why this issue has not been resolved after so many years, it is actually a long history, caused by defects in C++\u0026rsquo;s object model. Until the implicit lifetime proposal was accepted in C++20, even optimizing trivially-copyable types into memcpy in the initial expansion function implementation was undefined behavior.\nOf course, don\u0026rsquo;t be afraid when you hear undefined behavior, as if there is a psychological barrier. In fact, this has long been considered a defect in the standard, and this optimization has been widely practiced in various codebases, with its reliability already verified. It\u0026rsquo;s just that the C++ standard has not had appropriate wording to describe this situation. Completely considering it as UB is certainly wrong, and using it without restrictions is also wrong. Therefore, the key issue is to find a suitable boundary between the two. I will write a dedicated article to introduce C++ object model-related content recently, so I won\u0026rsquo;t expand on it here.\nOther Languages # C++ certainly has various shortcomings, and considering historical compatibility and other factors, the design cannot be too bold. What about new languages? How do they solve these problems?\nRust # First, let\u0026rsquo;s look at Rust, which has been quite popular recently. In fact, as long as the structure does not contain self-referential members, using memcpy to move the old object to new memory is almost always feasible. Additionally, Rust does not have multiple inheritance, virtual functions (complex virtual table structures), virtual inheritance, and other strange things (which are rarely used in practice), so almost all types can directly use memcpy to create a new object from the old one. Coincidentally, the move semantics in Safe Rust are destructive moves, so its default move implementation is directly memcpy, which is much cleaner.\nHowever, the default move can only move local non-static variables. If a variable is a reference, you cannot move it. Fortunately, Safe Rust provides a std::mem::take function to solve this problem:\nuse std::mem; let mut v: Vec\u0026lt;i32\u0026gt; = vec![1, 2]; let old_v = mem::take(\u0026amp;mut v); assert_eq!(vec![1, 2], old_v); assert!(v.is_empty()); The effect is move + set the original object to empty, somewhat similar to move in C++. There are also std::mem::swap and std::mem::replace for other scenarios where moving from a reference is needed.\nAlthough there may not be many such cases, what if a type contains a self-referential structure? In fact, allowing users to customize constructors is a relatively simple solution, but the Rust community seems to be quite averse to this. The current solution is through Pin, but\n","date":"25 January 2024","externalUrl":null,"permalink":"/en/articles/679782886/","section":"Articles","summary":"\u003cp\u003eAs is well known, there are two special constructors in C++: the copy constructor and the move constructor.\u003c/p\u003e\n\u003cp\u003eThe copy constructor was introduced as early as C++98 to copy an object. For types like \u003ccode\u003evector\u003c/code\u003e that own resources, copying will also duplicate the resources it owns.\u003c/p\u003e","title":"Relocation Semantics in C++","type":"articles"},{"content":" Introduction # In C++17, a feature called structured binding was introduced, also known as Struct Bind. This feature is similar to pattern matching in other languages, allowing us to conveniently access the members of a structure.\nstruct Point { int x; int y; }; Point p = {1, 2}; auto [x, y] = p; // x = 1, y = 2 Using this, we can implement some interesting functionalities, including limited reflection capabilities for structures, such as implementing a for_each function.\nvoid for_each(auto\u0026amp;\u0026amp; object, auto\u0026amp;\u0026amp; func) { using T = std::remove_cvref_t\u0026lt;decltype(object)\u0026gt;; if constexpr (std::is_aggregate_v\u0026lt;T\u0026gt;) { auto\u0026amp;\u0026amp; [x, y] = object; for_each(x, func); for_each(y, func); } else { func(object); } } This way, for any aggregate type with two members, we can traverse it.\nstruct Point { int x; int y; }; struct Line { Point start; Point end; }; Line line = {{ 1, 2 }, { 3, 4 }}; for_each(line, [](auto\u0026amp;\u0026amp; object) { std::cout \u0026lt;\u0026lt; object \u0026lt;\u0026lt; std::endl; // 1 2 3 4 }); However, there is a problem: this only recursively supports structures with exactly 2 fields. If you try to use a structure with 3 fields, the compiler will throw a hard error. That is, the number of structured bindings is incorrect, and it cannot be handled by SFINAE or requires, causing the compilation to abort directly.\nstruct Vec3 { float x; float y; float z; }; // Inside is a lambda constexpr auto value = requires{ [](){ auto [x, y] = Vec3{ 1, 2, 3 }; }; }; // hard error We can solve this problem by manually dispatching.\nif constexpr(N == 1) { auto\u0026amp;\u0026amp; [x] = object; // ... } else if constexpr(N == 2) { auto\u0026amp;\u0026amp; [x, y] = object; // ... } else if constexpr(N == 3) { auto\u0026amp;\u0026amp; [x, y, z] = object; // ... } // ... You can freely enumerate up to the number of fields you want to support. Here, N is the number of fields in the structure. You may need to pass it explicitly as a template parameter or specialize a template for each type, storing its number of fields. However, this is still cumbersome. Is there a way to let the compiler automatically calculate the number of fields in a structure?\nFirst Leg: Antony Polukhin # A preliminary solution was provided in boost/pfr. Its author, Antony Polukhin, gave detailed introductions at CppCon2016 and CppCon2018. However, the author used C++14/17, and the code was quite obscure. After rewriting it in C++20, the readability improved significantly.\nFirst, in C++, we can write an Any type that supports conversion to any type. Essentially, we just need to template the type conversion function.\nstruct Any { constexpr Any(int){}; // Supports construction from int template\u0026lt;typename T\u0026gt; constexpr operator T() const; }; static_assert(std::is_convertible_v\u0026lt;Any, int\u0026gt;); // true static_assert(std::is_convertible_v\u0026lt;Any, std::string\u0026gt;); // true Then, we can utilize the feature of aggregate initialization: for expressions that exceed the maximum number of aggregate initializations, the requires statement will return false.\nstruct Point { int x; int y; }; template\u0026lt;typename T, std::size_t N\u0026gt; constexpr auto test() { // Use make_index_sequence to construct N parameters return []\u0026lt;std::size_t... I\u0026gt;(std::index_sequence\u0026lt;I...\u0026gt;) { return requires{ T{ Any(I)... }; }; }(std::make_index_sequence\u0026lt;N\u0026gt;{}); } static_assert(test\u0026lt;Point, 0\u0026gt;()); // true static_assert(test\u0026lt;Point, 1\u0026gt;()); // true static_assert(test\u0026lt;Point, 2\u0026gt;()); // true static_assert(!test\u0026lt;Point, 3\u0026gt;()); // false Notice that Point only has two members. When we pass three parameters to the initialization list, requires will return false. Using this feature, we can turn the above trial process into a recursive one, linearly searching the sequence until we find false.\ntemplate\u0026lt;typename T, int N = 0\u0026gt; constexpr auto member_count() { if constexpr(!test\u0026lt;T, N\u0026gt;()) { return N - 1; } else { return member_count\u0026lt;T, N + 1\u0026gt;(); } } If test\u0026lt;T, N\u0026gt; is true, it means N parameters can successfully construct T. Then we recursively try N + 1 parameters until test\u0026lt;T, N\u0026gt; is false, and N - 1 is the number of members in T. This way, we can get the number of members in T through member_count\u0026lt;T\u0026gt;(). Let\u0026rsquo;s test it.\nstruct A{ std::string a; }; static_assert(member_count\u0026lt;A\u0026gt;() == 1); struct B{ std::string a; int b; }; static_assert(member_count\u0026lt;B\u0026gt;() == 2); Great, it\u0026rsquo;s a success! Is this the end of the story?\nSecond Leg: João Baptista # Consider the following three examples:\nLvalue reference struct A{ int\u0026amp; x; }; static_assert(member_count\u0026lt;A\u0026gt;() == 1); // error Default constructor deleted struct X { X() = delete; } // Default constructor deleted struct B{ X x; X y; }; static_assert(member_count\u0026lt;B\u0026gt;() == 2); // error Arrays struct C { int x[2]; }; static_assert(member_count\u0026lt;C\u0026gt;() == 1); // error In these three cases, the original method completely fails. Why is that?\nThis section mainly references two blogs by João Baptista:\nCounting the number of fields in an aggregate in C++20 Counting the number of fields in an aggregate in C++20 — part 2 He summarized the issues in boost/pfr and proposed solutions to the three problems mentioned above.\nThe Lvalue Reference Problem # The first problem is relatively easy to understand. It\u0026rsquo;s mainly because the conversion produced by T() type generates pure rvalues, and lvalue references cannot bind to pure rvalues. If it were an rvalue reference, it would work.\nstatic_assert(!std::is_constructible_v\u0026lt;int\u0026amp;, Any\u0026gt;); // false static_assert(std::is_constructible_v\u0026lt;int\u0026amp;\u0026amp;, Any\u0026gt;); // true How to solve it? There\u0026rsquo;s a clever way to handle this:\nstruct Any { constexpr Any(int) {}; // Supports construction from int template\u0026lt;typename T\u0026gt; constexpr operator T\u0026amp;() const; template\u0026lt;typename T\u0026gt; constexpr operator T\u0026amp;\u0026amp;() const; }; One converts to an lvalue reference, and the other to an rvalue reference. If only one of them matches, that one will be chosen. If both can match, the lvalue reference conversion has higher priority and will be chosen first, avoiding overload resolution issues.\nstatic_assert(std::is_constructible_v\u0026lt;int, Any\u0026gt;); // true static_assert(std::is_constructible_v\u0026lt;int\u0026amp;, Any\u0026gt;); // true static_assert(std::is_constructible_v\u0026lt;int\u0026amp;\u0026amp;, Any\u0026gt;); // true static_assert(std::is_constructible_v\u0026lt;const int\u0026amp;, Any\u0026gt;); // true Great, the first problem is solved!\nThe Default Constructor Problem # Why does deleting the default constructor cause issues? Remember our initial Point type?\nstruct Point{ int x; int y; }; Our test results show that 0, 1, and 2 work, but 3 doesn\u0026rsquo;t. If the number of parameters in { } exceeds the number of members in Point, causing failure, I can understand. But why does it succeed when there are fewer parameters than the actual number of members? The reason is simple: members that are not explicitly initialized will be value-initialized. Thus, the number of parameters in { } can be less than the actual number of fields. However, if a field prohibits default construction, value initialization is not possible, leading to a compilation error.\nstruct X { X() = delete; } // Default constructor deleted struct B { X x; X y; int z; }; For this type, if we try with Any, it should be that 0 and 1 don\u0026rsquo;t work, but 2 and 3 do, and 4, 5, etc., don\u0026rsquo;t work. That is, at least all members that cannot be default-initialized must be initialized. If a type supports default initialization, the valid search interval is [0, N], where N is its maximum number of fields. If it doesn\u0026rsquo;t support default initialization, the search interval becomes [M, N], where M is the minimum number of parameters required to initialize all members that cannot be default-initialized.\nOur previous search strategy started from 0. If the current one is true, we try the next one until we find false. Clearly, this search strategy is not suitable for the current situation because in the interval [0, M), it also fits the case where the search fails. Now, we need to change it so that if the current one is true and the next one is false, we stop the search, which will find the upper bound of the interval.\ntemplate\u0026lt;typename T, int N = 0\u0026gt; constexpr auto member_count() { if constexpr(test\u0026lt;T, N\u0026gt;() \u0026amp;\u0026amp; !test\u0026lt;T, N + 1\u0026gt;()) { return N; } else { return member_count\u0026lt;T, N + 1\u0026gt;(); } } Let\u0026rsquo;s test it.\nstruct A{ int\u0026amp; x; }; static_assert(member_count\u0026lt;A\u0026gt;() == 1); struct X { X() = delete; }; // Default constructor deleted struct B{ X x; X y; }; static_assert(member_count\u0026lt;B\u0026gt;() == 2); OK, the second problem is solved. That\u0026rsquo;s awesome!\nThe Array Problem # If there are arrays in the structure\u0026rsquo;s members, the final result will count each element of the array as a separate field. This is because aggregate initialization of standard arrays has a backdoor.\nstruct Array { int x[2]; }; Array{ 1, 2 }; // OK Notice that there\u0026rsquo;s only one field but two values can be filled. However, this backdoor for arrays leads to a dilemma: if a structure contains arrays, the final count will be incorrect. Is there any way to solve this problem?\nNote: The following part might be a bit hard to understand.\nConsider the following example:\nstruct D { int x; int y[2]; int z[2]; } Let\u0026rsquo;s look at its initialization:\nD{ 1, 2, 3, 4, 5 } // OK // Position 0 D{ {1}, 2, 3, 4, 5 } // OK, position 0 can hold at most 1 element D{ {1, 2}, 3, 4, 5 } // Error // Position 1 D{ 1, {2}, 3, 4, 5 } // Error D{ 1, {2, 3}, 4, 5 } // OK, position 1 can hold at most 2 elements D{ 1, {2, 3, 4}, 5 } // Error // Position 3 D{ 1, 2, 3, {4}, 5} // Error D{ 1, 2, 3, {4, 5} } // OK, position 3 can hold at most 2 elements Yes, we can use nested initialization to solve this problem! First, we use the original method to find the maximum possible number of fields in the structure (including array expansion, which is 5 here). Then, we try to fit the original sequence into this nested initialization at each position. By continuously trying, we can find the maximum number of elements that can be placed at this position. If the maximum number exceeds 1, it means this position is an array. This maximum number is the number of elements in the array, and we subtract the extra numbers from the final result.\nIt sounds simple, but the implementation is a bit complicated.\nFirst, write a helper function to assist. By filling in different N1, N2, N3, we can correspond to the above different situations. Note that Any in I2 is nested initialization, with an extra layer of parentheses.\ntemplate\u0026lt;typename T, std::size_t N1, std::size_t N2, std::size_t N3\u0026gt; constexpr bool test_three_parts() { return []\u0026lt;std::size_t... I1, std::size_t... I2, std::size_t... I3\u0026gt; (std::index_sequence\u0026lt;I1...\u0026gt;, std::index_sequence\u0026lt;I2...\u0026gt;, std::index_sequence\u0026lt;I3...\u0026gt;) { return requires{ T{ Any(I1)..., { Any(I2)... }, Any(I3)... }; }; }(std::make_index_sequence\u0026lt;N1\u0026gt;{}, std::make_index_sequence\u0026lt;N2\u0026gt;{}, std::make_index_sequence\u0026lt;N3\u0026gt;{}); } Next, we need to write a function to test whether placing N elements at a specified position with double { } is feasible.\ntemplate \u0026lt;typename T, std::size_t position, std::size_t N\u0026gt; constexpr bool try_place_n_in_pos() { constexpr auto Total = member_count\u0026lt;T\u0026gt;(); // Maximum possible number of fields if constexpr (N == 0) // Placing 0 elements is the same as the original effect, definitely feasible { return true; } else if constexpr (position + N \u0026lt;= Total) // The sum of elements cannot exceed the total { return test_three_parts\u0026lt;T, position, N, Total - position - N\u0026gt;(); } else { return false; } } Since there\u0026rsquo;s a lot of content, it might be hard to understand. Here, we\u0026rsquo;ll first show the test results of this function to help understand. If you don\u0026rsquo;t understand the function implementation, it\u0026rsquo;s okay. Let\u0026rsquo;s take the previous structure D as an example.\ntry_place_n_in_pos\u0026lt;D, 0, 1\u0026gt;(); // This is testing D{ {1}, 2, 3, 4, 5 } // Placing 1 element at position 0 try_place_n_in_pos\u0026lt;D, 1, 2\u0026gt;(); // This is testing D{ 1, {2, 3}, 4, 5 } // Placing 2 elements at position 1 Okay, just understand what this function is doing: trying at a certain position continuously, and then finding the maximum number of elements that can be placed at this position.\ntemplate\u0026lt;typename T, std::size_t pos, std::size_t N = 0\u0026gt; constexpr auto search_max_in_pos() { constexpr auto Total = member_count\u0026lt;T\u0026gt;(); std::size_t result = 0; [\u0026amp;]\u0026lt;std::size_t... Is\u0026gt;(std::index_sequence\u0026lt;Is...\u0026gt;) { ((try_place_n_in_pos\u0026lt;T, pos, Is\u0026gt;() ? result = Is : 0), ...); }(std::make_index_sequence\u0026lt;Total + 1\u0026gt;()); return result; } Here, we search for the maximum number of elements that can be placed at this position.\nstatic_assert(search_max_in_pos\u0026lt;D, 0\u0026gt;() == 1); // 1, position 0 can hold at most 1 element static_assert(search_max_in_pos\u0026lt;D, 1\u0026gt;() == 2); // 2, position 1 can hold at most 2 elements static_assert(search_max_in_pos\u0026lt;D, 3\u0026gt;() == 2); // 2, position 3 can hold at most 2 elements This matches our initial manual test results. Next, we traverse all positions, find all extra array elements, and subtract these extras from the initial maximum number.\ntemplate \u0026lt;typename T, std::size_t N = 0\u0026gt; constexpr auto search_all_extra_index(auto\u0026amp;\u0026amp; array) { constexpr auto total = member_count\u0026lt;T\u0026gt;(); constexpr auto num = search_max_in_pos\u0026lt;T, N\u0026gt;(); constexpr auto value = num \u0026gt; 1 ? num : 1; array[N] = value; if constexpr (N + value \u0026lt; total) { search_all_extra_index\u0026lt;T, N + value\u0026gt;(array); } } Here, we recursively search, and the results are stored in the array. Note that N + value: if we find two elements here, we can directly skip two positions. For example, if position 1 can hold 2 elements, then we can directly go to position 3 without checking position 2.\nNext, we store the results in the array and subtract the extras.\ntemplate\u0026lt;typename T\u0026gt; constexpr auto true_member_count ","date":"26 December 2023","externalUrl":null,"permalink":"/en/articles/674157958/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003eIntroduction \n    \u003cdiv id=\"introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eIn \u003ccode\u003eC++17\u003c/code\u003e, a feature called \u003cstrong\u003estructured binding\u003c/strong\u003e was introduced, also known as \u003ccode\u003eStruct Bind\u003c/code\u003e. This feature is similar to pattern matching in other languages, allowing us to conveniently access the members of a structure.\u003c/p\u003e","title":"A 7-Year Relay Race: Obtaining the Number of Fields in a C++ Struct","type":"articles"},{"content":" Static vs Dynamic # The terms static typing and dynamic typing are familiar to many. The key distinction lies in the timing of type checking. What does this mean?\nConsider the following C++ code:\nstd::string s = \u0026#34;123\u0026#34;; int a = s + 1; We know that string cannot be directly added to int, so this should result in a TypeError. C++ checks for type errors at compile time, so this code will trigger a compile-time error.\nNow, consider the corresponding Python code:\ns = \u0026#34;123\u0026#34; a = s + 1 Python, on the other hand, checks for errors at runtime, so the above code will actually produce a runtime error.\nIt\u0026rsquo;s important to emphasize the meanings of compile time and runtime in this context. These terms are often encountered, but their meanings can vary depending on the context. Here, we define them as follows:\nCompile time: Refers to the period when code is being compiled into target code, before the program is executed.\nFor AOT (Ahead-Of-Time) compiled languages like C++, this is the process of compiling C++ into machine code. For JIT (Just-In-Time) compiled languages like C#/Java, this generally refers to the process of compiling source code into IR (Intermediate Representation). For transpiled languages like TypeScript, this is the process of compiling TypeScript into JavaScript. Runtime: Refers to the period when the program is actually running, such as when machine code is executed on the CPU or bytecode is executed on a virtual machine.\nThus, C++, Java, C#, and TypeScript are considered statically typed languages. Python, although it also compiles source code into bytecode, does not perform type checking during this stage, so Python is considered a dynamically typed language.\nHowever, this distinction is not absolute. The boundary between static and dynamic languages is not clear-cut. While C++, Java, C#, and TypeScript are statically typed, they provide various methods to bypass static type checking, such as pointer in C++, Object in Java/C#, and Any in TypeScript. Conversely, dynamically typed languages are increasingly incorporating static type checking, such as Python\u0026rsquo;s type hints and JavaScript\u0026rsquo;s TypeScript. Both paradigms are borrowing features from each other.\nCurrently, C++ only provides std::any for type erasure, but it is often not flexible enough. We desire more advanced features, such as accessing members by field names, calling functions by function names, and creating class instances by type names. The goal of this article is to construct a dynamic type in C++ similar to Java/C#\u0026rsquo;s Object.\nMeta Types # Here, we do not adopt the intrusive design (inheritance) used in Java/C#\u0026rsquo;s Object. Instead, we use a non-intrusive design called fat pointer. A fat pointer is essentially a structure containing a pointer to the actual data and a pointer to type information. In the case of inheritance, the virtual table pointer resides in the object\u0026rsquo;s header.\nclass Any { Type* type; // type info, similar to vtable void* data; // pointer to the data uint8_t flag; // special flag public: Any() : type(nullptr), data(nullptr), flag(0) {} Any(Type* type, void* data) : type(type), data(data), flag(0B00000001) {} Any(const Any\u0026amp; other); Any(Any\u0026amp;\u0026amp; other); ~Any(); template \u0026lt;typename T\u0026gt; Any(T\u0026amp;\u0026amp; value); // box value to Any template \u0026lt;typename T\u0026gt; T\u0026amp; cast(); // unbox Any to value Type* GetType() const { return type; } // get type info Any invoke(std::string_view name, std::span\u0026lt;Any\u0026gt; args); // call method void foreach(const std::function\u0026lt;void(std::string_view, Any\u0026amp;)\u0026gt;\u0026amp; fn); // iterate fields }; The member functions will be implemented in subsequent sections. First, let\u0026rsquo;s consider what is stored in the Type type.\nMeta Information # struct Type { std::string_view name; // type name void (*destroy)(void*); // destructor void* (*copy)(const void*); // copy constructor void* (*move)(void*); // move constructor using Field = std::pair\u0026lt;Type*, std::size_t\u0026gt;; // type and offset using Method = Any (*)(void*, std::span\u0026lt;Any\u0026gt;); // method std::unordered_map\u0026lt;std::string_view, Field\u0026gt; fields; // field info std::unordered_map\u0026lt;std::string_view, Method\u0026gt; methods; // method info }; The content here is straightforward. We store the type name, destructor, move constructor, copy constructor, field information, and method information in Type. Field information includes the field type and name, while method information includes the method name and function address. If further expansion is desired, information about parent classes and overloaded functions can also be included. Since this is just an example, we will not consider them for now.\nFunction Type Erasure # To store member functions of different types in the same container, we must perform type erasure on the functions. All types of functions are erased to the type Any(*)(void*, std::span\u0026lt;Any\u0026gt;). Here, Any is the type we defined earlier, void* represents the this pointer, and std::span\u0026lt;Any\u0026gt; is the function\u0026rsquo;s parameter list. Now, we need to consider how to perform this function type erasure.\nTake the member function say as an example:\nstruct Person { std::string_view name; std::size_t age; void say(std::string_view msg) { std::cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; say: \u0026#34; \u0026lt;\u0026lt; msg \u0026lt;\u0026lt; std::endl; } }; First, for convenience, let\u0026rsquo;s implement Any\u0026rsquo;s cast:\ntemplate \u0026lt;typename T\u0026gt; Type* type_of(); // type_of\u0026lt;T\u0026gt; returns type info of T template \u0026lt;typename T\u0026gt; T\u0026amp; Any::cast() { if(type != type_of\u0026lt;T\u0026gt;()) { throw std::runtime_error{\u0026#34;type mismatch\u0026#34;}; } return *static_cast\u0026lt;T*\u0026gt;(data); } Using the feature in C++ that allows non-capturing lambda to implicitly convert to function pointers, we can easily implement this erasure.\nauto f = +[](void* object, std::span\u0026lt;Any\u0026gt; args) { auto\u0026amp; self = *static_cast\u0026lt;Person*\u0026gt;(object); self.say(args[0].cast\u0026lt;std::string_view\u0026gt;()); return Any{}; }; The principle is simple: write a wrapper function to perform type conversion and forward the call. However, writing such forwarding code for each member function is cumbersome. We can consider using template metaprogramming to generate the code automatically, simplifying the type erasure process.\ntemplate \u0026lt;typename T\u0026gt; struct member_fn_traits; template \u0026lt;typename R, typename C, typename... Args\u0026gt; struct member_fn_traits\u0026lt;R (C::*)(Args...)\u0026gt; { using return_type = R; using class_type = C; using args_type = std::tuple\u0026lt;Args...\u0026gt;; }; template \u0026lt;auto ptr\u0026gt; auto* type_ensure() { using traits = member_fn_traits\u0026lt;decltype(ptr)\u0026gt;; using class_type = typename traits::class_type; using result_type = typename traits::return_type; using args_type = typename traits::args_type; return +[](void* object, std::span\u0026lt;Any\u0026gt; args) -\u0026gt; Any { auto self = static_cast\u0026lt;class_type*\u0026gt;(object); return [=]\u0026lt;std::size_t... Is\u0026gt;(std::index_sequence\u0026lt;Is...\u0026gt;) { if constexpr(std::is_void_v\u0026lt;result_type\u0026gt;) { (self-\u0026gt;*ptr)(args[Is].cast\u0026lt;std::tuple_element_t\u0026lt;Is, args_type\u0026gt;\u0026gt;()...); return Any{}; } else { return Any{(self-\u0026gt;*ptr)(args[Is].cast\u0026lt;std::tuple_element_t\u0026lt;Is, args_type\u0026gt;\u0026gt;()...)}; } }(std::make_index_sequence\u0026lt;std::tuple_size_v\u0026lt;args_type\u0026gt;\u0026gt;{}); }; } I won\u0026rsquo;t explain the code here. If you don\u0026rsquo;t understand, it\u0026rsquo;s okay. Essentially, it automates the process of type erasure for member functions using template metaprogramming. Just know how to use it. Using it is very simple. Here, \u0026amp;Person::say is the pointer-to-member syntax. If you\u0026rsquo;re not familiar, refer to C++ Member Pointers Explained.\nauto f = type_ensure\u0026lt;\u0026amp;Person::say\u0026gt;(); // decltype(f) =\u0026gt; Any (*)(void*, std::span\u0026lt;Any\u0026gt;) Type Information Registration # In fact, we need to generate a corresponding Type structure for each type to store its information, so that it can be accessed correctly. This functionality is handled by the type_of function mentioned earlier.\ntemplate \u0026lt;typename T\u0026gt; Type* type_of() { static Type type; type.name = typeid(T).name(); type.destroy = [](void* obj) { delete static_cast\u0026lt;T*\u0026gt;(obj); }; type.copy = [](const void* obj) { return (void*)(new T(*static_cast\u0026lt;const T*\u0026gt;(obj))); }; type.move = [](void* obj) { return (void*)(new T(std::move(*static_cast\u0026lt;T*\u0026gt;(obj)))); }; return \u0026amp;type; } template \u0026lt;\u0026gt; Type* type_of\u0026lt;Person\u0026gt;() { static Type type; type.name = \u0026#34;Person\u0026#34;; type.destroy = [](void* obj) { delete static_cast\u0026lt;Person*\u0026gt;(obj); }; type.copy = [](const void* obj) { return (void*)(new Person(*static_cast\u0026lt;const Person*\u0026gt;(obj))); }; type.move = [](void* obj) { return (void*)(new Person(std::move(*static_cast\u0026lt;Person*\u0026gt;(obj)))); }; type.fields.insert({\u0026#34;name\u0026#34;, {type_of\u0026lt;std::string_view\u0026gt;(), offsetof(Person, name)}}); type.fields.insert({\u0026#34;age\u0026#34;, {type_of\u0026lt;std::size_t\u0026gt;(), offsetof(Person, age)}}); type.methods.insert({\u0026#34;say\u0026#34;, type_ensure\u0026lt;\u0026amp;Person::say\u0026gt;()}); return \u0026amp;type; }; We provide a default implementation so that built-in basic types can automatically register some information. Then, we can specialize for custom types. Now, with this meta information, we can complete the implementation of Any\u0026rsquo;s member functions.\nComplete Implementation of Any # Any::Any(const Any\u0026amp; other) { type = other.type; data = type-\u0026gt;copy(other.data); flag = 0; } Any::Any(Any\u0026amp;\u0026amp; other) { type = other.type; data = type-\u0026gt;move(other.data); flag = 0; } template \u0026lt;typename T\u0026gt; Any::Any(T\u0026amp;\u0026amp; value) { type = type_of\u0026lt;std::decay_t\u0026lt;T\u0026gt;\u0026gt;(); data = new std::decay_t\u0026lt;T\u0026gt;(std::forward\u0026lt;T\u0026gt;(value)); flag = 0; } Any::~Any() { if(!(flag \u0026amp; 0B00000001) \u0026amp;\u0026amp; data \u0026amp;\u0026amp; type) { type-\u0026gt;destroy(data); } } void Any::foreach(const std::function\u0026lt;void(std::string_view, Any\u0026amp;)\u0026gt;\u0026amp; fn) { for(auto\u0026amp; [name, field]: type-\u0026gt;fields) { Any any = Any{field.first, static_cast\u0026lt;char*\u0026gt;(data) + field.second}; fn(name, any); } } Any Any::invoke(std::string_view name, std::span\u0026lt;Any\u0026gt; args) { auto it = type-\u0026gt;methods.find(name); if(it == type-\u0026gt;methods.end()) { throw std::runtime_error{\u0026#34;method not found\u0026#34;}; } return it-\u0026gt;second(data, args); } The implementation of foreach is to iterate over all Fields, get the offset and type, and then wrap it into an Any type. Note that this is just a simple wrapper; since we set the flag, this wrapper will not cause multiple destructions. invoke is to find the corresponding function from the member function list and call it.\nExample Code # int main() { Any person = Person{\u0026#34;Tom\u0026#34;, 18}; std::vector\u0026lt;Any\u0026gt; args = {std::string_view{\u0026#34;Hello\u0026#34;}}; person.invoke(\u0026#34;say\u0026#34;, args); // =\u0026gt; Tom say: Hello auto f = [](std::string_view name, Any\u0026amp; value) { if(value.GetType() == type_of\u0026lt;std::string_view\u0026gt;()) { std::cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; = \u0026#34; \u0026lt;\u0026lt; value.cast\u0026lt;std::string_view\u0026gt;() \u0026lt;\u0026lt; std::endl; } else if(value.GetType() == type_of\u0026lt;std::size_t\u0026gt;()) { std::cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; = \u0026#34; \u0026lt;\u0026lt; value.cast\u0026lt;std::size_t\u0026gt;() \u0026lt;\u0026lt; std::endl; } }; person.foreach(f); // name = Tom // age = 18 return 0; } The complete code is available on Github. With this, we have implemented a highly dynamic, non-intrusive Any.\nExtensions and Optimizations # This article provides a very simple introduction to the principles, and the scenarios considered are also very simple. For example, inheritance and function overloading are not considered, and there are several areas where runtime efficiency can be optimized. Nevertheless, the functionality I\u0026rsquo;ve implemented may still be more than you need. The main point of this article is to express that for a performance-focused language like C++, there are indeed scenarios where such dynamic features are needed. However, efficiency and generality are often contradictory. At the language level, because generality must be considered, efficiency often falls short. For example, RTTI and dynamic_cast are often complained about, but fortunately, compilers provide options to disable them. Similarly, my implementation may not fully fit your scenario, but understanding this not-too-difficult principle allows you to implement a version more suitable for your needs.\nPossible extensions:\nSupport modifying members by name. Add a global map to record information for all types, enabling the creation of class instances by class name. ... Possible optimizations:\nReduce the number of new calls, or implement an object pool. Currently, too much meta information is stored; you can tailor it according to your needs. Additionally, a current pain point is that all this meta information must be written manually, making it difficult to maintain. If the class definition is modified, the registration code must also be modified, or errors will occur. A practical solution is to use a code generator to automatically generate this mechanical code. For more on how to do this, refer to other articles in this series.\n","date":"3 December 2023","externalUrl":null,"permalink":"/en/articles/670191053/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003eStatic vs Dynamic \n    \u003cdiv id=\"static-vs-dynamic\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#static-vs-dynamic\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eThe terms static typing and dynamic typing are familiar to many. The key distinction lies in the timing of type checking. What does this mean?\u003c/p\u003e","title":"Implementing Object in C++!","type":"articles"},{"content":"","date":"3 December 2023","externalUrl":null,"permalink":"/en/series/reflection/","section":"Series","summary":"","title":"Reflection","type":"series"},{"content":" What is Metadata? # Consider the following Python code, where we aim to automatically modify the corresponding field values based on the input string:\nclass Person: def __init__(self, age, name): self.age = age self.name = name person = Person(10, \u0026#34;xiaohong\u0026#34;) setattr(person, \u0026#34;age\u0026#34;, 12) setattr(person, \u0026#34;name\u0026#34;, \u0026#34;xiaoming\u0026#34;) print(f\u0026#34;name: {person.name}, age: {person.age}\u0026#34;) # =\u0026gt; name: xiaoming, age: 12 setattr is a built-in function in Python that perfectly meets our needs. It modifies the corresponding value based on the input field name.\nHow can we achieve this in C++? C++ does not have a built-in setattr function. Here is a code example (for now, let\u0026rsquo;s consider only types that can be directly memcpyed, i.e., trivially copyable types):\nstruct Person { int age; std::string_view name; }; // Name -\u0026gt; Field offset, field size std::map\u0026lt;std::string_view, std::pair\u0026lt;std::size_t, std::size_t\u0026gt;\u0026gt; fieldInfo = { {\u0026#34;age\u0026#34;, {offsetof(Person, age), sizeof(int)}}, {\u0026#34;name\u0026#34;, {offsetof(Person, name), sizeof(std::string_view)}}, }; void setattr(Person* point, std::string_view name, void* data) { if (!fieldInfo.contains(name)) { throw std::runtime_error(\u0026#34;Field not found\u0026#34;); } auto\u0026amp; [offset, size] = fieldInfo[name]; std::memcpy(reinterpret_cast\u0026lt;char*\u0026gt;(point) + offset, data, size); } int main() { Person person = {.age = 1, .name = \u0026#34;xiaoming\u0026#34;}; int age = 10; std::string_view name = \u0026#34;xiaohong\u0026#34;; setattr(\u0026amp;person, \u0026#34;age\u0026#34;, \u0026amp;age); setattr(\u0026amp;person, \u0026#34;name\u0026#34;, \u0026amp;name); std::cout \u0026lt;\u0026lt; person.age \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; person.name \u0026lt;\u0026lt; std::endl; // =\u0026gt; 10 xiaohong } We have essentially implemented the setattr function ourselves, and this implementation seems to be generic. As long as we provide the fieldInfo for a specific type, it will work. The fieldInfo contains the field name, field offset, and field type size. This can be considered metadata. Additionally, metadata might include variable names, function names, etc. These pieces of information do not directly participate in the program\u0026rsquo;s execution but provide additional information about the program\u0026rsquo;s structure, data, types, etc. The content of metadata seems to be fixed and known to us since it exists in the program\u0026rsquo;s source code. Does the C/C++ compiler provide this functionality? The answer is: For programs in debug mode, some metadata might be retained for debugging purposes, but in release mode, nothing is retained. The benefit of this is obvious: since this information is not necessary for the program to run, not retaining it can significantly reduce the size of the binary executable.\nWhy is this Information Unnecessary, and When is it Needed? # Next, I will use the C language as an example to correlate its source code with its binary representation. Let\u0026rsquo;s see what information is actually needed for code execution.\nVariable Definition # int value; In fact, variable declarations do not have a direct binary representation. They merely inform the compiler to allocate a block of memory to store the variable named value. The size of the allocated memory is determined by its type. Therefore, if the type size is unknown at the time of variable declaration, a compilation error will occur.\nstruct A; A x; // error: storage size of \u0026#39;x\u0026#39; isn\u0026#39;t known A* y; // ok the size of pointer is always known struct Node { int val; Node next; }; // error Node is not a complete type // Essentially, the size of Node is still unknown at the time of its definition struct Node { int val; Node* next; }; // ok You might think this is somewhat similar to malloc, and indeed it is. The difference is that malloc allocates memory on the heap at runtime, whereas direct variable declarations typically allocate memory in the data segment or on the stack. The compiler might internally maintain a symbol table that maps variable names to their addresses. When you later operate on this variable, you are actually operating on this memory region.\nBuilt-in Operators # Built-in operators in C generally correspond directly to CPU instructions. As for how the CPU implements these operations, you can learn about digital electronics. Taking x86_64 as an example, the possible correspondences are as follows:\n| Operator | Meaning | Operator | Meaning | |----------|---------|----------|---------| | + | add | * | mul | | - | sub | / | div | | % | div | \u0026amp; | and | | \\| | or | ^ | xor | | ~ | not | \u0026lt;\u0026lt; | shl | | \u0026gt;\u0026gt; | shr | \u0026amp;\u0026amp; | and | | || | or | ! | not | | == | cmp | != | cmp | | \u0026gt; | cmp | \u0026gt;= | cmp | | \u0026lt; | cmp | \u0026lt;= | cmp | | ++ | inc | -- | dec | Assignment is likely accomplished through the mov instruction, for example:\na = 3; // mov [addressof(a)] 3 Structures # struct Point { int x; int y; } int main() { Point point; point.x = 1; point.y = 2; } The size of a structure can generally be calculated from its members, often considering memory alignment, and is determined by the compiler. For example, msvc. But in any case, the size of the structure is known at compile time, and we can also obtain the size of a type or variable through sizeof. Therefore, the Point point variable definition here is straightforward: the type size is known, and memory is allocated on the stack.\nNow, let\u0026rsquo;s focus on structure member access. In fact, C has a macro that can obtain the offset of a structure member relative to the structure\u0026rsquo;s starting address, called offsetof (even if we can\u0026rsquo;t obtain it, the compiler internally calculates the field offsets, so the offset information is always known to the compiler). For example, here offsetof(Point, x) is 0, and offsetof(Point, y) is 4. Therefore, the above code can be understood as:\nint main() { char point[sizeof(Point)]; // 8 = sizeof(Point) *(int*)(point + offsetof(Point, x)) = 1; // point.x = 1 *(int*)(point + offsetof(Point, y)) = 2; // point.y = 2 } The compiler might also maintain a symbol table for field names to offsets, and field names will eventually be replaced by offset. There is no need to retain them in the program.\nFunction Calls # Function calls are generally implemented through the function call stack, which is too common to elaborate on. Function names are eventually replaced by function addresses.\nSummary # Through the above analysis, you may have noticed that in C, symbol names, type names, variable names, function names, structure field names, etc., are all replaced by numbers, addresses, offsets, etc. Losing them does not affect the program\u0026rsquo;s execution. Therefore, they are discarded to reduce the size of the binary file. For C++, the situation is largely similar. C++ only retains some metadata in special cases, such as type_info, and you can manually disable RTTI to ensure that such information is not generated.\nWhen do we need to use this information? Obviously, the setattr introduced at the beginning requires it. When debugging a program, we need to know the variable names, function names, member names, etc., corresponding to an address to facilitate debugging, and we need this information at that time. When serializing a structure into json, we need to know its field names, and we need this information. When type erasure is performed to void*, we still need to know the actual type it corresponds to, and we need this information at that time. In summary, when we need to distinguish what a piece of binary content originally was at runtime, we need this information (of course, we also need it when we want to use this information for code generation at compile time).\nHow to Obtain This Information? # The C/C++ compiler does not provide us with an interface to obtain this information, but as mentioned earlier, this information is clearly in the source code. Variable names, function names, type names, field names. We can choose to manually understand the code and then manually store the metadata. For thousands of classes and dozens of member functions, it might take a few months to write. Just kidding, or we can write some programs, such as regular expression matching, to help us obtain this information? However, we have a better choice to obtain this information, and that is through the AST.\nAST (Abstract Syntax Tree) # AST stands for Abstract Syntax Tree. It is a data structure used in programming language processing to represent the abstract syntax structure of source code. The AST is the result of source code being processed by a parser, capturing the syntactic structure of the code but not all details, such as whitespace or comments. In the AST, each node represents a syntactic structure in the source code, such as variable declarations, function calls, loops, etc. These nodes are connected through parent-child and sibling relationships, forming a tree structure that is easier for computer programs to understand and process. If you have the clang compiler installed on your computer, you can use the following command to view the syntax tree of a source file:\nclang -Xclang -ast-dump -fsyntax-only \u0026lt;your.cpp\u0026gt; The output is as follows, with important information filtered out and irrelevant parts deleted:\n|-CXXRecordDecl 0x2103cd9c318 \u0026lt;col:1, col:8\u0026gt; col:8 implicit struct Point |-FieldDecl 0x2103cd9c3c0 \u0026lt;line:4:5, col:9\u0026gt; col:9 referenced x \u0026#39;int\u0026#39; |-FieldDecl 0x2103e8661f0 \u0026lt;line:5:5, col:9\u0026gt; col:9 referenced y \u0026#39;int\u0026#39; `-FunctionDecl 0x2103e8662b0 \u0026lt;line:8:1, line:13:1\u0026gt; line:8:5 main \u0026#39;int ()\u0026#39; `-CompoundStmt 0x2103e866c68 \u0026lt;line:9:1, line:13:1\u0026gt; |-DeclStmt 0x2103e866b30 \u0026lt;line:10:5, col:16\u0026gt; | `-VarDecl 0x2103e866410 \u0026lt;col:5, col:11\u0026gt; col:11 used point \u0026#39;Point\u0026#39;:\u0026#39;Point\u0026#39; callinit | `-CXXConstructExpr 0x2103e866b08 \u0026lt;col:11\u0026gt; \u0026#39;Point\u0026#39;:\u0026#39;Point\u0026#39; \u0026#39;void () noexcept\u0026#39; |-BinaryOperator 0x2103e866bb8 \u0026lt;line:11:5, col:15\u0026gt; \u0026#39;int\u0026#39; lvalue \u0026#39;=\u0026#39; | |-MemberExpr 0x2103e866b68 \u0026lt;col:5, col:11\u0026gt; \u0026#39;int\u0026#39; lvalue .x 0x2103cd9c3c0 | | `-DeclRefExpr 0x2103e866b48 \u0026lt;col:5\u0026gt; \u0026#39;Point\u0026#39;:\u0026#39;Point\u0026#39; lvalue Var 0x2103e866410 \u0026#39;point\u0026#39; \u0026#39;Point\u0026#39;:\u0026#39;Point\u0026#39; | `-IntegerLiteral 0x2103e866b98 \u0026lt;col:15\u0026gt; \u0026#39;int\u0026#39; 1 `-BinaryOperator 0x2103e866c48 \u0026lt;line:12:5, col:15\u0026gt; \u0026#39;int\u0026#39; lvalue \u0026#39;=\u0026#39; |-MemberExpr 0x2103e866bf8 \u0026lt;col:5, col:11\u0026gt; \u0026#39;int\u0026#39; lvalue .y 0x2103e8661f0 | `-DeclRefExpr 0x2103e866bd8 \u0026lt;col:5\u0026gt; \u0026#39;Point\u0026#39;:\u0026#39;Point\u0026#39; lvalue Var 0x2103e866410 \u0026#39;point\u0026#39; \u0026#39;Point\u0026#39;:\u0026#39;Point\u0026#39; `-IntegerLiteral 0x2103e866c28 \u0026lt;col:15\u0026gt; \u0026#39;int\u0026#39; 2 Alternatively, if you have the clangd plugin installed in vscode, you can right-click on a block of code and select show AST to view the ast of that code snippet. You can see that the source code content is indeed presented to us in a tree structure. Since it is a tree, we can freely traverse the tree nodes and filter to obtain the information we want. The above two examples are visual outputs. Typically, there are also direct code interfaces to obtain this information. For example, Python has a built-in ast module to obtain it, and C++ generally uses clang-related tools to obtain this content. If you want to know how to use clang tools specifically, you can refer to the article: Use clang tools to freely control C++ code!\nIf you are curious about how the compiler transforms source code into an ast, you can learn about the front-end content of compilation principles.\nHow to Store This Information? # This question might sound confusing, but in fact, it is a question that only C++ programmers need to consider.\nActually, everything is caused by constexpr. Storing information like this:\nstruct FieldInfo { std::string_view name; std::size_t offset; std::size_t size; }； struct Point { int x; int y; }； constexpr std::array\u0026lt;FieldInfo, 2\u0026gt; fieldInfos = {{ {\u0026#34;x\u0026#34;, offsetof(Point, x), sizeof(int)}, {\u0026#34;y\u0026#34;, offsetof(Point, y), sizeof(int)}, }}; Means that we can not only query this information at runtime but also at compile time.\nFurthermore, it can be stored in template parameters, so that even types can be stored:\ntemplate\u0026lt;fixed_string name, std::size_t offset, typename Type\u0026gt; struct Field{}; using FieldInfos = std::tuple \u0026lt; Field\u0026lt;\u0026#34;x\u0026#34;, offsetof(Point, x), int\u0026gt;, Field\u0026lt;\u0026#34;y\u0026#34;, offsetof(Point, y), int\u0026gt; \u0026gt;; This undoubtedly gives us more room for operation. So, what should we do next with this information? In fact, we can choose to generate code based on this information. For related content, you can browse other sections in the series of articles.\n","date":"3 December 2023","externalUrl":null,"permalink":"/en/articles/670190357/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003eWhat is Metadata? \n    \u003cdiv id=\"what-is-metadata\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#what-is-metadata\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eConsider the following \u003ccode\u003ePython\u003c/code\u003e code, where we aim to automatically modify the corresponding field values based on the input string:\u003c/p\u003e","title":"Why Do C/C++ Compilers Not Retain Metadata?","type":"articles"},{"content":"Clang is a compiler front-end for the C family of languages provided by the LLVM project. It was initially developed to replace the C front-end of the GNU Compiler Collection (GCC), aiming to offer faster compilation, better diagnostic information, and a more flexible architecture. Clang includes front-ends for C, C++, and Objective-C, designed to be embeddable in other projects. A key feature of Clang is its modular architecture, which allows developers to easily extend and customize the compiler\u0026rsquo;s functionality. Clang is widely used in many projects, including LLVM itself, the development of some operating system kernels, and the implementation of compilers for some programming languages.\nIn addition to being used as a compiler, Clang can also be provided as a library, enabling developers to leverage the compiler\u0026rsquo;s capabilities in their applications, such as source code analysis and generation. Clang can be used to obtain the Abstract Syntax Tree (AST) of C++ source files for further processing. This article will introduce how to use Clang tools.\nInstallation \u0026amp; Usage # Currently, Clang is divided into the following libraries and tools: libsupport, libsystem, libbasic, libast, liblex, libparse, libsema, libcodegen, librewrite, libanalysis. Since Clang itself is written in C++, the related interfaces are all in C++. However, due to the complexity and instability of C++ interfaces (for example, DLLs compiled by GCC on Windows cannot be used by MSVC, or API changes due to Clang version upgrades leading to incompatibility), the official does not recommend prioritizing the use of C++ interfaces.\nIn addition to C++ interfaces, the official also provides a C interface called libclang, which is not only relatively simple to use but also quite stable. The only drawback is that it cannot obtain the complete C++ Abstract Syntax Tree (AST), but given that the complete syntax tree of C++ is extremely complex, often we only need a small part of the information, so this issue can usually be ignored unless you really have such a requirement.\nIf you want to use libclang, you need to install LLVM and Clang first. On the LLVM Release page, there are several pre-release binary packages available for download. If you have customization needs, please refer to the Getting Started page for manual compilation. After installation, simply link the libclang.dll from the llvm/lib directory to your program and include the clang-c/Index.h header file from the llvm/include directory to use it.\nHowever, since C language lacks some high-level abstractions, even manipulating strings can be cumbersome. If used on a large scale, we need to encapsulate a layer in C++ ourselves. Fortunately, the official also provides a Python binding based on this C interface, namely the clang package, which makes it more convenient to use. However, the Python binding provided by the official does not package the libclang DLL, so you still need to manually configure the LLVM environment on your computer, which can be a bit troublesome. However, someone in the community has provided a packaged version on PyPI: libclang.\nSo if you want to use libclang to obtain the C++ syntax tree, you just need\npip install libclang No additional steps are required. This article is based on this Python binding version. The C version API and the Python version API are basically identical. If you find Python performance insufficient, you can also refer to this tutorial to write C version code. Additionally, the official package does not provide type hints, so writing in Python lacks code completion and is not comfortable to use. I have added a type hint cindex.pyi, which can be downloaded and placed in the same folder to enable code hints.\nQuick Start # The example C++ source file code is as follows\n// main.cpp struct Person { int age; const char* name; }; int main() { Person person = {1, \u0026#34;John\u0026#34;}; return 0; } The Python code to parse it is as follows\nimport clang.cindex as CX def traverse(node: CX.Cursor, prefix=\u0026#34;\u0026#34;, is_last=True): branch = \u0026#34;└──\u0026#34; if is_last else \u0026#34;├──\u0026#34; text = f\u0026#34;{str(node.kind).removeprefix(\u0026#39;CursorKind.\u0026#39;)}: {node.spelling}\u0026#34; if node.kind == CX.CursorKind.INTEGER_LITERAL: value = list(node.get_tokens())[0].spelling text = f\u0026#34;{text}{value}\u0026#34; print(f\u0026#34;{prefix}{branch} {text}\u0026#34;) new_prefix = prefix + (\u0026#34; \u0026#34; if is_last else \u0026#34;│ \u0026#34;) children = list(node.get_children()) for child in children: traverse(child, new_prefix, child is children[-1]) index = CX.Index.create(excludeDecls=True) tu = index.parse(\u0026#39;main.cpp\u0026#39;, args=[\u0026#39;-std=c++20\u0026#39;]) traverse(tu.cursor) The output is as follows\nTRANSLATION_UNIT: main.cpp ├── STRUCT_DECL: Person │ ├── FIELD_DECL: age │ └── FIELD_DECL: name └── FUNCTION_DECL: main └── COMPOUND_STMT: ├── DECL_STMT: │ └── VAR_DECL: person │ ├── TYPE_REF: struct Person │ └── INIT_LIST_EXPR: │ ├── INTEGER_LITERAL: 1 │ └── STRING_LITERAL: \u0026#34;John\u0026#34; └── RETURN_STMT: └── INTEGER_LITERAL: 0 The front part is the syntax tree node type, and the back part is the node content. It can be seen that it is very clear and almost corresponds to the source code one by one.\nBasic Types # Note, this article assumes that the reader has some understanding of syntax trees and will not introduce them in detail here. If you don\u0026rsquo;t know what a syntax tree is, you can take a look at Why C/C++ Compilers Do Not Retain Meta Information. Below is an introduction to some commonly used types in cindex\nCursor # Equivalent to the basic node of the syntax tree, the entire syntax tree is composed of Cursor. The kind property returns a CursorKind type enumeration value, which represents the actual type corresponding to this node.\nfor kind in CursorKind.get_all_kinds(): print(kind) This can print all supported node types, or you can directly view the source code. Cursor also has some other properties and methods for us to use, commonly used are as follows:\n@property def spelling(self) -\u0026gt; str: @property def displayname(self) -\u0026gt; str: @property def mangled_name(self) -\u0026gt; str: Get the name of the node, for example, for a variable declaration node, its spelling is the name of the variable. The displayname is the short name of the node, which is usually the same as spelling. But sometimes there are differences, for example, the spelling of a function will include the parameter types, such as func(int), but its displayname is just func. The mangled_name is the name of the symbol after name mangling for linking.\n@property def type(self) -\u0026gt; Type: The type of the node element, for example, for a variable declaration node, its type is the type of the variable. Or for a field declaration node, its type is the type of the field. The return type is Type.\n@property def location(self) -\u0026gt; SourceLocation: The location information of the node, the return type is SourceLocation, which carries the line number, column number, file name and other information of the node in the source code.\n@property def extent(self) -\u0026gt; SourceRange: The range information of the node, the return type is SourceRange, composed of two SourceLocation, which carries the start and end positions of the node in the source code.\n@property def access_specifier(self) -\u0026gt; AccessSpecifier: The access permission of the node, the return type is AccessSpecifier. There are five types: PUBLIC, PROTECTED, PRIVATE, NONE, INVALID.\ndef get_children(self) -\u0026gt; iterable[Cursor]: Get all child nodes, the return type is iterable of Cursor. This function is the most commonly used, because we can traverse the entire syntax tree recursively.\ndef get_tokens(self) -\u0026gt; iterable[Token]: Get all tokens representing the node, the return type is iterable of Token. token is the smallest unit of the syntax tree, for example, for a variable declaration node, its tokens are int, a, ;. This function can be used to obtain some detailed information, such as obtaining the values of integer literals and floating-point literals.\ndef is_definition(self) -\u0026gt; bool: def is_const_method(self) -\u0026gt; bool: def is_converting_constructor(self) -\u0026gt; bool: def is_copy_constructor(self) -\u0026gt; bool: def is_default_constructor(self) -\u0026gt; bool: def is_move_constructor(self) -\u0026gt; bool: def is_default_method(self) -\u0026gt; bool: def is_deleted_method(self) -\u0026gt; bool: def is_copy_assignment_operator_method(self) -\u0026gt; bool: def is_move_assignment_operator_method(self) -\u0026gt; bool: def is_mutable_field(self) -\u0026gt; bool: def is_pure_virtual_method(self) -\u0026gt; bool: def is_static_method(self) -\u0026gt; bool: def is_virtual_method(self) -\u0026gt; bool: def is_abstract_record(self) -\u0026gt; bool: def is_scoped_enum(self) -\u0026gt; bool: These functions are basically self-explanatory, for example, is_definition is to determine whether the node is a definition, is_const_method is to determine whether the node is a const method.\nType # If the node has a type, it represents the type of the node. Commonly used properties are\n@property def kind(self) -\u0026gt; TypeKind: The type of the type, the return type is TypeKind. For example, INT, FLOAT, POINTER, FUNCTIONPROTO, etc.\n@property def spelling(self) -\u0026gt; str: The name of the type, for example, int, float, void, etc.\ndef get_align(self) -\u0026gt; int: def get_size(self) -\u0026gt; int: def get_offset(self, fieldname: str) -\u0026gt; int: Get the alignment, size, field offset, etc. of the type.\nAnd some functions starting with is, such as is_const_qualified, is_function_variadic, is_pod, etc. I won\u0026rsquo;t go into detail here.\nTranslationUnit # Generally, a C++ source file represents a TranslationUnit, which is what we often call a compilation unit.\nCommonly used are\n@property def cursor(self) -\u0026gt; Cursor: Get the root node of the TranslationUnit, which is the Cursor of type TRANSLATION_UNIT.\n@property def spelling(self) -\u0026gt; str: Get the file name of the TranslationUnit.\ndef get_includes(self, depth: int = -1) -\u0026gt; iterable[FileInclusion]: Get all includes of the TranslationUnit, the return type is a list of FileInclusion. Note that since the included files may contain other files, you can use the depth parameter to limit it. For example, if you only want to get the first layer, that is, the directly included header files, you can write it like this.\nindex = CX.Index.create() tu = index.parse(\u0026#39;main.cpp\u0026#39;, args=[\u0026#39;-std=c++20\u0026#39;]) for file in tu.get_includes(): if file.depth == 1: print(file.include.name) This will print all directly used header files.\nIndex # An Index is a collection of TranslationUnits, which are eventually linked together to form an executable file or library.\nThere is a static method create to create a new Index, and then the member method parse can parse a C++ source file and return a TranslationUnit.\ndef parse(self, path: str, args: list[str] | None = ..., unsaved_files: list[tuple[str, str]] | None = ..., options: int = ...) -\u0026gt; TranslationUnit: path is the source file path, args is the compilation parameters, unsaved_files is the unsaved files, options are some parameters defined in TranslationUnit.PARSE_XXX, such as PARSE_SKIP_FUNCTION_BODIES and PARSE_INCOMPLETE. It can be used to customize the parsing process, speed up parsing, or retain macro information, etc.\nExamples # Namespace # Since clang will expand all header files when parsing, the output content is too much. But we may mainly want the information of our own code, so we can use namespaces for filtering. The example is as follows:\n#include \u0026lt;iostream\u0026gt; namespace local { struct Person { int age; std::string name; }; } The parsing code is as follows\nimport clang.cindex as CX def traverse_my(node: CX.Cursor): if node.kind == CX.CursorKind.NAMESPACE: if node.spelling == \u0026#34;local\u0026#34;: traverse(node) # forward to the previous function for child in node.get_children(): traverse_my(child) index = CX.Index.create() tu = index.parse(\u0026#39;main.cpp\u0026#39;, args=[\u0026#39;-std=c++20\u0026#39;]) traverse_my(tu.cursor) Write a function to filter the namespace name, and then forward it to our previous function, so that only the content in the namespace we want will be output.\nClass \u0026amp; Struct # We mainly want to get the field names, types, method names, types, etc. inside them, the example is as follows:\nstruct Person { int age; const char* name; void say_hello(int a, char b); }; The parsing code is as follows\ndef traverse_class(node: CX.Cursor): match node.kind: case CX.CursorKind.STRUCT_DECL | CX.CursorKind.CLASS_DECL: print(f\u0026#34;Class: {node.spelling}:\u0026#34;) case CX.CursorKind.FIELD_DECL: print(f\u0026#34; Field: {node.spelling}: {node.type.spelling}\u0026#34;) case CX.CursorKind.CXX_METHOD: print(f\u0026#34; Method: {node.spelling}: {node.type.spelling}\u0026#34;) for arg in node.get_arguments(): print(f\u0026#34; Param: {arg.spelling}: {arg.type.spelling}\u0026#34;) for child in node.get_children(): traverse_class(child) # Class: Person: # Field: age: int # Field: name: const char * # Method: say_hello: void (int, char) # Param: a: int # Param: b: char Comment # You can get Doxygen-style comments\n@property def brief_comment(self) -\u0026gt; str: @property def raw_comment(self) -\u0026gt; str: brief_comment gets the content after @brief, raw_comment gets the entire comment content.\n/** * @brief func description * @param param1 * @return int */ int func(int param1){ return param1 + 10000000; } The parsing code is as follows\ndef traverse_comment(node: CX.Cursor): if node.brief_comment: print(f\u0026#34;brief_comment =\u0026gt; {node.brief_comment}\u0026#34;) if node.raw_comment: print(f\u0026#34;raw_comment =\u0026gt; {node.raw_comment}\u0026#34;) for child in node.get_children(): traverse_comment(child) # brief_comment =\u0026gt; func description # raw_comment =\u0026gt; /** # * @brief func description # * @param param1 # * @return int # */ Enum # Get the enumeration name and corresponding enumeration constant values, as well as its underlying type\nenum class Color{ RED = 0, GREEN, BLUE }; The parsing code is as follows\ndef traverse_enum(node: CX.Cursor): if node.kind == CX.CursorKind.ENUM_DECL: print(f\u0026#34;enum: {node.spelling}, underlying type: {node.enum_type.spelling}\u0026#34;) print(f\u0026#34;is scoped?: {node.is_scoped_enum()}\u0026#34;) for child in node.get_children(): print(f\u0026#34; enum_value: {child.spelling}: {child.enum_value}\u0026#34;) for child in node.get_children(): traverse_enum(child) # enum: Color, underlying type: int # is scoped?: True # enum_value: RED: 0 # enum_value: GREEN: 1 # enum_value: BLUE: 2 Attribute # C++11 introduced a new attribute syntax: [[ ... ]], which can be used to add additional information to functions or variables. For example, [[nodiscard]] and [[deprecated]]. But sometimes we define some markers ourselves for our preprocessing tools to use, such as marking whether a type needs to generate meta-information, and we also hope that these markers can be recognized by libclang. Unfortunately, if you directly write attributes not supported by the standard, they will be ignored by libclang, that is, they will not appear in the final AST.\nstruct [[Reflect]] Person{}; // ignored A feasible solution is to use get_tokens to get all tokens in the declaration\n","date":"29 November 2023","externalUrl":null,"permalink":"/en/articles/669360731/","section":"Articles","summary":"\u003cp\u003eClang is a compiler front-end for the C family of languages provided by the LLVM project. It was initially developed to replace the C front-end of the GNU Compiler Collection (GCC), aiming to offer faster compilation, better diagnostic information, and a more flexible architecture. Clang includes front-ends for C, C++, and Objective-C, designed to be embeddable in other projects. A key feature of Clang is its modular architecture, which allows developers to easily extend and customize the compiler\u0026rsquo;s functionality. Clang is widely used in many projects, including LLVM itself, the development of some operating system kernels, and the implementation of compilers for some programming languages.\u003c/p\u003e","title":"Harness the Power of C++ Code with Clang Tools","type":"articles"},{"content":" Introduction # Let\u0026rsquo;s start with a recent requirement as an introduction. We all know that markdown can use lang to insert code blocks and supports syntax highlighting. However, I wanted to support custom syntax highlighting rules and encountered the following issues:\nSome websites render markdown statically and cannot run scripts, so it\u0026rsquo;s not possible to directly call JavaScript syntax highlighting libraries. For example, rendering markdown files on Github. The languages supported are generally determined by the rendering engine. For instance, the languages supported by Github\u0026rsquo;s rendering engine differ from others. Writing extensions for different rendering engines would require a lot of work, and there is little documentation available. Is there really no solution? Well, there is a way. Fortunately, most engines support using HTML rules directly, such as \u0026lt;code\u0026gt; for rendering.\n\u0026lt;code style= \u0026#34;color: #5C6370;font-style: italic;\u0026#34;\u0026gt; # this a variable named \u0026amp;#x27;a\u0026amp;#x27; \u0026lt;/code\u0026gt; This provides the possibility to add custom styles. However, we can\u0026rsquo;t manually write such code in the markdown source file. If a statement has three different colors, such as let a = 3;, it means we have to write three different \u0026lt;span\u0026gt; tags for just one statement. It\u0026rsquo;s very difficult to write and maintain.\nIn fact, we can do this: read the markdown source file, write the source file in normal markdown syntax, and when we encounter lang, extract the text and pass it to a rendering library to render it into DOM text. I chose the highlight.js library. Then replace the original text and output it in a new folder, such as \u0026lsquo;out\u0026rsquo; for the new folder and \u0026lsquo;src\u0026rsquo; for the original. This way, the source file doesn\u0026rsquo;t need any modification, and the actual rendering is done with the content in the \u0026lsquo;out\u0026rsquo; folder. Every time we change the source file, we just need to run this program to do the conversion.\nWhat is Code Generation? # The above case is a typical example of using \u0026lsquo;code generation\u0026rsquo; to solve problems. So what exactly is code generation? It is actually a very broad term. Generally speaking,\nCode generation refers to the process of using computer programs to generate other programs or code.\nThis includes but is not limited to:\nCompiler generating target code: This is the most typical example, where a compiler translates source code from a high-level programming language into machine-executable target code. Using configuration files or DSL to generate code: Generate actual code through specific configuration files or domain-specific languages (DSL). An example is using XML configuration files to define a UI interface, then generating the corresponding code. Language built-in features generating code: Some programming languages have built-in features such as macros, generics, etc., which can generate code at compile time or runtime. Such mechanisms can improve code flexibility and reusability. External code generators: Some frameworks or libraries use external code generators to create the required code. For example, the Qt framework uses the Meta-Object Compiler (MOC) to handle the meta-object system, generating code related to signals and slots. Below are some specific examples for these points:\nCompile-time Code Generation # Macros # The macro in C language is one of the most classic and simplest compile-time code generation techniques. Pure text replacement, for example, if we want to repeat the string \u0026quot;Hello World\u0026quot; 100 times. What should we do? Obviously, we don\u0026rsquo;t want to manually copy and paste. Consider using macros to accomplish this task.\n#define REPEAT(x) (REPEAT1(x) REPEAT1(x) REPEAT1(x) REPEAT1(x) REPEAT1(x)) #define REPEAT1(x) REPEAT2(x) REPEAT2(x) REPEAT2(x) REPEAT2(x) REPEAT2(x) #define REPEAT2(x) x x x x int main(){ const char* str = REPEAT(\u0026#34;Hello world \u0026#34;); } Here, we mainly use a feature in C language where \u0026quot;a\u0026quot;\u0026quot;b\u0026quot; is equivalent to \u0026quot;ab\u0026quot;. Then, through macro expansion, 5*5*4 exactly one hundred times, we easily complete this task. Of course, the macros in C language are essentially just token replacements and do not allow users to obtain the token stream for input analysis, so their functionality is very limited. Nevertheless, there are still some interesting uses. Those interested can read this article The Art of Macro Programming in C/C++. Of course, macros are not unique to C language; other programming languages also have them and can support stronger features. For example, the flexibility of macros in Rust is much stronger than in C language, mainly because Rust allows you to analyze the input token stream, rather than simply performing replacements. You can generate different code based on different input tokens. Even more, macros in Lisp are super flexible.\nGenerics/Templates # In some programming languages, generics (Generic) are also considered a code generation technique, generating actual different code based on different types. Of course, this is the most basic. Some programming languages support more powerful features, such as template metaprogramming in C++ for some advanced code generation. A typical case is creating a function pointer table (jump table) at compile time.\ntemplate\u0026lt;std::size_t N, typename T, typename F\u0026gt; void helper(T t, F f) { f(std::get\u0026lt;N\u0026gt;(t)); } template\u0026lt;typename Tuple, typename Func\u0026gt; constexpr void access(std::size_t index, Tuple\u0026amp;\u0026amp; tuple, Func\u0026amp;\u0026amp; f){ constexpr auto length = std::tuple_size\u0026lt;std::decay_t\u0026lt;decltype(tuple)\u0026gt;\u0026gt;::value; using FuncType = void (*)(decltype(tuple), decltype(f)); constexpr auto fn_table = []\u0026lt;std::size_t... I\u0026gt;(std::index_sequence\u0026lt;I...\u0026gt;){ std::array\u0026lt;FuncType, length\u0026gt; table = { helper\u0026lt;I, decltype(tuple), decltype(f)\u0026gt;... }; return table; }(std::make_index_sequence\u0026lt;length\u0026gt;{}); return fn_table[index](std::forward\u0026lt;Tuple\u0026gt;(tuple), std::forward\u0026lt;Func\u0026gt;(f)); } int main(){ std::tuple a = { 1, \u0026#39;a\u0026#39;, \u0026#34;123\u0026#34; }; auto f = [](auto\u0026amp;\u0026amp; v) { std::cout \u0026lt;\u0026lt; v \u0026lt;\u0026lt; std::endl; }; std::size_t index = 0; access(index, a, f); // =\u0026gt; 1 index = 2; access(index, a, f); // =\u0026gt; 123 } This way, we achieve the effect of accessing elements in a tuple based on the runtime index. The specific principle is manually creating a function pointer table and dispatching based on the index.\nCode Generators # The above two points discuss language built-in features. However, in many scenarios, the built-in features of languages are not flexible enough to meet our needs. For example, in C++, if you want to generate functions and types in chunks, neither macros nor templates can do it.\nBut code is just strings in source files. Based on this idea, we can completely write a specialized program to generate such strings. For example, write a python code to generate the above C program that repeats Hello World 100 times.\ns = \u0026#34;\u0026#34;; for i in range(100): s += \u0026#39;\u0026#34;Hello World \u0026#34;\u0026#39; code = f\u0026#34;\u0026#34;\u0026#34; int main() {{ const char* str = {s}; }}\u0026#34;\u0026#34;\u0026#34; with open(\u0026#34;hello.c\u0026#34;, \u0026#34;w\u0026#34;) as file: file.write(code) This way, we generate the above source file. Of course, this is just the simplest application. Or we can use Protocol Buffer to automatically generate serialization and deserialization code. Or we can obtain information from the AST, and even the type\u0026rsquo;s meta-information can be generated by the code generator. The principle of such programs is simple, just string concatenation, and their upper limit depends entirely on how your code is written.\nBut more often, language built-in features are more convenient to use. Using external code generators can complicate the compilation process. However, some languages have made this feature a built-in feature of the language, such as C#\u0026rsquo;s code generation.\nRuntime Code Generation # exec # Alright, we\u0026rsquo;ve talked a lot about static language features. Now let\u0026rsquo;s look at some sufficiently dynamic code generation. First, let\u0026rsquo;s look at features like eval and exec in languages like Python/JavaScript, which allow us to load strings as code and execute them at runtime.\neval is a mechanism that parses strings into executable code. In Python, the eval function can take a string as a parameter and execute the expression within it, returning the result. This provides a powerful tool for dynamic computation and code generation. result = eval(\u0026#34;2 + 3\u0026#34;) print(result) # Output: 5 exec is different from eval in that exec can execute multiple statements, even including function and class definitions. Copy code code_block = \u0026#34;\u0026#34;\u0026#34; def multiply(x, y): return x * y result = multiply(4, 5) \u0026#34;\u0026#34;\u0026#34; exec(code_block) print(result) # Output: 20 Undoubtedly, generating code at runtime through string concatenation can easily meet some demanding requirements in appropriate scenarios.\nDynamic Compilation # Now there is a question, can C language achieve the above dynamic compilation features? Of course, you might say we can implement a C language interpreter, then naturally it can be done. But actually, there is a simpler way.\nThere are mainly two points:\nCompile code at runtime If you have gcc installed on your computer, you can run the following two commands:\n# Compile the source file into an object file gcc -c source.c source.o # Extract the .text section from the object file to generate a binary file objcopy -O binary -j .text source.o source.bin This way, we can obtain the binary form of the code in the source.c file. But having the code is not enough; we need to execute it.\nAllocate executable memory Code is also binary data. As long as we write the obtained code data into a block of memory and then jmp to execute it, it should work, right? The idea is straightforward, but unfortunately, most operating systems have memory protection, and generally allocated memory is not executable. If you try to write data and then execute it, it will directly cause a segmentation fault. But we can use VirtualAlloc or mmap to allocate a block of memory with execution permissions, write the code into it, and then execute it.\n// Windows VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_EXECUTE_READWRITE); // Linux mmap(NULL, size, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0); Combining these two points and making some adjustments, we can achieve reading code and input from the command line and directly running the output.\n#include \u0026lt;fstream\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #ifdef _WIN32 #include \u0026lt;Windows.h\u0026gt; #define Alloc(size) VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_EXECUTE_READWRITE) #elif __linux__ #include \u0026lt;sys/mman.h\u0026gt; #define Alloc(size) mmap(NULL, size, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0) #endif int main(int argc, char* argv[]) { std::ofstream(\u0026#34;source.c\u0026#34;) \u0026lt;\u0026lt; argv[1]; system(\u0026#34;gcc -c source.c \u0026amp;\u0026amp; objcopy -O binary -j .text source.o source.bin\u0026#34;); std::ifstream file(\u0026#34;source.bin\u0026#34;, std::ios::binary); std::string source((std::istreambuf_iterator\u0026lt;char\u0026gt;(file)), {}); auto p = Alloc(source.size()); memcpy(p, source.c_str(), source.size()); using Fn = int (*)(int, int); std::cout \u0026lt;\u0026lt; reinterpret_cast\u0026lt;Fn\u0026gt;(p)(std::stoi(argv[2]), std::stoi(argv[3])) \u0026lt;\u0026lt; std::endl; return 0; } The final effect:\n.\\main.exe \u0026#34;int f(int a, int b){ return a + b; }\u0026#34; 1 2 # output: 3 .\\main.exe \u0026#34;int f(int a, int b){ return a - b; }\u0026#34; 1 2 # output: -1 Perfect implementation.\nConclusion # This article mainly introduces some basic concepts and examples of code generation, as well as some simple applications. Code generation is a very powerful technology. If we only focus on the built-in features of programming languages, we often cannot meet some complex requirements. If we broaden our perspective, we will unexpectedly discover a new world. This is one of the articles in the Reflection series, welcome to read other articles in the series!\n","date":"29 November 2023","externalUrl":null,"permalink":"/en/articles/669359855/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003eIntroduction \n    \u003cdiv id=\"introduction\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eLet\u0026rsquo;s start with a recent requirement as an introduction. We all know that markdown can use \u003ccode\u003elang\u003c/code\u003e to insert code blocks and supports syntax highlighting. However, I wanted to support custom syntax highlighting rules and encountered the following issues:\u003c/p\u003e","title":"Various Approaches to Code Generation","type":"articles"},{"content":" What is Reflection? # The term \u0026ldquo;Reflection\u0026rdquo; is likely familiar to many, even if you haven\u0026rsquo;t used it, you\u0026rsquo;ve probably heard of it. However, like many other jargon in the field of computer science, there isn\u0026rsquo;t a clear and precise definition for reflection. This leads to situations where, for languages like C#, Java, and Python that have reflection, discussing reflection naturally brings to mind the corresponding facilities, APIs, and code examples in those languages, making it very concrete. However, for languages like C, C++, and Rust that lack reflection, when people talk about reflection, there\u0026rsquo;s often uncertainty about what exactly is being referred to, making it very abstract. For example, someone once told me that Rust has reflection, citing the official Rust documentation\u0026rsquo;s introduction to the std::Any module, which mentions:\nUtilities for dynamic typing or type reflection\nBut the awkwardness lies in the fact that if you consider it as reflection, its functionality is quite limited; if you say it\u0026rsquo;s not, well, you could argue that it somewhat embodies reflection.\nSimilar situations frequently occur in C++. You might often hear opinions like: C++ only has very weak reflection, namely RTTI (Run Time Type Information), but some frameworks like QT and UE have implemented their own reflection. In recent discussions, blogs, or proposals for new C++ standards, you might also hear terms like:\nStatic reflection Dynamic reflection Compile-time reflection Runtime reflection These terms can be quite confusing and overwhelming. Moreover, prefixes like static, dynamic, compile-time, and runtime are themselves jargon, often combined with various terms, carrying many meanings depending on the context.\nSome readers might say, \u0026ldquo;I checked Wikipedia, and reflection does have a definition, as follows:\nIn computer science, reflective programming or reflection is the ability of a process to examine, introspect, and modify its own structure and behavior.\nFirst, Wikipedia is written by people and isn\u0026rsquo;t absolutely authoritative; if you\u0026rsquo;re dissatisfied with this definition, you can modify it yourself. Second, the wording here is quite vague. What does introspection (introspect) mean? Self-reflection, but what does that mean in the context of computer science? So this definition is also quite awkward. What to do then? I choose to break it down into several processes for explanation, so we don\u0026rsquo;t have to struggle with the conceptual question of \u0026ldquo;what exactly is reflection.\u0026rdquo; Instead, by understanding these processes, you\u0026rsquo;ll naturally grasp what reflection is doing.\nHow to Understand Reflection? # Reflection in all languages can be seen as the following three steps:\nGenerate Metadata # First, what is metadata (Metadata)? When we write code, we name variables, types, struct fields, etc. These names are mainly for programmers to understand and maintain the source code. For C/C++, these names are usually discarded after compilation to save binary space, which is understandable. For a detailed discussion, see Why C/C++ Compilers Do Not Retain Metadata.\nBut gradually, we found that in some cases, we need this data. For example, when serializing a struct into json, we need the struct field names, or when printing logs, we don\u0026rsquo;t want to print enum values but the corresponding enum names. What to do? Early on, the only way was through hard coding, i.e., writing it manually, or using macros for more advanced cases. This was quite inconvenient and not conducive to future code maintenance.\nLater, some languages, like Java and C#, their compilers would retain a lot of data, including these names, during compilation. This data is called metadata (Metadata). Additionally, there are ways for programmers to attach metadata to certain structures themselves, such as C#\u0026rsquo;s attribute and Java\u0026rsquo;s annotation.\nWhat about C++? Currently, C++ compilers only retain type names for implementing RTTI, i.e., facilities related to std::type_info in the standard. Other information is stripped away by the compiler. What to do? Manually writing metadata is acceptable for a small number of classes, but as the project scale increases, such as having dozens or hundreds of classes, it becomes very tedious and error-prone. In fact, we can run a script before actual compilation to generate this data, known as code generation (Code Generation). For related content, see Using Clang Tools to Freely Manipulate C++ Code.\nQuery Metadata # After generation, the next step is querying metadata. Many languages\u0026rsquo; built-in reflection modules, such as Python\u0026rsquo;s inspect, Java\u0026rsquo;s Reflection, and C#\u0026rsquo;s System.Reflection, essentially encapsulate some operations, making it more convenient for users to access metadata without directly dealing with raw data.\nIt\u0026rsquo;s worth noting that the queries in the above cases occur at runtime. Searching and matching based on strings at runtime is a relatively slow process, which is why we often say that reflective method calls are slower than normal method calls.\nFor C++, the compiler provides some limited interfaces for us to access (reflect) some information at compile time, such as using decltype to get a variable\u0026rsquo;s type, further determining if two variable types are equal, or if one is a subclass of another, but the functionality is quite limited.\nHowever, you can generate metadata yourself as described in the previous section, mark them as constexpr, and then query them at compile time. In fact, C++26\u0026rsquo;s static reflection follows this approach, with the compiler generating metadata and exposing some interfaces for users to query. For related content, see C++26 Static Reflection Proposal Analysis. The timing of the query is what distinguishes dynamic reflection from static reflection.\nOf course, what can be done at compile time is certainly less than what can be done at runtime. For example, creating a class instance based on a runtime type name is something that can\u0026rsquo;t be done at compile time. But you can build dynamic reflection based on these static metadata. For related content, see Implementing Object in C++.\nOperate Metadata # Then, based on the metadata, further operations can be performed, such as code generation. In C++, this can be understood as compile-time code generation, while in Java and C#, it can be considered runtime code generation. For details, see Various Ways to Generate Code.\nConclusion # Finally, let\u0026rsquo;s break down reflection in different languages using the above three steps:\nPython, JavaScript, Java, C#: Metadata is generated by the compiler/interpreter, standard libraries provide interfaces, users can query metadata at runtime, and with the presence of a virtual machine (VM), code generation is convenient. Go: Metadata is generated by the compiler, standard libraries provide interfaces, users can query metadata at runtime. However, since Go is mainly AOT (Ahead-of-Time) compiled, runtime code generation is not convenient. Zig, C++26 static reflection: Metadata is generated by the compiler, standard libraries provide interfaces, users can query metadata at compile time. Similarly, since it\u0026rsquo;s AOT compiled, runtime code generation is not convenient, but compile-time code generation is possible. As for QT and UE, they generate metadata through code generation, encapsulate interfaces, and users can query metadata at runtime. The implementation principle is similar to Go\u0026rsquo;s reflection.\nI hope this tutorial series is helpful to you! If there are any errors, feel free to discuss them in the comments. Thank you for reading.\n","date":"29 November 2023","externalUrl":null,"permalink":"/en/articles/669358870/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003eWhat is Reflection? \n    \u003cdiv id=\"what-is-reflection\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#what-is-reflection\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eThe term \u0026ldquo;Reflection\u0026rdquo; is likely familiar to many, even if you haven\u0026rsquo;t used it, you\u0026rsquo;ve probably heard of it. However, like many other \u003cstrong\u003ejargon\u003c/strong\u003e in the field of computer science, there isn\u0026rsquo;t a clear and precise definition for reflection. This leads to situations where, for languages like C#, Java, and Python that have reflection, discussing reflection naturally brings to mind the corresponding facilities, APIs, and code examples in those languages, making it very concrete. However, for languages like C, C++, and Rust that lack reflection, when people talk about reflection, there\u0026rsquo;s often uncertainty about what exactly is being referred to, making it very abstract. For example, someone once told me that Rust has reflection, citing the official Rust documentation\u0026rsquo;s introduction to the \u003ca href=\"https://doc.rust-lang.org/stable/std/any/index.html\" target=\"_blank\"\u003estd::Any module\u003c/a\u003e, which mentions:\u003c/p\u003e","title":"A Reflection Tutorial for C++ Programmers","type":"articles"},{"content":"I recently planned to write a series of articles discussing the concept of reflection in detail. Coincidentally, C++26 has introduced a new reflection proposal, and I noticed that there are no related articles on Zhihu, even though this topic is frequently discussed. Therefore, I decided to take this opportunity to talk about static reflection in C++, serving as a warm-up for the series.\nWhat is Static Reflection? # First, what is reflection? Like many other terms in computer science, it doesn\u0026rsquo;t have a detailed and precise definition. I won\u0026rsquo;t delve into this question in this article, as I will explain it in detail in subsequent articles. The focus of this article is on C++\u0026rsquo;s static reflection. Why emphasize \u0026ldquo;static\u0026rdquo;? Mainly because when we talk about reflection, we almost always refer to reflection in languages like Java, C#, and Python, where the implementation involves type erasure and runtime information querying. This approach inevitably incurs runtime overhead, which clearly violates C++\u0026rsquo;s principle of zero-cost abstraction. To distinguish it from their reflection, we add \u0026ldquo;static\u0026rdquo; as a qualifier, indicating that C++\u0026rsquo;s reflection is done at compile time. Of course, this statement still lacks some rigor. A detailed discussion will be provided in subsequent articles. For now, you just need to know that C++\u0026rsquo;s static reflection is different from Java, C#, and Python\u0026rsquo;s reflection and is primarily done at compile time.\nWhat Can Static Reflection Do? # Type as Value # We all know that as C++ versions continue to update, the capabilities of compile-time computation are constantly improving. Through constexpr/consteval functions, we can largely reuse runtime code directly, making compile-time computation more convenient. This completely replaces the old method of using template metaprogramming for compile-time computation. Not only is it easier to write, but it also compiles faster.\nObserve the following code snippets for computing factorials at compile time:\nIn C++03/98, we could only achieve this through template recursive instantiation, and we couldn\u0026rsquo;t reuse the code at runtime.\ntemplate\u0026lt;int N\u0026gt; struct factorial { enum { value = N * factorial\u0026lt;N - 1\u0026gt;::value }; }; template\u0026lt;\u0026gt; struct factorial\u0026lt;0\u0026gt; { enum { value = 1 }; }; C++11 introduced the concept of constexpr functions for the first time, allowing us to write code that can be reused at both compile time and runtime. However, there were many restrictions, such as no variables or loops, so we had to write code in a purely functional style.\nconstexpr int factorial(int n) { return n == 0 ? 1 : n * factorial(n - 1); } int main() { constexpr std::size_t a = factorial(5); // Compile-time computation std::size_t\u0026amp; n = *new std::size_t(6); std::size_t b = factorial(n); // Runtime computation std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; } With the advent of C++14/17, the restrictions in constexpr functions were further relaxed. Now, we can use local variables and loops in constexpr functions, as shown below.\nconstexpr std::size_t factorial(std::size_t N) { std::size_t result = 1; for (std::size_t i = 1; i \u0026lt;= N; ++i) { result *= i; } return result; } After C++20, we can even use new/delete at compile time, and we can use vector in compile-time code. Much of the runtime code can be directly reused at compile time without any changes, just by adding a constexpr marker to the function. We no longer need to use obscure template metaprogramming for compile-time computation. However, the above examples only apply to values. In C++, besides values, there are types and higher-kinded types.\ntemplate\u0026lt;typename ...Ts\u0026gt; struct type_list; template\u0026lt;typename T, typename U, typename ...Ts\u0026gt; struct find_first_of { constexpr static auto value = find_first_of\u0026lt;T, Ts...\u0026gt;::value + 1; }; template\u0026lt;typename T, typename ...Ts\u0026gt; struct find_first_of\u0026lt;T, T, Ts...\u0026gt; { constexpr static std::size_t value = 0; }; static_assert(find_first_of\u0026lt;int, double, char, int, char\u0026gt;::value == 2); Since types and higher-kinded types can only be template arguments, we still have to process them through template recursive matching. It would be great if we could manipulate them like values, so that constexpr functions could handle them too. But C++ is not a language like Zig, where \u0026ldquo;type is value.\u0026rdquo; What can we do? No problem, we can map types to values to achieve the effect of \u0026ldquo;type as value.\u0026rdquo; Before static reflection was introduced, we could achieve this effect through some tricks. We could map types to type names at compile time, and then perform computations on the type names. For how to perform such mapping, refer to How to Elegantly Convert enum to string in C++.\ntemplate\u0026lt;typename ...Ts\u0026gt; struct type_list{}; template\u0026lt;typename T, typename ...Ts\u0026gt; constexpr std::size_t find(type_list\u0026lt;Ts...\u0026gt;) { // type_name is used to get compile-time type names std::array arr{ type_name\u0026lt;Ts\u0026gt;()... }; for(auto i = 0; i \u0026lt; arr.size(); i++) { if(arr[i] == type_name\u0026lt;T\u0026gt;()) { return i; } } } The code is very intuitive, but if we want to map the value back to the type, it becomes more difficult. However, in the upcoming static reflection, this bidirectional mapping between types and values has become a language feature, and we no longer need to handle it manually.\nUse the ^ operator to map types to values.\nconstexpr std::meta::info value = ^int; Use [: ... :] to map it back. Note that this is a symbol-level mapping.\nusing Int = typename[:value:]; // In this context, typename can be omitted typename[:value:] a = 3; // Equivalent to int a = 3; Now we can write code like this.\ntemplate\u0026lt;typename ...Ts\u0026gt; struct type_list { constexpr static std::array types = {^Ts...}; template\u0026lt;std::size_t N\u0026gt; using at = typename[:types[N]:]; }; using Second = typename type_list\u0026lt;int, double, char\u0026gt;::at\u0026lt;1\u0026gt;; static_assert(std::is_same_v\u0026lt;Second, double\u0026gt;); No more recursive matching! We can compute types like values. As long as you understand this mapping relationship, writing code becomes very simple. Template metaprogramming for type computation can now retire!\nIn fact, the ^ operator can map more than just types. It has the following functionalities:\n^:: —— Represents the global namespace ^namespace-name —— Namespace name ^type-id —— Type ^cast-expression —— Special expressions, currently including: Primary expressions representing functions or member functions Primary expressions representing variables, static member variables, and structured bindings Primary expressions representing non-static members Primary expressions representing templates Constant expressions Similarly, [: ... :] can also restore the corresponding entities. Note that it restores to the corresponding symbol, so this operator is called the \u0026ldquo;splicer.\u0026rdquo;\n[: r :] —— Restores to the corresponding entity or expression typename[: r :] —— Restores to the corresponding type template[: r :] —— Restores to template parameters namespace[: r :] —— Restores to the namespace [:r:]:: —— Restores to the corresponding namespace, class, or enum nested specifier See the usage example below.\nint x = 0; void g() { [:^x:] = 42; // Okay. Same as: x = 42; } If the restored entity does not match the originally stored one, a compilation error will occur.\ntypename[: ^:: :] x = 0; // Error Meta Info # The above feature alone is enough to be exciting. However, there\u0026rsquo;s much more. The ability to obtain meta-information about entities like class has also been introduced.\nThe most basic is obtaining type names (variable names, field names can also use this function).\nnamespace std::meta { consteval auto name_of(info r) -\u0026gt; string_view; consteval auto display_name_of(info r) -\u0026gt; string_view; } For example:\ndisplay_name_of(^std::vector\u0026lt;int\u0026gt;) // =\u0026gt; std::vector\u0026lt;int\u0026gt; name_of(^std::vector\u0026lt;int\u0026gt;) // =\u0026gt; std::vector\u0026lt;int, std::allocator\u0026lt;int\u0026gt;\u0026gt; Determine if a template is a specialization of another higher-order template and extract parameters from the higher-order template.\nnamespace std::meta { consteval auto template_of(info r) -\u0026gt; info; consteval auto template_arguments_of(info r) -\u0026gt; vector\u0026lt;info\u0026gt;; } std::vector\u0026lt;int\u0026gt; v = {1, 2, 3}; static_assert(template_of(type_of(^v)) == ^std::vector); static_assert(template_arguments_of(type_of(^v))[0] == ^int); Fill template parameters into higher-order templates.\nnamespace std::meta { consteval auto substitute(info templ, span\u0026lt;info const\u0026gt; args) -\u0026gt; info; } constexpr auto r = substitute(^std::vector, std::vector{^int}); using T = [:r:]; // Ok, T is std::vector\u0026lt;int\u0026gt; Obtain member information of struct, class, union, and enum.\nnamespace std::meta { template\u0026lt;typename ...Fs\u0026gt; consteval auto members_of(info class_type, Fs ...filters) -\u0026gt; vector\u0026lt;info\u0026gt;; template\u0026lt;typename ...Fs\u0026gt; consteval auto nonstatic_data_members_of(info class_type, Fs ...filters) -\u0026gt; vector\u0026lt;info\u0026gt; { return members_of(class_type, is_nonstatic_data_member, filters...); } template\u0026lt;typename ...Fs\u0026gt; consteval auto bases_of(info class_type, Fs ...filters) -\u0026gt; vector\u0026lt;info\u0026gt; { return members_of(class_type, is_base, filters...); } template\u0026lt;typename ...Fs\u0026gt; consteval auto enumerators_of(info class_type, Fs ...filters) -\u0026gt; vector\u0026lt;info\u0026gt;; template\u0026lt;typename ...Fs\u0026gt; consteval auto subobjects_of(info class_type, Fs ...filters) -\u0026gt; vector\u0026lt;info\u0026gt;; } Later, we can use this to implement features like traversing structures and enums. Further, we can implement advanced features like serialization and deserialization. Some examples will be provided later. In addition, there are other compile-time functions, and only a part of the content is shown above. For more APIs, refer to the proposal. Since functions for directly obtaining parameters from higher-order templates are provided, we no longer need to use templates for type extraction! Template metaprogramming for type extraction can also retire.\nBetter Compile Facilities # The main part of reflection has been introduced. Now let\u0026rsquo;s talk about other things. Although this part is from other proposals, they can make writing code easier and give code stronger expressiveness.\nTemplate For # In C++, generating a large number of code segments is a very difficult problem to solve. Thanks to C++\u0026rsquo;s unique (or rather, bizarre) mechanisms, current code segment generation is almost entirely based on lambda expressions + variadic parameter pack expansion. See the example below.\nconstexpr auto dynamic_tuple_get(std::size_t N, auto\u0026amp; tuple) { constexpr auto size = std::tuple_size_v\u0026lt;std::decay_t\u0026lt;decltype(tuple)\u0026gt;\u0026gt;; [\u0026amp;]\u0026lt;std::size_t ...Is\u0026gt;(std::index_sequence\u0026lt;Is...\u0026gt;) { auto f = [\u0026amp;]\u0026lt;std::size_t Index\u0026gt; { if(Index == N) { std::cout \u0026lt;\u0026lt; std::get\u0026lt;Index\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } }; (f.template operator()\u0026lt;Is\u0026gt;(), ...); }(std::make_index_sequence\u0026lt;size\u0026gt;{}); } int main() { std::tuple tuple = {1, \u0026#34;Hello\u0026#34;, 3.14, 42}; auto n1 = 0; dynamic_tuple_get(n1, tuple); // 1 auto n2 = 3; dynamic_tuple_get(n2, tuple); // 42 } A classic example, the principle is to distribute runtime variables to compile-time constants through multiple branch judgments. Implement accessing elements in tuple based on runtime index. Note: A more efficient method here is to generate a function pointer array at compile time and then jump directly based on the index, but this is just for demonstration, so don\u0026rsquo;t worry too much.\nThe above code expands to the equivalent of:\nconstexpr auto dynamic_tuple_get(std::size_t N, auto\u0026amp; tuple) { if(N == 0) { std::cout \u0026lt;\u0026lt; std::get\u0026lt;0\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } // ... if(N == 3) { std::cout \u0026lt;\u0026lt; std::get\u0026lt;3\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; } } As you can see, we used extremely awkward syntax just to achieve a very simple effect. Moreover, since lambda is actually a function, it cannot directly return to the upper-level function, causing us to do many redundant if judgments.\nUsing template for makes the code much cleaner.\nconstexpr void dynamic_tuple_get(std::size_t N, auto\u0026amp; tuple) { constexpr auto size = std::tuple_size_v\u0026lt;std::decay_t\u0026lt;decltype(tuple)\u0026gt;\u0026gt;; template for(constexpr auto num : std::views::iota(0, size)) { if(num == N) { std::cout \u0026lt;\u0026lt; std::get\u0026lt;num\u0026gt;(tuple) \u0026lt;\u0026lt; std::endl; return; } } } You can think of template for as a syntax sugar-enhanced version of lambda expansion. It\u0026rsquo;s very useful. If this is added, using template metaprogramming to generate functions (code) can retire.\nNon-Transient Constexpr Allocation # This proposal mainly discusses two issues together.\nC++ can reserve space in the data segment by controlling template instantiation of static members, which can be seen as compile-time memory allocation. template\u0026lt;auto... items\u0026gt; struct make_array { using type = std::common_type_t\u0026lt;decltype(items)...\u0026gt;; static inline type value[sizeof ...(items)] = {items...}; }; template\u0026lt;auto... items\u0026gt; constexpr auto make_array_v = make_array\u0026lt;items...\u0026gt;::value; int main() { constexpr auto arr = make_array_v\u0026lt;1, 2, 3, 4, 5\u0026gt;; std::cout \u0026lt;\u0026lt; arr[0] \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; arr[1] \u0026lt;\u0026lt; std::endl; // Successfully reserves space in the data segment, storing 1 2 3 4 5 } C++20 allows new in constexpr, but memory allocated at compile time must be deleted at compile time. constexpr auto size(auto... Is) { std::vector\u0026lt;int\u0026gt; v = {Is...}; return v.size(); } So, can\u0026rsquo;t we new at compile time and not delete, with the actual data placed in the data segment? This is the problem this proposal aims to solve. It hopes we can use:\nconstexpr std::vector\u0026lt;int\u0026gt; v = {1, 2, 3, 4, 5}; // Global The main difficulty is that memory allocated in the data segment, unlike memory on the heap, has no ownership and doesn\u0026rsquo;t need to be deleted. Once this problem is solved, we can use compile-time std::map, std::vector and retain them until runtime. The author\u0026rsquo;s approach is to mark them. The specific details won\u0026rsquo;t be discussed here. If this is added, using template metaprogramming to create constant tables can also retire.\nSome Examples # Alright, after all that, let\u0026rsquo;s see what we can do with reflection.\nPrint Any Type # template\u0026lt;typename T\u0026gt; constexpr auto print(const T\u0026amp; t) { template for(constexpr auto member : nonstatic_data_members_of(type_of(^t))) { if constexpr (is_class(type_of(member))) { // If it\u0026#39;s a class, recursively traverse its members println(\u0026#34;{}= \u0026#34;, name_of(member)); print(t.[:member:]); } else { // Non-class types can be printed directly std::println(\u0026#34;{}= {}\u0026#34;, name_of(member), t.[:member:]); } } } Enum to String # template \u0026lt;typename E\u0026gt; requires std::is_enum_v\u0026lt;E\u0026gt; constexpr std::string enum_to_string(E value) { template for (constexpr auto e : std::meta::members_of(^E)) { if (value == [:e:]) { return std::string(std::meta::name_of(e)); } } return \u0026#34;\u0026lt;unnamed\u0026gt;\u0026#34;; } Conclusion # I spent a long time introducing C++\u0026rsquo;s static reflection. Actually, I really like C++\u0026rsquo;s compile-time computation and am very interested in its development history. C++\u0026rsquo;s compile-time computation has been developed step by step, with many wise masters proposing their unique ideas, turning the impossible into reality. From the perverse template metaprogramming of C++03, to constexpr variables in C++11, to the gradual relaxation of restrictions in constexpr functions from C++14 to C++23, moving more and more operations to compile time. To today\u0026rsquo;s static reflection, C++ is gradually breaking free from the clutches of template metaprogramming. All those old template metaprogramming techniques can now be retired!!! If you haven\u0026rsquo;t written old-style template metaprogramming code, you probably can\u0026rsquo;t appreciate how terrifying it is.\nTo get static reflection into the standard sooner, the author team specifically selected a core subset of the original proposal. Hopefully, as the author wishes, static reflection will enter the standard in C++26! Of course, the core part enters first, and more useful features will be added later, so this is by no means the entirety of reflection\n","date":"17 October 2023","externalUrl":null,"permalink":"/en/articles/661692275/","section":"Articles","summary":"\u003cp\u003eI recently planned to write a series of articles discussing the concept of reflection in detail. Coincidentally, C++26 has introduced a new reflection proposal, and I noticed that there are no related articles on Zhihu, even though this topic is frequently discussed. Therefore, I decided to take this opportunity to talk about static reflection in C++, serving as a warm-up for the series.\u003c/p\u003e","title":"Analysis of the C++26 Static Reflection Proposal","type":"articles"},{"content":" 引言 # 在 C++ 中，形如\u0026amp;T::name的表达式返回的结果就是成员指针。写代码的时候偶尔会用到，但是这个概念可能很多人都并不熟悉。考虑如下代码\nstruct Point { int x; int y; }; int main() { Point point; *(int*)((char*)\u0026amp;point + offsetof(Point, x)) = 20; *(int*)((char*)\u0026amp;point + offsetof(Point, y)) = 20; } 在 C 语言中，我们经常通过这样计算 offset 的方式来访问结构体成员。如果把它封装成函数，还能用来根据传入的参数动态访问结构体的成员变量。然而上面的代码在 C++ 中是 undefined behavior，具体的原因可以参考 Stack Overflow 上的这个讨论。但是如果我们确实有这样需求，那该怎么合法的实现需求呢？C++ 为我们提供了一层抽象：pointers to members，用来合法进行这样的操作。\n使用 # 指向数据成员的指针 # 一个指向类C非静态成员m的成员指针可以用\u0026amp;C::m进行初始化。当在C的成员函数里面使用\u0026amp;C::m会出现二义性。即既可以指代对m成员取地址\u0026amp;this-\u0026gt;m，也可以指代成员指针。为此标准规定，\u0026amp;C::m表示成员指针，\u0026amp;(C::m)或者\u0026amp;m表示对m成员取地址。可以通过运算符.*和-\u0026gt;*来访问对应的成员。示例代码如下\nstruct C { int m; void foo() { int C::*x1 = \u0026amp;C::m; // pointer to member m of C int* x2 = \u0026amp;(C::m); // pointer to member this-\u0026gt;m } }; int main() { int C::*p = \u0026amp;C::m; // type of a member pointer is: T U::* // T is the type of the member, U is the class type // here, T is int, U is C C c = {7}; std::cout \u0026lt;\u0026lt; c.*p \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // same as c.m, print 7 C* cp = \u0026amp;c; cp-\u0026gt;m = 10; std::cout \u0026lt;\u0026lt; cp-\u0026gt;*p \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // same as cp-\u0026gt;m, print 10 } 指向基类的数据成员指针 可以隐式转换成 **非虚继承 **的派生类数据成员指针 struct Base { int m; }; struct Derived1 : Base {}; // non-virtual inheritance struct Derived2 : virtual Base {}; // virtual inheritance int main() { int Base::*bp = \u0026amp;Base::m; int Derived1::*dp = bp; // ok, implicit cast int Derived2::*dp2 = bp; // error Derived1 d; d.m = 1; std::cout \u0026lt;\u0026lt; d.*dp \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; d.*bp \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // ok, prints 1 1 } 根据传入的指针，动态访问结构体字段 struct Point { int x; int y; }; auto\u0026amp; access(Point\u0026amp; point, auto pm) { return point.*pm; } int main() { Point point; access(point, \u0026amp;Point::x) = 10; access(point, \u0026amp;Point::y) = 20; std::cout \u0026lt;\u0026lt; point.x \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; point.y \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // 10 20 }} 指向成员函数的指针 # 一个指向非静态成员函数f的成员指针可以用\u0026amp;C::f进行初始化。由于不能对非静态成员函数取地址，\u0026amp;(C::f)和\u0026amp;f什么都不表示。类似的可以通过运算符.*和-\u0026gt;*来访问对应的成员函数。如果成员函数是重载函数，想要获取对应的成员函数指针，请参考 如何获取重载函数的地址。示例代码如下\nstruct C { void foo(int x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; } }; int main() { using F = void(int); // function type using MP = F C::*; // pointer to member function using T = void (C::*)(int); // pointer to member function static_assert(std::is_same_v\u0026lt;MP, T\u0026gt;); auto mp = \u0026amp;C::foo; T mp2 = \u0026amp;C::foo; static_assert(std::is_same_v\u0026lt;decltype(mp), T\u0026gt;); C c; (c.*mp)(1); // call foo, print 1 C* cp = \u0026amp;c; (cp-\u0026gt;*mp)(2); // call foo, print 2 } 指向基类的成员函数指针 可以隐式转换成 **非虚继承 **的派生类成员函数指针 struct Base { void f(int) {} }; struct Derived1 : Base {}; // non-virtual inheritance struct Derived2 : virtual Base {}; // virtual inheritance int main() { void (Base::*bp)(int) = \u0026amp;Base::f; void (Derived1::*dp)(int) = bp; // ok, implicit cast void (Derived2::*dp2)(int) = bp; // error Derived1 d; (d.*dp)(1); // ok } 根据传入参数动态调用成员函数 struct C { void f(int x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl;} void g(int x) { std::cout \u0026lt;\u0026lt; x + 1 \u0026lt;\u0026lt; std::endl;} }; auto access(C\u0026amp; c, auto pm, auto... args){ return (c.*pm)(args...); } int main(){ C c; access(c, \u0026amp;C::f, 1); // 1 access(c, \u0026amp;C::g, 1); // 2 } 实现 # 首先要明确的是，C++ 标准并没有规定成员指针是什么实现的。在这一点上和虚函数一样，即标准没有规定虚函数是怎么实现的，只规定了虚函数的行为。所以成员指针相关的实现完全是 implementation defined。本来只需要了解怎么使用就足够了，不要关心底层实现。但是奈何网络上相关话题的错误文章太多了，已经严重的产生了误导，所以有必要进行澄清。\n对于三大主流编译器，GCC 遵循 Itanium C++ ABI ，MSVC 则遵守 MSVC C++ ABI，Clang 通过不同的编译选项可以分别设置为这两种 ABI。关于 ABI 的详细讨论请移步 彻底理解 C++ ABI 和 MSVC 与 GCC 产生的动态库如何才能相互替换，这里不过多介绍。\nItanium ABI 具有公开的文档，之后的相关描述主要参考这个文档 MSVC ABI 没有公开的文档，之后的相关描述主要参考 MSVC C++ ABI Member Function Pointers 这篇博客 请注意：文章具有时效性，未来的实现可能会改变，仅作参考，以官方文档为准。\n首先尝试打印一个成员指针的值\nstruct C { int m; void foo(int x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl;} }; int main(){ int C::* p = \u0026amp;C::m; void (C::* p2)(int) = \u0026amp;C::foo; std::cout \u0026lt;\u0026lt; p \u0026lt;\u0026lt; std::endl; // 1 std::cout \u0026lt;\u0026lt; p2 \u0026lt;\u0026lt; std::endl; // 1 } 输出的结果都是1。鼠标移到\u0026lt;\u0026lt;就会发现，这是发生了到bool的隐式类型转换。\u0026lt;\u0026lt;并没有重载成员指针类型。我们只能通过一些手段查看它的二进制值表示。\nItanium C++ ABI # 指向数据成员的指针 # 一般来说可以用下述结构体表示，数据成员指针。表示相对于对象首地址的偏移量。如果是nullptr则里面存的是-1。此时成员指针大小就是sizeof(ptrdiff_t)。\nstruct data_member_pointer{ ptrdiff_t offset; }; 如前文所述，C++ 标准不允许沿着虚继承链进行成员指针转换。所以在编译期根据继承关系就可以算出转换需要的 offset，而不需要在运行期去查虚表。\nstruct A { int a; }; struct B { int b; }; struct C : A, B {}; void log(auto mp) { std::cout \u0026lt;\u0026lt; \u0026#34;offset is \u0026#34; \u0026lt;\u0026lt; *reinterpret_cast\u0026lt;ptrdiff_t*\u0026gt;(\u0026amp;mp) // or use std::bit_cast after C++20 // std::bit_cast\u0026lt;std::ptrdiff_t\u0026gt;(mp) \u0026lt;\u0026lt; std::endl; } int main() { auto a = \u0026amp;A::a; log(a); // offset is 0 auto b = \u0026amp;B::b; log(b); // offset is 0 int C::*c = a; log(c); // offset is 0 // implicit cast int C::*c2 = b; log(c2); // offset is 4 } 指向成员函数的指针 # 在主流的平台上，一般来说可以用下述结构体表示，成员函数指针:\nstruct member_function_pointer { std::ptrdiff_t ptr; // function address or vtable offset // if low bit is 0, it\u0026#39;s a function address, otherwise it\u0026#39;s a vtable offset ptrdiff_t offset; // offset to the base(unless multiple inheritance, it\u0026#39;s always 0) }; 这个实现依赖于一些大多数平台的假定：\n考虑到地址对齐，非静态成员函数的地址最低位几乎总是 0 空的函数指针是 0，所以空函数指针可以和虚表偏移量区分开来 体系结构是字节寻址，并且指针大小是偶数，所以虚表偏移量是偶数 只要知道虚表的地址，虚表偏移量和函数类型就可以进行函数调用，具体的实现细节由编译器根据 ABI 来决定 当然也有一些平台不满足上述假设，例如 ARM32 平台的某些情况，这时候它的实现方式就和我们刚才说的不同了。所以你现在应该能更加理解什么叫实现定义的行为了，即使编译器相同，但是目标平台不同，实现都有可能不同。\n在我的环境 x64 windows 上，符合主流实现的要求。于是对着这个 ABI，进行了\u0026quot;解糖\u0026quot;。\nstruct member_func_pointer { std::size_t ptr; ptrdiff_t offset; }; template \u0026lt;typename Derived, typename Ret, typename Base, typename... Args\u0026gt; Ret invoke(Derived\u0026amp; object, Ret (Base::*ptr)(Args...), Args... args) { Ret (Derived::*dptr)(Args...) = ptr; member_func_pointer mfp = *(member_func_pointer*)(\u0026amp;dptr); using func = Ret (*)(void*, Args...); void* self = (char*)\u0026amp;object + mfp.offset; func fp = nullptr; bool is_virtual = mfp.ptr \u0026amp; 1; if(is_virtual) { auto vptr = (char*)(*(void***)self); auto voffset = mfp.ptr - 1; auto address = *(void**)(vptr + voffset); fp = (func)address; } else { fp = (func)mfp.ptr; } return fp(self, args...); } struct A { int a; A(int a) : a(a) {} virtual void foo(int b) { std::cout \u0026lt;\u0026lt; \u0026#34;A::foo \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; } void bar(int b) { std::cout \u0026lt;\u0026lt; \u0026#34;A::bar \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; } }; int main() { A a = {4}; invoke(a, \u0026amp;A::foo, 3); // A::foo 43 invoke(a, \u0026amp;A::bar, 3); // A::bar 43 } MSVC C++ ABI # MSVC 对于此的实现非常复杂，还对 C++ 标准进行了扩展。如果想要细致全面的了解，还是建议阅读上面那篇博客。\nC++ 标准不允许虚基类成员指针向子类成员指针转换，但是 MSVC 允许。\nstruct Base { int m; }; struct Derived1 : Base {}; // non-virtual inheritance struct Derived2 : virtual Base {}; // virtual inheritance int main() { int Base::*bp = \u0026amp;Base::m; int Derived1::*dp = bp; // ok, implicit cast int Derived2::*dp2 = bp; // ok in MSVC， error in GCC } 为了不浪费空间，即使在同一程序中 MSVC 的成员指针大小也可能是不同的大小（Itanium 中由于统一实现，所以都是一样大的）。MSVC 对不同情况做了不同处理。\n另外请注意 MSVC 对于虚继承的是实现和 Itanium 也是不一样的。可以参考 C++中虚函数、虚继承内存模型 这篇文章中的相关介绍。\n指向数据成员的指针 # 对于非虚继承的情况下，实现的和 GCC 类似。除了大小有点区别。64位程序中 GCC 是8字节，MSVC 是4字节。都是用-1表示nullptr。\nstruct data_member_pointer { int offset; }; 对于虚继承的情况下（标准扩展），需要额外存储一个 voffset。用于运行期从虚表里面找到对应虚基类成员的 offset。\nstruct Base { int m; }; struct Base2 { int n; }; struct Base3 { int n; }; struct Derived : virtual Base, Base2, Base3 {}; struct dmp { int offset; int voffset; }; template \u0026lt;typename T\u0026gt; void log(T mp) { dmp d = *reinterpret_cast\u0026lt;dmp*\u0026gt;(\u0026amp;mp); std::cout \u0026lt;\u0026lt; \u0026#34;offset is \u0026#34; \u0026lt;\u0026lt; d.offset \u0026lt;\u0026lt; \u0026#34;, voffset is \u0026#34; \u0026lt;\u0026lt; d.voffset \u0026lt;\u0026lt; std::endl; } int main() { int Derived::*dp = \u0026amp;Base::m; log(dp); // offset is 0, voffset is 4 dp = \u0026amp;Base3::n; log(dp); // offset is 4, voffset is 0 } 指向成员函数的指针 # 对于成员函数指针就更复杂了，有四种情况：\n非虚继承，非多继承 struct member_function_ptr{ void* address; }; 非虚继承，多继承 struct member_function_ptr{ void* address; int offset; }; 虚继承，多继承 struct member_function_ptr{ void* address; int offset; int vindex; }; 未知继承 struct member_function_ptr{ void* address; int offset; int vadjust; // use to find vptr int vindex; }; 还要注意：32程序中成员函数的调用约定和普通函数不一样。所以如果希望转换成函数指针并调用，需要在函数指针里面把函数调用约定写上才行，不然会导致调用失败。\n结论 # 讨论 C++ 问题千万不要想当然，你在特定平台上的测试结果，不代表所有可能的实现。而且 MSVC 已经告诉你了，即使是同一个程序内，你的测试也可能没有覆盖到所有的 case。之前发现 MSVC 的成员函数指针大小变来变去的时候给我吓了一跳，以为是我的代码出了问题。如果希望自己写一个类似std::function的容器，并希望执行 SBO 优化，最好把 SBO 大小设置在16字节以上，这样能覆盖掉绝大部分的成员函数指针。\n如果需要成员函数作为回调函数的，推荐使用 lambda 表达式包裹一层。 像下面这样\nstruct A { int a; void bar(int b) { std::cout \u0026lt;\u0026lt; \u0026#34;A::bar \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; } }; int main() { auto f = +[](A\u0026amp; a, int b) { a.bar(b); }; // + is unary plus operator, use to cast a non-capturing lambda to a function pointer // f is function pointer } 在 C++23 之后，如果使用 explicit this 定义成员函数，则\u0026amp;C::f可以直接获取对应成员函数的函数指针，不需要像上面那样多一层包裹了\nstruct A { void bar(this A\u0026amp; self, int b); }; auto p = \u0026amp;A::bar; // p is function pointer, rather than member function pointer ","date":"4 October 2023","externalUrl":null,"permalink":"/en/articles/659510753/","section":"Articles","summary":"\u003ch2 class=\"relative group\"\u003e引言 \n    \u003cdiv id=\"%E5%BC%95%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BC%95%E8%A8%80\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在 C++ 中，形如\u003ccode\u003e\u0026amp;T::name\u003c/code\u003e的表达式返回的结果就是成员指针。写代码的时候偶尔会用到，但是这个概念可能很多人都并不熟悉。考虑如下代码\u003c/p\u003e","title":"Comprehensive Analysis of C++ Member Pointers","type":"articles"},{"content":"In C++, the concept of templates has existed for over two decades. As one of the most important language constructs in C++, discussions about templates are countless. Unfortunately, deep and valuable discussions are rare, especially those that view this feature from multiple perspectives. Many articles often intertwine templates with various syntactic details, making it easy to leave readers feeling lost in a fog. Similar examples occur in other topics, such as introducing coroutines while mixing them with various I/O discussions, or discussing reflection as if it were limited to Java or C#. While this approach is not without reason, it often makes it difficult to grasp the essence. After reading a lot of content, one may still fail to grasp the key points and instead end up confusing different concepts.\nPersonally, I prefer to discuss a problem from multiple levels and angles, rather than limiting myself to a specific aspect. This way, one can better understand the problem itself and avoid having too narrow a perspective. Therefore, this article will attempt to observe templates from four angles, starting from their inception, to clarify the development trajectory of this feature in C++. Note that this article is not a tutorial and will not delve into syntactic details. Instead, it will focus more on design philosophy and trade-offs. A basic understanding of templates is sufficient to follow along, so feel free to read on. Of course, this approach may lack some rigor, and any errors are welcome to be discussed in the comments.\nWe will mainly discuss four themes:\nCode Generation Type Constraints Compile-time Computing Type Manipulation The first theme is generally considered to be the standard use of templates. The latter three are usually categorized under TMP, or Template Meta Programming. The original intent of templates was not to achieve these three functions, but they were eventually realized through some clever tricks, making the code more obscure and difficult to understand, hence the term \u0026ldquo;meta programming.\u0026rdquo;\nCode Generation # Generic # Generic programming involves writing the same code for different types to achieve code reuse. Before templates were introduced, we could only simulate generics using macros. Consider the following simple example:\n#define add(T) _ADD_IMPL_##T #define ADD_IMPL(T) \\ T add(T)(T a, T b) { \\ return a + b; \\ } ADD_IMPL(int); ADD_IMPL(float); int main() { add(int)(1, 2); add(float)(1.0f, 2.0f); } The principle is simple: replace the type in a regular function with a macro parameter, and generate different names for different type parameters through macro concatenation. The IMPL macro is then used to generate definitions for specific functions, a process known as instantiation.\nOf course, this is just a simple example, and it might seem fine. But imagine implementing a vector using macros—it would be quite daunting. Specifically, using macros for generics has several drawbacks:\nPoor code readability, as macro concatenation is coupled with code logic, making error messages hard to read. Difficult to debug, as breakpoints can only be set at the macro expansion point, not inside the macro definition. Requires explicit type parameters, which can become verbose with many parameters. Manual instantiation of function definitions is necessary, which can be cumbersome in larger codebases where a generic might have dozens of instantiations. These issues are all resolved with templates:\ntemplate \u0026lt;typename T\u0026gt; T add(T a, T b) { return a + b; } template int add\u0026lt;\u0026gt;(int, int); // explicit instantiation int main() { add(1, 2); // auto deduce T add(1.0f, 2.0f); // implicit instantiation add\u0026lt;float\u0026gt;(1, 2); // explicitly specify T } Templates act as placeholders, eliminating the need for character concatenation, making the code look just like regular code, with only an additional template parameter declaration. Errors and debugging point accurately to the template definition location, not the instantiation point. Supports automatic template parameter deduction, eliminating the need for explicit type parameters, while also allowing explicit specification. Supports implicit instantiation, where the compiler automatically instantiates used functions, as well as explicit instantiation, where instantiations are done manually. Additionally, features like partial specialization, full specialization, variadic templates, and variable templates are all impossible with macros. It is the advent of templates that made the implementation of generic libraries like STL possible.\nTable Generation # The generics discussed above can be seen as the most direct use of templates. Based on these, we can achieve more advanced code generation, such as generating a fixed table at compile time for runtime queries. The standard library\u0026rsquo;s std::visit implementation uses this technique. Here\u0026rsquo;s a simple simulation:\ntemplate \u0026lt;typename T, typename Variant, typename Callback\u0026gt; void wrapper(Variant\u0026amp; variant, Callback\u0026amp; callback) { callback(std::get\u0026lt;T\u0026gt;(variant)); } template \u0026lt;typename... Ts, typename Callback\u0026gt; void visit(std::variant\u0026lt;Ts...\u0026gt;\u0026amp; variant, Callback\u0026amp;\u0026amp; callback) { using Variant = std::variant\u0026lt;Ts...\u0026gt;; constexpr static std::array table = {\u0026amp;wrapper\u0026lt;Ts, Variant, Callback\u0026gt;...}; table[variant.index()](variant, callback); } int main() { auto callback = [](auto\u0026amp; value) { std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; }; std::variant\u0026lt;int, float, std::string\u0026gt; variant = 42; visit(variant, callback); variant = 3.14f; visit(variant, callback); variant = \u0026#34;Hello, World!\u0026#34;; visit(variant, callback); return 0; } Although the type of elements stored in the variant is determined at runtime, the set of possible types it can hold is known at compile time. Therefore, we instantiate a corresponding wrapper function for each possible type in the set using callback and store them in an array. At runtime, we simply use the variant\u0026rsquo;s index to access the corresponding member in the array to complete the call.\nOf course, with C++17\u0026rsquo;s folding expressions, we can do better:\ntemplate \u0026lt;typename... Ts, typename Callback\u0026gt; void visit(std::variant\u0026lt;Ts...\u0026gt;\u0026amp; variant, Callback\u0026amp;\u0026amp; callback) { auto foreach = []\u0026lt;typename T\u0026gt;(std::variant\u0026lt;Ts...\u0026gt;\u0026amp; variant, Callback\u0026amp; callback) { if(auto value = std::get_if\u0026lt;T\u0026gt;(\u0026amp;variant)) { callback(*value); return true; } return false; }; (foreach.template operator()\u0026lt;Ts\u0026gt;(variant, callback) || ...); } By leveraging the short-circuiting behavior of logical operators, we can exit the evaluation of subsequent folding expressions early, and shorter functions are more conducive to inlining.\nType Constraints # I agree with most points, but template error messages are definitely not easy to read. Compared to macros, isn\u0026rsquo;t it a case of the pot calling the kettle black? Or even worse. Producing hundreds or thousands of lines of error messages is something only C++ templates can do.\nThis leads to the next question: why are C++ compilation error messages so long? And why are they sometimes so difficult to understand?\nFunction Overloading # Consider this simple example with just a few lines:\nstruct A {}; int main() { std::cout \u0026lt;\u0026lt; A{} \u0026lt;\u0026lt; std::endl; return 0; } On my GCC compiler, this produces a whopping 239 lines of error messages. The good news is that GCC highlights the key part, as shown below:\nno match for \u0026#39;operator\u0026lt;\u0026lt;\u0026#39; (operand types are \u0026#39;std::ostream\u0026#39; {aka \u0026#39;std::basic_ostream\u0026lt;char\u0026gt;\u0026#39;} and \u0026#39;A\u0026#39;) 9 | std::cout \u0026lt;\u0026lt; A{} \u0026lt;\u0026lt; std::endl; | ~~~~~~~~~ ^~ ~~~ | | | | | A | std::ostream {aka std::basic_ostream\u0026lt;char\u0026gt;} So it\u0026rsquo;s still somewhat understandable: it means no matching overloaded function was found, indicating that we need to overload operator\u0026lt;\u0026lt; for A. But what are the remaining 200 lines of errors doing? The key lies in overload resolution. Let\u0026rsquo;s look at one of the messages:\nnote: template argument deduction/substitution failed: note: cannot convert \u0026#39;A()\u0026#39; (type \u0026#39;A\u0026#39;) to type \u0026#39;const char*\u0026#39; 9 | std::cout \u0026lt;\u0026lt; A{} \u0026lt;\u0026lt; std::endl; This means the compiler tried to match the A type with the const char* overload (via implicit type conversion) and failed. The standard library has many such functions with numerous overloads. For example, operator\u0026lt;\u0026lt; is overloaded for int, bool, long, double, and many others—nearly dozens of functions. The error messages list all the reasons why each overload attempt failed, easily resulting in hundreds of lines. Combined with the cryptic naming in the standard library, it can look like gibberish.\nInstantiation Stack # Function overloading is part of the reason why error messages are hard to read, but not the whole story. As shown above, merely enumerating all possibilities results in a few hundred lines of errors. But we can produce thousands of lines—an order of magnitude difference that can\u0026rsquo;t be easily explained by quantity alone. Moreover, this section is about type constraints, so what does it have to do with compiler errors? Consider this example:\nstruct A {}; struct B {}; template \u0026lt;typename T\u0026gt; void test(T a, T b) { std::cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; b \u0026lt;\u0026lt; std::endl; } int main() { test(A{}, B{}); // #1: a few lines test(A{}, A{}); // #2: hundred lines } In this example, #1 produces only a few lines of error messages, while #2 produces hundreds. Why such a big difference? Recall the two advantages of templates over macros mentioned in the first part: automatic type deduction and implicit instantiation. Only when template parameter deduction succeeds does template instantiation occur, and only then are errors in the function body checked.\nIn test(A{}, B{}), template parameter deduction fails because the test function implies an important condition: the types of a and b must be the same. Thus, the error is that no matching function is found. In test(A{}, A{}), template parameter deduction succeeds, and instantiation proceeds, but an error occurs during instantiation. That is, T is deduced as A, and when substituting A into the function body, an error occurs. The compiler then lists all the reasons why the substitution failed.\nThis leads to a problem: when there are many layers of template nesting, the error might occur in the innermost template function, forcing the compiler to print the entire template instantiation stack.\nSo what\u0026rsquo;s the use of type constraints? Consider this example:\nstruct A {}; template \u0026lt;typename T\u0026gt; void print1(T x) { std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; } template \u0026lt;typename T\u0026gt; // requires requires (T x) { std::cout \u0026lt;\u0026lt; x; } void print2(T x) { print1(x); std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; } int main() { print2(A{}); return 0; } This short code produces 700 lines of compilation errors on my GCC. Now, uncomment the commented line. In contrast, the error messages are much shorter:\nIn substitution of \u0026#39;template\u0026lt;class T\u0026gt; requires requires(T x) {std::cout \u0026lt;\u0026lt; x;} void print2(T) [with T = A]\u0026#39;: required from here required by the constraints of \u0026#39;template\u0026lt;class T\u0026gt; requires requires(T x) {std::cout \u0026lt;\u0026lt; x;} void print2(T)\u0026#39; in requirements with \u0026#39;T x\u0026#39; [with T = A] note: the required expression \u0026#39;(std::cout \u0026lt;\u0026lt; x)\u0026#39; is invalid 15 | requires requires (T x) { std::cout \u0026lt;\u0026lt; x; } This means that an instance x of type A does not satisfy the requires clause std::cout \u0026lt;\u0026lt; x. In fact, with this syntax, we can restrict errors to the type deduction phase, avoiding instantiation. Thus, the error messages become much more concise.\nIn other words, requires can prevent the propagation of compilation errors. Unfortunately, constraint-related syntax was only added in C++20. What about before that?\nBefore C++20 # Before C++20, we didn\u0026rsquo;t have such convenient methods. We had to use a technique called SFINAE to achieve similar functionality for type constraints. For example, the above functionality could only be written like this before C++20:\ntemplate \u0026lt;typename T, typename = decltype(std::cout \u0026lt;\u0026lt; std::declval\u0026lt;T\u0026gt;())\u0026gt; void print2(T x) { print1(x); std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; } The specific rules won\u0026rsquo;t be discussed here, but interested readers can search for related articles.\nThe result is that the line:\ntypename = decltype(std::cout \u0026lt;\u0026lt; std::declval\u0026lt;T\u0026gt;()) is completely unintuitive and hard to understand. Only by deeply understanding C++ template rules can one grasp what this is doing. For why requires wasn\u0026rsquo;t added until C++20, you can read the autobiography written by the father of C++ himself.\nCompile-time Computing # Meaning # First, it\u0026rsquo;s important to acknowledge that compile-time computing is definitely useful. The extent of its significance in specific scenarios cannot be generalized. Many people panic at the mention of compile-time computing, citing reasons like difficult-to-understand code, niche skills, or lack of value. This can easily mislead beginners. In fact, there is a real demand for such functionality. If a programming language lacks this feature but there is a need, programmers will find other ways to achieve it.\nI will give two examples to illustrate:\nFirst, compiler optimizations for constant expressions are well-known. In extremely simple cases, like the expression 1+1+x, the compiler will optimize it to 2+x. In fact, modern compilers can perform many optimizations for similar cases, as seen in this question. The asker wondered if the C function strlen would optimize the function call directly to a constant when the parameter is a constant string. For example, would strlen(\u0026quot;hello\u0026quot;) be directly optimized to 5? Based on experiments with mainstream compilers, the answer is yes. Similar cases are countless, and you are unknowingly using compile-time computing. It\u0026rsquo;s just that it\u0026rsquo;s categorized under compiler optimizations. However, the compiler\u0026rsquo;s optimization capabilities are ultimately limited, and allowing users to define such optimization rules would be more flexible and free. For example, in C++, strlen is explicitly marked as constexpr, ensuring this optimization. Second, in the early days of programming language development, when compiler optimizations were not as advanced, external scripting languages were widely used to precompute data (or even generate code) to reduce runtime overhead. A typical example is precomputing trigonometric function tables, which are then used directly at runtime. For example, before compiling code, a script is run to generate some necessary code. C++\u0026rsquo;s compile-time computing has clear semantic guarantees and is embedded within the language, allowing for good interaction with other parts. From this perspective, it effectively addresses the two issues mentioned above. Of course, many criticisms of it are not without merit. Compile-time computing via template meta-programming results in ugly and obscure code, involves many syntactic details, and significantly slows down compilation while increasing binary size. Undeniably, these issues exist. However, as C++ versions continue to evolve, compile-time computing has become much easier to understand, no longer requiring complex template meta-code, and even beginners can quickly learn it. This is because it now closely resembles runtime code. Next, we will clarify this through its historical development.\nHistory # Historically, TMP was an accidental discovery. During the standardization of C++, it was found that the template system was Turing complete, meaning it could, in principle, compute anything computable. The first concrete demonstration was a program written by Erwin Unruh that computed prime numbers, although it didn\u0026rsquo;t actually compile: the list of primes was part of the error messages generated by the compiler while trying to compile the code. For a specific example, refer here.\nAs an introductory programming example, here\u0026rsquo;s a method to compute factorials at compile time:\ntemplate \u0026lt;int N\u0026gt; struct factorial { enum { value = N * factorial\u0026lt;N - 1\u0026gt;::value }; }; template \u0026lt;\u0026gt; struct factorial\u0026lt;0\u0026gt; { enum { value = 1 }; }; constexpr auto value = factorial\u0026lt;5\u0026gt;::value; // =\u0026gt; 120 This code can compile even before C++11. After C++11, many new features were introduced to simplify compile-time computing. The most important is the constexpr keyword. Before C++11, there was no suitable way to represent compile-time constants, so enum was used. After C++11, we can write:\ntemplate \u0026lt;int N\u0026gt; struct factorial { constexpr static int value = N * factorial\u0026lt;N - 1\u0026gt;::value; }; template \u0026lt;\u0026gt; struct factorial\u0026lt;0\u0026gt; { constexpr static int value = 1; }; Although this simplifies things, we are still using templates for compile-time computing. This makes the code hard to read, mainly for two reasons:\nTemplate parameters can only be compile-time constants; there is no concept of compile-time variables, whether global or local. Only recursion can be used for programming, not loops. Imagine writing code without variables or loops—it would be quite painful.\nAre there programming languages that satisfy these two characteristics? In fact, programming languages that satisfy these two points are generally called pure functional programming languages. Haskell is a typical example. However, Haskell has powerful pattern matching, and once familiar with Haskell\u0026rsquo;s mindset, one can write concise and elegant code (and Haskell itself can use the do syntax to simulate local variables, as using local variables is equivalent to passing them down as function parameters). C++ lacks these features, inheriting the drawbacks without the benefits. Fortunately, these issues are resolved with constexpr functions.\nconstexpr std::size_t factorial(std::size_t N) { std::size_t result = 1; for(std::size_t i = 1; i \u0026lt;= N; ","date":"12 September 2023","externalUrl":null,"permalink":"/en/articles/655902377/","section":"Articles","summary":"\u003cp\u003eIn C++, the concept of templates has existed for over two decades. As one of the most important language constructs in C++, discussions about templates are countless. Unfortunately, deep and valuable discussions are rare, especially those that view this feature from multiple perspectives. Many articles often intertwine templates with various syntactic details, making it easy to leave readers feeling lost in a fog. Similar examples occur in other topics, such as introducing coroutines while mixing them with various I/O discussions, or discussing reflection as if it were limited to Java or C#. While this approach is not without reason, it often makes it difficult to grasp the essence. After reading a lot of content, one may still fail to grasp the key points and instead end up confusing different concepts.\u003c/p\u003e","title":"Seeing Through the Fog: A True Understanding of C++ Templates","type":"articles"},{"content":"In the previous article, we gained a preliminary understanding of the principles of STMP and used it to implement a simple compile-time counter. However, its power extends far beyond that. This article will discuss some advanced applications based on STMP.\ntype \u0026lt;=\u0026gt; value # In C++, the need to perform calculations on types has always existed, such as:\nstd::variant requires that its template parameters must not be duplicated, so we need to deduplicate the type list. Sorting the type list of variant so that identical types, such as std::variant\u0026lt;int, double\u0026gt; and std::variant\u0026lt;double, int\u0026gt;, can share the same code, reducing binary bloat. Retrieving a type from a type list based on a given index. Mapping function parameters with variable order. And so on, the list goes on. However, in C++, types are not first-class citizens and can only be passed as template parameters. To perform calculations on types, we often have to resort to obscure template metaprogramming. If types could be passed to constexpr functions like values for computation, calculations on types would become much simpler. Directly passing types is impossible, so consider establishing a one-to-one mapping between types and values. Before computation, map types to values, and after computation, map values back to types, thus achieving our goal.\ntype -\u0026gt; value # First, consider mapping types to values.\nstruct identity { int size; }; using meta_value = const identity*; template \u0026lt;typename T\u0026gt; struct storage { constexpr inline static identity value = {sizeof(T)}; }; template \u0026lt;typename T\u0026gt; consteval meta_value value_of() { return \u0026amp;storage\u0026lt;T\u0026gt;::value; } By leveraging the fact that the addresses of static variables in different template instantiations are also different, we can easily map types to unique values (addresses).\nvalue -\u0026gt; type # How do we map values back to types? Consider using straightforward template specialization.\ntemplate \u0026lt;meta_value value\u0026gt; struct type_of; template \u0026lt;\u0026gt; struct type_of\u0026lt;value_of\u0026lt;int\u0026gt;()\u0026gt; { using type = int; }; // ... This works, but it requires us to specialize all the types we want to use in advance, which is impractical for most programs. Is there a way to add this specialization during evaluation? The answer is the friend injection technique we discussed in the previous article.\ntemplate \u0026lt;typename T\u0026gt; struct self { using type = T; }; template \u0026lt;meta_value value\u0026gt; struct reader { friend consteval auto to_type(reader); }; template \u0026lt;meta_value value, typename T\u0026gt; struct setter { friend consteval auto to_type(reader\u0026lt;value\u0026gt;) { return self\u0026lt;T\u0026gt;{}; } }; Then, we just need to instantiate a setter while instantiating value_of to complete the registration.\ntemplate \u0026lt;typename T\u0026gt; consteval meta_value value_of() { constexpr auto value = \u0026amp;storage\u0026lt;T\u0026gt;::value; setter\u0026lt;value, T\u0026gt; setter; return value; } Finally, we can directly read the registration result through reader to implement type_of.\ntemplate \u0026lt;meta_value value\u0026gt; using type_of = typename decltype(to_type(reader\u0026lt;value\u0026gt;{}))::type; sort types! # Without further ado, let\u0026rsquo;s try using std::sort to sort a type_list.\n#include \u0026lt;array\u0026gt; #include \u0026lt;algorithm\u0026gt; template \u0026lt;typename... Ts\u0026gt; struct type_list {}; template \u0026lt;std::array types, typename = std::make_index_sequence\u0026lt;types.size()\u0026gt;\u0026gt; struct array_to_list; template \u0026lt;std::array types, std::size_t... Is\u0026gt; struct array_to_list\u0026lt;types, std::index_sequence\u0026lt;Is...\u0026gt;\u0026gt; { using result = type_list\u0026lt;type_of\u0026lt;types[Is]\u0026gt;...\u0026gt;; }; template \u0026lt;typename List\u0026gt; struct sort_list; template \u0026lt;typename... Ts\u0026gt; struct sort_list\u0026lt;type_list\u0026lt;Ts...\u0026gt;\u0026gt; { constexpr inline static std::array sorted_types = [] { std::array types{value_of\u0026lt;Ts\u0026gt;()...}; std::ranges::sort(types, [](auto lhs, auto rhs) { return lhs-\u0026gt;size \u0026lt; rhs-\u0026gt;size; }); return types; }(); using result = typename array_to_list\u0026lt;sorted_types\u0026gt;::result; }; type_list is a simple type container, array_to_list is used to map the types in std::array back to type_list, and sort_list is the specific implementation of sorting. The process involves first mapping all types to a std::array, then sorting this array with std::ranges::sort, and finally mapping the sorted std::array back to type_list.\nLet\u0026rsquo;s test it.\nusing list = type_list\u0026lt;int, char, int, double, char, char, double\u0026gt;; using sorted = typename sort_list\u0026lt;list\u0026gt;::result; using expected = type_list\u0026lt;char, char, char, int, int, double, double\u0026gt;; static_assert(std::is_same_v\u0026lt;sorted, expected\u0026gt;); All three major compilers pass with C++20! The code is available on Compiler Explorer, and to prevent link failure, it\u0026rsquo;s also on Github.\nIt\u0026rsquo;s worth mentioning that this bidirectional mapping between types and values has become a built-in feature in Reflection for C++26. We no longer need to rely on friend injection tricks; we can directly use the ^ and [: :] operators to complete the mapping. For more details, see C++26 Static Reflection Proposal Analysis.\nthe true any # std::any is often used for type erasure, allowing completely different types to be erased and placed in the same container. However, erasure is easy, but restoration is difficult, especially when you want to print the object stored in any to see what it is, you have to cast it one by one. Is it possible to write a true any type that doesn\u0026rsquo;t require manual cast and can directly call the member functions of the type it contains?\nFor a single translation unit, this is entirely possible because the set of types constructed as any within a single translation unit is determined at compile time. We just need to record all instantiated types and use template metaprogramming to automatically try each type.\ntype register # First, consider how to register types.\ntemplate \u0026lt;typename T\u0026gt; struct self { using type = T; }; template \u0026lt;int N\u0026gt; struct reader { friend consteval auto at(reader); }; template \u0026lt;int N, typename T\u0026gt; struct setter { friend consteval auto at(reader\u0026lt;N\u0026gt;) { return self\u0026lt;T\u0026gt;{}; } }; template \u0026lt;typename T, int N = 0\u0026gt; consteval int lookup() { constexpr bool exist = requires { at(reader\u0026lt;N\u0026gt;{}); }; if constexpr(exist) { using type = decltype(at(reader\u0026lt;N\u0026gt;{}))::type; if constexpr(std::is_same_v\u0026lt;T, type\u0026gt;) { return N; } else { return lookup\u0026lt;T, N + 1\u0026gt;(); } } else { setter\u0026lt;N, T\u0026gt; setter{}; return N; } } template \u0026lt;int N = 0, auto seed = [] {}\u0026gt; consteval int count() { constexpr bool exist = requires { at(reader\u0026lt;N\u0026gt;{}); }; if constexpr(exist) { return count\u0026lt;N + 1, seed\u0026gt;(); } else { return N; } } We still use setter to register types. lookup is used to find the index of a type in the type set. The principle is to traverse the set and compare each one with is_same_v. If found, return the corresponding index. If not found by the end, register a new type. count is used to calculate the size of the type set.\nany type # Next, we define a simple any type and a make_any function to construct any objects.\nstruct any { void* data; void (*destructor)(void*); std::size_t index; constexpr any(void* data, void (*destructor)(void*), std::size_t index) noexcept : data(data), destructor(destructor), index(index) {} constexpr any(any\u0026amp;\u0026amp; other) noexcept : data(other.data), destructor(other.destructor), index(other.index) { other.data = nullptr; other.destructor = nullptr; } constexpr ~any() { if(data \u0026amp;\u0026amp; destructor) { destructor(data); } } }; template \u0026lt;typename T, typename Decay = std::decay_t\u0026lt;T\u0026gt;\u0026gt; auto make_any(T\u0026amp;\u0026amp; value) { constexpr int index = lookup\u0026lt;Decay\u0026gt;(); auto data = new Decay(std::forward\u0026lt;T\u0026gt;(value)); auto destructor = [](void* data) { delete static_cast\u0026lt;Decay*\u0026gt;(data); }; return any{data, destructor, index}; } Why write a separate make_any instead of a template constructor? Because in my actual attempts, I found that the three major compilers have different and somewhat strange instantiation locations for template constructors, leading to different evaluation results. However, for ordinary template functions, the instantiation locations are the same, so I wrote it as a separate function.\nvisit it! # The highlight is here. We can implement a function similar to std::visit to access any objects. It accepts a callback function, then traverses the type set of the any object. If it finds the corresponding type, it converts any to that type and calls the callback function.\ntemplate \u0026lt;typename Callback, auto seed = [] {}\u0026gt; constexpr void visit(any\u0026amp; any, Callback\u0026amp;\u0026amp; callback) { constexpr std::size_t n = count\u0026lt;0, seed\u0026gt;(); [\u0026amp;]\u0026lt;std::size_t... Is\u0026gt;(std::index_sequence\u0026lt;Is...\u0026gt;) { auto for_each = [\u0026amp;]\u0026lt;std::size_t I\u0026gt;() { if(any.index == I) { callback(*static_cast\u0026lt;type_at\u0026lt;I\u0026gt;*\u0026gt;(any.data)); return true; } return false; }; return (for_each.template operator()\u0026lt;Is\u0026gt;() || ...); }(std::make_index_sequence\u0026lt;n\u0026gt;{}); } Then let\u0026rsquo;s try it out.\nstruct String { std::string value; friend std::ostream\u0026amp; operator\u0026lt;\u0026lt; (std::ostream\u0026amp; os, const String\u0026amp; string) { return os \u0026lt;\u0026lt; string.value; } }; int main() { std::vector\u0026lt;any\u0026gt; vec; vec.push_back(make_any(42)); vec.push_back(make_any(std::string{\u0026#34;Hello world\u0026#34;})); vec.push_back(make_any(3.14)); for(auto\u0026amp; any: vec) { visit(any, [](auto\u0026amp; value) { std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; \u0026#39; \u0026#39;; }); // =\u0026gt; 42 Hello world 3.14 } std::cout \u0026lt;\u0026lt; \u0026#34;\\n-----------------------------------------------------\\n\u0026#34;; vec.push_back(make_any(String{\u0026#34;\\nPowerful Stateful Template Metaprogramming!!!\u0026#34;})); for(auto\u0026amp; any: vec) { visit(any, [](auto\u0026amp; value) { std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; \u0026#39; \u0026#39;; }); // =\u0026gt; 42 Hello world 3.14 // =\u0026gt; Powerful Stateful Template Metaprogramming!!! } return 0; } All three major compilers output the results as expected! The code is also available on Compiler Explorer and Github.\nconclusion # These two articles on STMP fulfill a long-standing wish of mine. Before this, I had been pondering how to implement a true any type like the code above, without requiring users to register in advance. I tried many methods but never succeeded. However, the emergence of STMP gave me hope. After realizing the heights it could reach, I immediately stayed up all night to write the article and examples.\nOf course, I do not recommend using this technique in any form in actual projects. Since this code heavily relies on the location of template instantiation, it is very prone to ODR violations, and repeated instantiation can significantly increase compilation time. For such stateful code requirements, we can often refactor them into stateless code. However, manually writing this can be very labor-intensive, so it\u0026rsquo;s more recommended to use code generators for additional code generation to meet this requirement. For example, we can use libclang to collect all instantiation information of any in the translation unit and then create a corresponding table.\nFinally, thank you for reading. I hope these two articles have given you a deeper understanding of C++ templates.\n","date":"30 July 2023","externalUrl":null,"permalink":"/en/articles/646812253/","section":"Articles","summary":"\u003cp\u003eIn the previous \u003ca href=\"https://www.ykiko.me/zh-cn/articles/646752343\" target=\"_blank\"\u003earticle\u003c/a\u003e, we gained a preliminary understanding of the principles of STMP and used it to implement a simple compile-time counter. However, its power extends far beyond that. This article will discuss some advanced applications based on STMP.\u003c/p\u003e","title":"C++ Forbidden Dark Magic: STMP (Part 2)","type":"articles"},{"content":"","date":"30 July 2023","externalUrl":null,"permalink":"/en/series/stmp/","section":"Series","summary":"","title":"STMP","type":"series"},{"content":"As is well known, traditional C++ constant expression evaluation neither depends on nor alters the global state of the program. For any identical input, its output is always the same, making it considered purely functional. Template Meta Programming (TMP), as a subset of constant evaluation, should also adhere to this rule.\nBut is this really the case? Without violating the C++ standard, could the following code possibly compile?\nconstexpr auto a = value(); constexpr auto b = value(); static_assert(a != b); Is it possible to implement a compile-time counter like this?\nconstexpr auto a = next(); constexpr auto b = next(); constexpr auto c = next(); static_assert(a == 0 \u0026amp;\u0026amp; b == 1 \u0026amp;\u0026amp; c == 2); If the results of constant evaluations differ each time, it implies that the evaluation alters the global state. This form of stateful meta-programming is known as Stateful Template Meta Programming (STMP).\nIn fact, with the help of some compiler built-in macros, we can achieve such effects, for example:\nconstexpr auto a = __COUNTER__; constexpr auto b = __COUNTER__; constexpr auto c = __COUNTER__; static_assert(a == 0 \u0026amp;\u0026amp; b == 1 \u0026amp;\u0026amp; c == 2); During preprocessing, the compiler increments the replacement result of the __COUNTER__ macro. If you preprocess the source file, you will find it transformed into:\nconstexpr auto a = 0; constexpr auto b = 1; constexpr auto c = 2; static_assert(a == 0 \u0026amp;\u0026amp; b == 1 \u0026amp;\u0026amp; c == 2); This still differs significantly from the effect we aim to achieve, as preprocessing does not involve the semantic part of the C++ program. Moreover, such a counter is globally unique, and we cannot create multiple counters. Is there another way?\nThe answer is yes. As unbelievable as it may seem, related discussions date back to 2015, and there are also related articles on Zhihu. However, this article was published in 2017, using C++14, and much of its content is no longer applicable. With the C++26 standard now being developed, many things need to be revisited. We will focus on C++20.\nIf you are only interested in the code, I have placed the relevant code on Compiler Explorer. It compiles successfully with the three major compilers under C++20, and you can directly see the compiler\u0026rsquo;s output. To prevent link failure, it is also available on GitHub. If you want to understand its principles, please continue reading. The C++ standard is very complex, and the author cannot guarantee the complete accuracy of the article. If there are any errors, please discuss them in the comments.\nNote: This article is for technical discussion only. Please do not use the related code in actual production. According to CWG 2118, the related code seems to be considered ill-formed. Moreover, STMP is prone to ODR violations and requires great caution.\nObservable State # Before changing, we must first be able to observe changes in the global state at compile time. Since C++ supports forward declaration, a struct is considered an incomplete type before its definition is seen, meaning the completeness of the class varies in different contexts.\nThe C++ standard stipulates that sizeof can only be used on complete types (after all, incomplete types cannot calculate size). Using it on an incomplete type causes a compilation error, and this error is not a hard error, so we can use SFINAE or requires to capture this error. Thus, we can detect class completeness as follows:\ntemplate \u0026lt;typename T\u0026gt; constexpr inline bool is_complete_v = requires { sizeof(T); }; Some readers might ask, why not use concept in C++20? Using concept here would have some strange effects due to the wording in the standard regarding atomic constraints. We won\u0026rsquo;t delve into this; interested readers can try it themselves.\nTry using it to observe type completeness:\nstruct X; static_assert(!is_complete_v\u0026lt;X\u0026gt;); struct X {}; static_assert(is_complete_v\u0026lt;X\u0026gt;); Actually, the above code will fail to compile, with the second static assertion failing. How strange, what\u0026rsquo;s going on? Let\u0026rsquo;s try it separately:\n// first time struct X; static_assert(!is_complete_v\u0026lt;X\u0026gt;); struct X {}; // second time struct X; struct X {}; static_assert(is_complete_v\u0026lt;X\u0026gt;); Separately, it works, but together it doesn\u0026rsquo;t. Why is this? It\u0026rsquo;s because the compiler caches the result of the first template instantiation, and subsequent encounters with the same template directly use the first instantiation result. In the initial example, the second is_complete_v\u0026lt;X\u0026gt; still uses the first template instantiation result, so it evaluates to false, causing the compilation to fail.\nIs it reasonable for the compiler to do this? Yes, because templates may ultimately produce externally linked symbols. If the results of two instantiations differ, which one should be chosen during linking? But this does affect our ability to observe compile-time state. How to solve it? The answer is to add a template parameter as a seed, filling in different parameters each time to force the compiler to instantiate a new template:\ntemplate \u0026lt;typename T, int seed = 0\u0026gt; constexpr inline bool is_complete_v = requires { sizeof(T); }; struct X; static_assert(!is_complete_v\u0026lt;X, 0\u0026gt;); struct X {}; static_assert(is_complete_v\u0026lt;X, 1\u0026gt;); Manually filling in a different parameter each time is cumbersome. Is there a way to automate this?\nNote that if a lambda expression is used as a Non Type Template Parameter (NTTP) default template parameter, each instantiation of the template will be of a different type:\n#include \u0026lt;iostream\u0026gt; template \u0026lt;auto seed = [] {}\u0026gt; void test() { std::cout \u0026lt;\u0026lt; typeid(seed).name() \u0026lt;\u0026lt; std::endl; } int main() { test(); // class \u0026lt;lambda_1\u0026gt; test(); // class \u0026lt;lambda_2\u0026gt; test(); // class \u0026lt;lambda_3\u0026gt; return 0; } This feature perfectly meets our needs, as it automatically fills in a different seed each time. Thus, the final implementation of is_complete_v is as follows:\ntemplate \u0026lt;typename T, auto seed = [] {}\u0026gt; constexpr inline bool is_complete_v = requires { sizeof(T); }; Try using it again to observe type completeness:\nstruct X; static_assert(!is_complete_v\u0026lt;X\u0026gt;); struct X {}; static_assert(is_complete_v\u0026lt;X\u0026gt;); Compilation succeeds! We have successfully observed changes in the compile-time global state.\nModifiable State # After being able to observe state changes, the next consideration is whether we can actively change the state through code. Unfortunately, for most declarations, the only way to change their state is by modifying the source code to add definitions; there are no other means to achieve this.\nThe only exception is friend functions. But before considering how friend functions can play a role, let\u0026rsquo;s first consider how to observe whether a function has been defined. For most functions, this is unobservable, as a function may be defined in another compilation unit, and calling a function does not require its definition to be visible.\nThe exception is functions with a return type of auto. If the function definition is not visible, the return type cannot be deduced, making the function call impossible. The following code can detect whether the foo function is defined:\ntemplate \u0026lt;auto seed = [] {}\u0026gt; constexpr inline bool is_complete_v = requires { foo(seed); }; auto foo(auto); static_assert(!is_complete_v\u0026lt;\u0026gt;); auto foo(auto value) { return sizeof(value); } static_assert(is_complete_v\u0026lt;\u0026gt;); Next, let\u0026rsquo;s discuss how to change the global state through friend functions.\nThe biggest difference between friend functions and ordinary functions is that the function definition and declaration do not need to be in the same scope. Consider the following example:\nstruct X { friend auto foo(X); }; struct Y { friend auto foo(X) { return 42; } }; int x = foo(X{}); The above code compiles successfully with the three major compilers and fully complies with the C++ standard. This gives us room to operate. We can instantiate a class template while also instantiating the friend functions defined within it, thereby adding definitions to function declarations in other locations. This technique is also known as friend injection.\nauto foo(auto); template \u0026lt;typename T\u0026gt; struct X { friend auto foo(auto value) { return sizeof(value); } }; static_assert(!is_complete_v\u0026lt;\u0026gt;); // #1 X\u0026lt;void\u0026gt; x; // #2 static_assert(is_complete_v\u0026lt;\u0026gt;); // #3 Note that at #1, the template X has not been instantiated, so the foo function has not yet been defined, causing is_complete_v to return false. At #2, we instantiate an X\u0026lt;void\u0026gt;, causing the foo function within X to be instantiated, adding a definition to foo, so at #3, is_complete_v returns true. Of course, a function can only have one definition. If you try to instantiate an X\u0026lt;int\u0026gt;, the compiler will report a redefinition error for foo.\nConstant Switch # Combining the above techniques, we can easily instantiate a compile-time switch:\nauto flag(auto); template \u0026lt;auto value\u0026gt; struct setter { friend auto flag(auto) {} }; template \u0026lt;auto N = 0, auto seed = [] {}\u0026gt; consteval auto value() { constexpr bool exist = requires { flag(N); }; if constexpr(!exist) { setter\u0026lt;exist\u0026gt; setter; } return exist; } int main() { constexpr auto a = value(); constexpr auto b = value(); static_assert(a != b); } Its principle is simple. The first time, setter has not been instantiated, so the flag function has not been defined, causing exist to evaluate to false, entering the if constexpr branch, instantiating a setter\u0026lt;false\u0026gt;, and returning false. The second time, setter has been instantiated, and the flag function has been defined, so exist evaluates to true, directly returning true.\nNote: The type of N here must be written as auto, not std::size_t. Only then is flag(N) a dependent name, allowing the requires to detect the legality of the expression. Due to the two-phase lookup of templates, if written as flag(0), it would be looked up in the first phase, find the call fails, and produce a hard error, causing compilation to fail.\nConstant Counter # Going further, we can directly implement a compile-time counter:\ntemplate \u0026lt;int N\u0026gt; struct reader { friend auto flag(reader); }; template \u0026lt;int N\u0026gt; struct setter { friend auto flag(reader\u0026lt;N\u0026gt;) {} }; template \u0026lt;int N = 0, auto seed = [] {}\u0026gt; consteval auto next() { constexpr bool exist = requires { flag(reader\u0026lt;N\u0026gt;{}); }; if constexpr(!exist) { setter\u0026lt;N\u0026gt; setter; return N; } else { return next\u0026lt;N + 1\u0026gt;(); } } int main() { constexpr auto a = next(); constexpr auto b = next(); constexpr auto c = next(); static_assert(a == 0 \u0026amp;\u0026amp; b == 1 \u0026amp;\u0026amp; c == 2); } Its logic is, starting from N as 0, detect whether flag(reader\u0026lt;N\u0026gt;) is defined. If not defined, instantiate a setter\u0026lt;N\u0026gt;, adding a definition to flag(reader\u0026lt;N\u0026gt;), and return N. Otherwise, recursively call next\u0026lt;N + 1\u0026gt;(), detecting the situation for N+1. Thus, this counter actually records the number of setter instantiations.\n§: Access Private # First, it\u0026rsquo;s important to clarify a point: the class access specifiers private, public, protected only act during compile-time checks. If there is a way to bypass this compile-time check, it is entirely possible to legally access any member of the class.\nIs there such a method? Yes: Template explicit instantiation ignores class scope access permissions:\nThe C++11/14 standards state the following in note 14.7.2/12 [temp.explicit]: The usual access checking rules do not apply to names used to specify explicit instantiations. [ Note: In particular, the template arguments and names used in the function declarator (including parameter types, return types and exception speciﬁcations) may be private types or objects which would normally not be accessible and the template may be a member template or member function which would not normally be accessible. — end note ]\nThis means that during template explicit instantiation, we can directly access private members of a class.\n#include \u0026lt;iostream\u0026gt; class Bank { double money = 999\u0026#39;999\u0026#39;999\u0026#39;999; public: void check() const { std::cout \u0026lt;\u0026lt; money \u0026lt;\u0026lt; std::endl; } }; template \u0026lt;auto mp\u0026gt; struct Thief { friend double\u0026amp; steal(Bank\u0026amp; bank) { return bank.*mp; } }; double\u0026amp; steal(Bank\u0026amp; bank); // #1 template struct Thief\u0026lt;\u0026amp;Bank::money\u0026gt;; // #2 int main() { Bank bank; steal(bank) = 100; // #3 bank.check(); // 100 return 0; } The syntax at #2 is template explicit instantiation, allowing us to directly access the private member money of Bank. By using \u0026amp;Bank::money, we obtain the corresponding member pointer. Simultaneously, through template explicit instantiation, a definition is added to the steal function at #1, allowing direct invocation of this function at #3 to obtain a reference to money. Finally, 100 is successfully output.\n","date":"29 July 2023","externalUrl":null,"permalink":"/en/articles/646752343/","section":"Articles","summary":"\u003cp\u003eAs is well known, traditional C++ constant expression evaluation neither depends on nor alters the global state of the program. For any identical input, its output is always the same, making it considered \u003cstrong\u003epurely functional\u003c/strong\u003e. \u003cstrong\u003eTemplate Meta Programming (TMP)\u003c/strong\u003e, as a subset of constant evaluation, should also adhere to this rule.\u003c/p\u003e","title":"C++ Forbidden Dark Arts: STMP (Part 1)","type":"articles"},{"content":"std::variant was introduced into the C++ standard library in C++17. This article will discuss the background of its inclusion in the standard and some issues with its usage.\nSum Type # First, let\u0026rsquo;s discuss sum types, also known as tagged unions. A sum type is a type that can hold one of several possible types.\nFor example, consider the following two types:\nstruct Circle { double radius; }; struct Rectangle { double width; double height; }; The sum type of Circle and Rectangle, let\u0026rsquo;s call it Shape, can be implemented in C as follows:\nstruct Shape { enum Type { Circle, Rectangle } type; union { struct Circle circle; struct Rectangle rectangle; }; }; Here, we use a feature called anonymous union, which declares a union member of the corresponding type and injects the field names into the current scope.\nThis allows us to assign values of different types to a variable of type Shape, while updating the type to reflect the current assignment. When accessing the value, we can determine how to access it based on the type. For example:\nvoid foo(Shape shape) { if(shape.type == Shape::Circle) { Circle c = shape.circle; printf(\u0026#34;circle: radius is %f\\n\u0026#34;, c.radius); } else if(shape.type == Shape::Rectangle) { Rectangle r = shape.rectangle; printf(\u0026#34;rectangle: width is %f, height is %f\\n\u0026#34;, r.width, r.height); } } int main() { Shape shape; shape.type = Shape::Circle; shape.circle.radius = 1.0; foo(shape); shape.type = Shape::Rectangle; shape.rectangle.width = 1.0; shape.rectangle.height = 2.0; foo(shape); } Not Trivial # However, things are not so simple in C++. Consider the following code:\nstruct Settings { enum class Type { int_, double_, string } type; union { int i; double d; std::string s; }; }; int main(){ Settings settings; settings.type = Settings::Type::String; settings.s = std::string(\u0026#34;hello\u0026#34;); } This code will not compile. The compiler will report an error: use of deleted function Settings::Settings(). Why is the constructor of Settings deleted? This is because the constructor of std::string is not trivial. When a union contains members of non-trivial types, the compiler cannot correctly generate constructors and destructors (it doesn\u0026rsquo;t know which member to initialize or destruct). For more details, refer to the union section on cppreference.\nHow can we solve this? We need to define the constructor and destructor for the union ourselves. For example, we can define an empty constructor and destructor that do nothing:\nunion Value { int i; double d; std::string s; Value() {} ~Value() {} }; struct Settings { enum class Type { int_, double_, string } type; Value value; }; When using this, we need to explicitly call the constructor to initialize a member using placement new, and similarly, we need to manually call the destructor to destroy a member.\nint main(){ Settings settings; settings.type = Settings::Type::string; new (\u0026amp;settings.value.s) std::string(\u0026#34;hello\u0026#34;); std::cout \u0026lt;\u0026lt; settings.value.s \u0026lt;\u0026lt; std::endl; settings.value.s.~basic_string(); settings.type = Settings::Type::int_; new (\u0026amp;settings.value.i) int(1); std::cout \u0026lt;\u0026lt; settings.value.i \u0026lt;\u0026lt; std::endl; settings.value.i.~int(); } Note that you cannot directly assign here. The assignment operation actually calls the member function operator=, and only objects that have already been initialized can call member functions.\nFrom the above code, it\u0026rsquo;s clear that directly using union to represent sum types in C++ is very cumbersome. Not only do you need to update the type in time, but you also need to correctly call constructors and destructors, and be careful about the timing of assignments. If any step is forgotten, it can lead to undefined behavior, which is very frustrating. Fortunately, C++17 provides std::variant to solve this problem.\nstd::variant # Let\u0026rsquo;s look at the code directly:\n#include \u0026lt;string\u0026gt; #include \u0026lt;variant\u0026gt; using Settings = std::variant\u0026lt;int, bool, std::string\u0026gt;; int main() { Settings s = {1}; s = true; s = std::string(\u0026#34;hello\u0026#34;); } The above code is completely well-defined. Through template metaprogramming, variant handles object construction and destruction at the appropriate times.\nIt has an index member function that can get the index of the current type in the type list you provided.\nSettings s; s = std::string(\u0026#34;hello\u0026#34;); // s.index() =\u0026gt; 2 s = 1; // s.index() =\u0026gt; 0 s = true; // s.index() =\u0026gt; 1 You can use std::get to retrieve the corresponding value from the variant:\nSettings s; s = std::string(\u0026#34;hello\u0026#34;); std::cout \u0026lt;\u0026lt; std::get\u0026lt;std::string\u0026gt;(s); // =\u0026gt; hello Some might wonder, if I already know that it contains a string, why use std::variant? Note that get also has an overload with an integer template parameter. Can it solve this problem?\nstd::cout \u0026lt;\u0026lt; std::get\u0026lt;2\u0026gt;(s); // =\u0026gt; hello Oh, I see. So if I can use index directly to get the value, why not write it like this?\nstd::cout \u0026lt;\u0026lt; std::get\u0026lt;s.index()\u0026gt;(s); Unfortunately, this won\u0026rsquo;t work. Template parameters must be compile-time constants, and variant, as a type-erasure mechanism, has an index that is definitely a runtime value. What to do? Dynamic to static, you can only dispatch one by one. For example:\nif (s.index() == 0){ std::cout \u0026lt;\u0026lt; std::get\u0026lt;0\u0026gt;(s) \u0026lt;\u0026lt; std::endl; } else if (s.index() == 1){ std::cout \u0026lt;\u0026lt; std::get\u0026lt;1\u0026gt;(s) \u0026lt;\u0026lt; std::endl; } else if (s.index() == 2){ std::cout \u0026lt;\u0026lt; std::get\u0026lt;2\u0026gt;(s) \u0026lt;\u0026lt; std::endl; } Using numbers is not very readable. We can use std::holds_alternative to make decisions based on types:\nif (std::holds_alternative\u0026lt;std::string\u0026gt;(s)){ std::cout \u0026lt;\u0026lt; std::get\u0026lt;std::string\u0026gt;(s) \u0026lt;\u0026lt; std::endl; } else if (std::holds_alternative\u0026lt;int\u0026gt;(s)){ std::cout \u0026lt;\u0026lt; std::get\u0026lt;int\u0026gt;(s) \u0026lt;\u0026lt; std::endl; } else if (std::holds_alternative\u0026lt;bool\u0026gt;(s)){ std::cout \u0026lt;\u0026lt; std::get\u0026lt;bool\u0026gt;(s) \u0026lt;\u0026lt; std::endl; } Although this works, there\u0026rsquo;s too much redundant code. Is there a better way to operate on the values inside a variant?\nstd::visit # The name visit actually comes from the visitor pattern in design patterns. Using it, we can write the following code:\nSettings s; s = std::string(\u0026#34;hello\u0026#34;); auto callback = [](auto\u0026amp;\u0026amp; value){ std::cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; }; std::visit(callback, s); // =\u0026gt; hello settings = 1; std::visit(callback, s); // =\u0026gt; 1 Isn\u0026rsquo;t it magical? Just pass in a callback, and you can directly access the value inside the variant without any manual dispatching. In software engineering, there\u0026rsquo;s a golden rule: complexity doesn\u0026rsquo;t disappear, it just shifts. This is no exception. In fact, visit internally instantiates a function for each type in the variant for your callback, pre-generates a function table, and then at runtime, directly calls the function in the table based on the index.\nBut more often, we want to do different things based on different types. In other languages, this can be conveniently achieved through pattern matching.\nHaskell:\ndata Settings = IntValue Int | BoolValue Bool | StringValue String deriving (Show, Eq) match :: Settings -\u0026gt; IO () match (IntValue x) = putStrLn $ \u0026#34;Int: \u0026#34; ++ show (x + 1) match (BoolValue x) = putStrLn $ \u0026#34;Bool: \u0026#34; ++ show (not x) match (StringValue x) = putStrLn $ \u0026#34;String: \u0026#34; ++ (x ++ \u0026#34; \u0026#34;) Rust:\nenum Settings{ Int(i32), Bool(bool), String(String), } fn main(){ let settings = Settings::Int(1); match settings{ Settings::Int(x) =\u0026gt; println!(\u0026#34;Int: {}\u0026#34;, x + 1), Settings::Bool(x) =\u0026gt; println!(\u0026#34;Bool: {}\u0026#34;, !x), Settings::String(x) =\u0026gt; println!(\u0026#34;String: {}\u0026#34;, x + \u0026#34; \u0026#34;), } } Unfortunately, as of C++23, C++ still lacks pattern matching. To achieve similar effects in C++, there are currently two ways to simulate it:\nFunction Overload:\ntemplate\u0026lt;typename ...Ts\u0026gt; struct Overload : Ts... { using Ts::operator()...; }; template\u0026lt;typename ...Ts\u0026gt; Overload(Ts...) -\u0026gt; Overload\u0026lt;Ts...\u0026gt;; int main() { using Settings = std::variant\u0026lt;int, bool, std::string\u0026gt;; Overload overloads{ [](int x) { std::cout \u0026lt;\u0026lt; \u0026#34;Int: \u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }, [](bool x) { std::cout \u0026lt;\u0026lt; \u0026#34;Bool: \u0026#34; \u0026lt;\u0026lt; std::boolalpha \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }, [](std::string x) { std::cout \u0026lt;\u0026lt; \u0026#34;String: \u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; std::endl; }, }; Settings settings = 1; std::visit(overloads, settings); } if constexpr:\nint main() { using Settings = std::variant\u0026lt;int, bool, std::string\u0026gt;; auto callback = [](auto\u0026amp;\u0026amp; value) { using type = std::decay_t\u0026lt;decltype(value)\u0026gt;; if constexpr(std::is_same_v\u0026lt;type, int\u0026gt;) { std::cout \u0026lt;\u0026lt; \u0026#34;Int: \u0026#34; \u0026lt;\u0026lt; value + 1 \u0026lt;\u0026lt; std::endl; } else if constexpr(std::is_same_v\u0026lt;type, bool\u0026gt;) { std::cout \u0026lt;\u0026lt; \u0026#34;Bool: \u0026#34; \u0026lt;\u0026lt; !value \u0026lt;\u0026lt; std::endl; } else if constexpr(std::is_same_v\u0026lt;type, std::string\u0026gt;) { std::cout \u0026lt;\u0026lt; \u0026#34;String: \u0026#34; \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; } }; Settings settings = 1; std::visit(callback, settings); } Both methods are somewhat awkward. Using templates for such tricks not only slows down compilation but also makes error messages harder to understand. This also means that variant is currently very difficult to use, lacking the necessary language facilities to simplify its operations, deeply entangled with templates, and discouraging to many.\n","date":"25 July 2023","externalUrl":null,"permalink":"/en/articles/645810896/","section":"Articles","summary":"\u003cp\u003e\u003ccode\u003estd::variant\u003c/code\u003e was introduced into the C++ standard library in C++17. This article will discuss the background of its inclusion in the standard and some issues with its usage.\u003c/p\u003e\n\n\n\u003ch2 class=\"relative group\"\u003eSum Type \n    \u003cdiv id=\"sum-type\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#sum-type\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eFirst, let\u0026rsquo;s discuss \u003cstrong\u003esum types\u003c/strong\u003e, also known as \u003ca href=\"https://en.wikipedia.org/wiki/Tagged_union\" target=\"_blank\"\u003etagged unions\u003c/a\u003e. A sum type is a type that can hold one of several possible types.\u003c/p\u003e","title":"std::variant is Hard to Use!","type":"articles"},{"content":"","externalUrl":null,"permalink":"/en/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]